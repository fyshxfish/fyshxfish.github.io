[{"content":" Embedde PDF is not supported, please clike here to download. ","date":"2025-05-29T18:06:00+08:00","permalink":"http://fyshxfish.github.io/p/foundations-and-applications-of-intersection-and-union-types/","title":"Foundations and Applications of Intersection and Union Types"},{"content":"Following problems come from functional, available on Steam.\nBasic anything Any term that conforms to Lambda Calculus syntax (1. variable 2. abstraction 3. application) is okay.\nidentity x: x two arguments x:y: y x squaring f:x: f (f x) indirection f:x:y: f y x Boolean Definitions:\nTRUE = t:f: t FALSE = t:f: f IF p:t:f: p t f Simple LC has no type system, so programmers need to ensure that p can always evaluate to TRUE / FALSE, then p t f further evaluates to t/ f. If p cannot evaluate to TRUE / FALSE, then p t f will be retained or produce unexpected evaluation behavior.\nOne thing you can easily notice is: IF P A B ‚â° P A B, you can completely omit IF in all occasions where it\u0026rsquo;s used. This doesn\u0026rsquo;t change the semantics and can reduce one reduction, but for readability, there\u0026rsquo;s still reason to keep IF in somewhat complex programs.\nNOT b: b FALSE TRUE This looks subtly clever. It can be obtained straightforwardly through b: IF b FALSE TRUE ‚Üí b FALSE TRUE, or directly by utilizing the meaning of TRUE / FALSE - selecting the first/second item.\nAND p:q: p q p If p = TRUE, then AND p q ‚â° q; if p = FALSE, then AND p q ‚â° FALSE ‚â° p.\nOR p:q: p p q If p = TRUE, then OR p q ‚â° p ‚â° TRUE; if p = FALSE, then OR p q ‚â° q.\nXOR p:q: p (NOT q) q Similar to AND, OR, you can draw a truth table to organize your thoughts.\nPair and List PAIR x:y:f: f x y PAIR A B ‚Üí (x:y:f: f x y) A B ‚Üí (f: f A B) is an abstraction that: contains A, B in order, waiting for a function f to act on the contained A, B. For example, when A, B are Boolean, f can be AND / OR / \u0026hellip; (of course, the syntax doesn\u0026rsquo;t restrict the shape of f,A,B, if you want to write PAIR TRUE 0 PAIR the interpreter won\u0026rsquo;t stop you)\nFST p: p TRUE When p = PAIR A B, p TRUE ‚Üí (PAIR A B) TRUE ‚Üí (f: f A B) TRUE ‚Üí TRUE A B ‚Üí A. Note that p is a function that can receive a parameter f, here we make it receive the TRUE function to select the first element. In LC, TRUE / FALSE are more appropriately interpreted as selecting the first/second item that follows, rather than expressing the truth/falsity of a proposition. This is meaningful because when we write programs in other high-level languages, if we need a Boolean value X, X\u0026rsquo;s ultimate utility is often in the selection of then-clause / else-clause.\nSND p: p FALSE Similar to FST.\nsimple list Get the 3rd item from the list (1-indexed):\nl: FST ( SND ( SND l ) ) A list is a simple recursive structure. The recursive base is an empty list, represented here by FALSE. The recursive step is adding elements to a list, implemented here using PAIR. e.g. [] ‚Ü¶ FALSE, 1 ‚Ü¶ (PAIR 1 FALSE), [1,3] ‚Ü¶ (PAIR 1 (PAIR 3 FALSE)). Note in the [1,3] example, if viewed from the perspective of adding elements to a list, the head is the item closest to FALSE, the closer to FALSE, the smaller the index, because it was added earlier. Under this interpretation, [1,3] ‚Ü¶ (PAIR 3 (PAIR 1 FALSE)). However, the game doesn\u0026rsquo;t adopt this interpretation, but maintains visual alignment with familiar [a,b,..], making the most recently added item - the leftmost item - the head. Keep this in mind when dealing with ascending/descending order problems later.\nANY For a list containing 3 Boolean values, return TRUE if any item is TRUE, otherwise return FALSE:\n(l: IF (OR (FST (SND (SND l))) (OR (FST l) (FST (SND l)) ) ) TRUE FALSE ) Just write according to logic straightforwardly. Here the list has fixed length, which is easy to deal with. Variable-length lists would require recursion, see later.\nPUSH (m:l: PAIR m l) Use PUSH to add new item m to list l. According to Œ∑-reduction, PUSH ‚â° PAIR, so writing PAIR directly is sufficient here.\nPOP SND Pop out the outermost / leftmost item.\nEMPTY l: l (t:x:y: FALSE) TRUE First, EMPTY needs to receive a list, so its basic shape is EMPTY = l: ....\nConsider case l' = FALSE, EMPTY l' ~expected‚Üí TRUE. Using FALSE\u0026rsquo;s selection ability, we make EMPTY = l: l ùïè TRUE.\nConsider case l* = PAIR a (PAIR b (...)) = (f: f a (PAIR b (...))) ‚âà (f: f a _tail), viewing l* as a function receiving one parameter, EMPTY l* = (f: f a _tail) ùïè TRUE ‚Üí ùïè a _tail TRUE ~expected‚Üí FALSE. Then ùïè\u0026rsquo;s job is to receive the following 3 items and return FALSE, so ùïè = (t:x:y: FALSE).\nCombining all above gives the final solution EMPTY = l: l (t:x:y: FALSE) TRUE\nRecursion create recursion - Y combinator Motivation: Recursion in LC Try to define recursive factorial function in LC:\nf = a: IF (EQ a 1) 1 (a * f (a - 1)) The above definition doesn\u0026rsquo;t conform to LC syntax because LC functions are anonymous functions and don\u0026rsquo;t support calling functions by name (like f above). Yet recursive functions inevitably need self-reference. How to solve this problem?\nApplying function $F$ to parameter $A$ can be expressed as $F A$, or using higher-order functions like this: $(\\lambda fa.\\ f\\ a) F A$. Building on this, add some logic, like expressing \u0026ldquo;with parameters $a$ and $p$, function $f$, if $p\\ a$ is true, return $f\\ a$, otherwise return $a$ itself\u0026rdquo;: $(\\lambda fap.\\ IF\\ (p\\ a)\\ (f\\ a)\\ a)$. Based on this idea, assuming our target factorial function is F, then F satisfies this equation, denoting (f:a: ..) as F':\nF = (f:a: IF (EQ a 1) 1 (a * f (a - 1)) ) F ‚â° F\u0026#39; F Looking at the right side of the equation, F'\u0026rsquo;s meaning is to receive function f and parameter a, if EQ a 1 return 1, otherwise return a * f (a - 1). Passing recursive function F to F', the behavior of resulting function F' F matches our target factorial function F, semantically making both sides equal.\nCurrently we have equation F = F' F ‚ë†, where F' is a known closed term. Since F involves self-reference, no normal form exists, so consider if there exists some Y s.t. Y F' = F ‚ë°. Substituting ‚ë° into ‚ë†, we get Y F' = F' (Y F'). The next goal is to solve for Y\u0026rsquo;s normal form. Once we get Y, target recursive function F = Y F' follows.\nWhy try to decompose F into Y F'?\nSpeaking loosely, from equation perspective F = F' F has only one unknown F. Transforming F to Y F' similarly contains only one unknown Y, while F' is known and closely related to our solution target (recursive function F).\nDesigning the Y Combinator Y is a term that satisfies: Y F = F (Y F) = F (F (Y F)) = .... (Note: How/When the term expands depends on the evaluaton strategy.)\nTo design Y that meets the above requirements, let\u0026rsquo;s analyze:\nY must be of the form (f: ...).\nSelf-reference in Y? ‚Äî We need to repeat Y, or construct the right-side Y.\nFunction/Abstraction is All You Need ‚Äî Since LC has no storage, in Y F = F (Y F), the Ys on both sides aren\u0026rsquo;t the same instance. They\u0026rsquo;re not value or address copies (LC has no storage concept). The right-side Y needs to be constructed, being equal under alpha-conversion to the left-side Y.\nHow to repeat F? Simple - Y = (f: ...) receives parameter F, and within Y\u0026rsquo;s body, we can repeat it as needed.\nDesign an abstraction M for construction. M will receive necessary parameters and organize them to form a structure identical to Y.\nY = f: M f ... ~·¥áx·¥ò·¥á·¥Ñ·¥õ·¥á·¥Ö‚Üí M = f: f (Wai f): M needs Y\u0026rsquo;s parameter f and must build structure matching Y F; Y = f: M f M ... ~·¥áx·¥ò·¥á·¥Ñ·¥õ·¥á·¥Ö‚Üí M = f:m: f (m f m): Since we want M to match Y F\u0026rsquo;s structure, and Y contains M, M must contain M too, passed via parameter m. In M\u0026rsquo;s body, leftmost f implements f\u0026rsquo;s reapplication, (m f m) constructs structure alpha-equivalent to left-side Y F. Y = f: M f M, where M = f:m: f (m f m) is a valid Y combinator, verifiable by Y F = M F M = (f:m: f (m f m)) F M = F (M F M) = F (M F M) = F (Y F). There are countless Y combinators, like (a) Y = f: M M f, M = m:f: f (m m f) - similar but more concise via Œ∑-reduction to Y = M M, M = ..., as given by Turing; (b) Y = f: E (E f) E f, E = r:s:f: f (s r s f) works too but less elegant; (c) most concise Y = f: (x: f (x x)) (x: f (x x)) which differs by not containing combinator sub-terms.\nExercise: How to implement combinator D satisfying D F D = D (D F D) D = ...?\nOne solution: D = f:d: d (d f d) d, following similar principles.\nMust Y be a combinator? Can it have free variables?\nIf Y had free variable z, constructing Y with M must consider z:\nclosed M: Pass z as parameter giving Y = f: M f c M, M = f:c:m: f (m f c m) - works but adds unnecessary complexity; open M: If M contains free z, like Y = f: K f K z, K = f:k: f (k f k z), it fails producing: Y F = F (K F K z) z = F (Y F) z = F (F (Y F) z) z. Conclusion: Possible but pointless. Intuitively, arbitrary free variables serve no purpose.\nUsing the Y combinator Following the motivation section, we use F' = f:a: ... to express the application logic between recursive function f and its parameter a. With target recursive function F, we have F = F' F. Since self-reference is invalid, we consider using Y F' to represent F. In the previous section we derived a viable Y, so F = Y F' gives us our desired target function.\nThe problems in this section become straightforward once you understand the Y combinator. Key points to note:\nWhen using previously defined functions, pay attention to parameter order. For example, FILTER takes the list first, then the filtering function. Since Simple LC has few syntax constraints, programmers need to be extra careful; Several problems may involve list reversal, so write REVERSE first and reuse it; Watch your bracket matching - write in an advanced editor first to avoid basic errors, then copy the code into the game for evaluation. The answers below pass evaluation but may not be the most concise. strip prefix Remove FALSE prefix from variable length list:\nY (f:l: IF (FST l) l (f (SND l)) ) ACC Y (a:l:f:i: IF (EMPTY l) i (a (SND l) f (f i (FST l))) ) ALL l: ACC l AND TRUE REVERSE Y (i:c:l: IF (EMPTY l) c (i (PAIR (FST l) c) (SND l)) ) FALSE MAP Y (m:c:l:f: IF (EMPTY l) (REVERSE c) (m (PAIR (f (FST l)) c) (SND l) f) ) FALSE NONE (l: ALL (MAP l NOT)) FILTER Y (m:c:l:f: IF (EMPTY l) (REVERSE c) ( IF (f (FST l)) (m (PAIR (FST l) c) (SND l) f) (m c (SND l) f) ) ) FALSE ZIP Y (z:c:m:n: IF (EMPTY m) (REVERSE c) (z (PAIR (PAIR (FST m) (FST n)) c) (SND m) (SND n)) ) FALSE EQBLIST (m:n: ALL (MAP (MAP (ZIP m n) (p: XOR (FST p) (SND p)) ) NOT ) ) CONCAT (m:n: (Y (g:c:r: IF (EMPTY r) c (g (PAIR (FST r) c) (SND r)) ) ) n (REVERSE m) ) Numerals Church Numerals use functions to express natural numbers. Two key points are: 1. base (0 := f:x: x) 2. successor (SUC). By repeatedly applying successor to the base, we can obtain all Church Numerals.\nSUC Given Church Numeral n, n is a function that takes parameters f, x, where n f x means applying f to x $n$ times. SUC n is a function that takes f, x and applies f to x $(n+1)$ times.\n(n: (f:x: f (n f x) ) ) ZERO Use logical operations to determine if given n is (f:x: x).\n(n: n (x: AND FALSE x) TRUE) PRE A basic observation is n = n SUC 0, where equality means intensional equality. So iterating on PAIR 0 0 $n$ times, where each iteration: 1. aligns right number with left 2. increments left number, means right number always lags left by one step. After $n$ iterations, left number is n, right number is its predecessor.\n(n: SND (n (p: PAIR (SUC (FST p)) (FST p)) (PAIR 0 0) ) ) ADD Given x, y, the goal is x+y, meaning: ready to receive f, z, apply f to z $(x+y)$ times. First apply f to z $x$ times getting x f z, then apply f to (x f z) $y$ times.\n(x:y: (f:z: y f (x f z)) ) SUB (x:y: (f:z: (y PRE x) f z)) MUL (x:y:f:z: y (x f) z ) DIV (Y (d:c:x:y: IF (ZERO x) 0 ( IF (ZERO (y PRE x)) (SUC c) (d (SUC c) (y PRE x) y) ) ) ) 0 EQ (x:y: AND (ZERO (x PRE y)) (ZERO (y PRE x)) ) MIN (x:y: IF (ZERO (x PRE y)) y x ) MAX (x:y: IF (ZERO (x PRE y)) x y ) More Numerals is odd (n: (n NOT FALSE)) As a side note, here\u0026rsquo;s a recursive method for checking odd/even numbers (looks interesting, fresher than familiar mod 2):\nisEven :: Int -\u0026gt; Bool isEven 0 = True isEven x = isOdd (x-1) isOdd :: Int -\u0026gt; Bool isOdd 0 = False isOdd x = isEven (x-1) increasing list Tail recursive:\n(Y (f:c:n: IF (ZERO n) (PAIR 0 c) (f (PAIR n c) (PRE n)) ) ) FALSE Non-tail recursive:\n(n: REVERSE ( (Y (f:x: IF (ZERO x) (PAIR 0 FALSE) (PAIR x (f (PRE x)))) ) n ) ) decomposition Decompose given number into sum of powers of 2:\n(Y (f:c:k:n: IF (ZERO n) c (IF (AND (EQ n (MIN k n)) (NOT (EQ k n))) (f c (DIV k 2) n) (f (PAIR k c) (DIV k 2) (SUB n k) ) ) ) ) FALSE 8 * primes and sort both need significant runtime (local tests show around 30min each level)\nprimes Y (f:l:p:n: IF (EQ n (FST p)) (PAIR n l) (IF (EQ (FST p) (MAX n (FST p))) (f l (SND p) n) ( IF ( (Y (f:n:p: IF (EQ n (MIN n p) ) (IF (EQ n p) TRUE FALSE ) (f (SUB n p) p) ) ) n (FST p) ) (f (PAIR (FST p) l) p (DIV n (FST p))) (f l (SND p) n) ) ) ) FALSE (PAIR 47 (PAIR 43 (PAIR 41 (PAIR 37 (PAIR 31 (PAIR 29 (PAIR 23 (PAIR 19 (PAIR 17 (PAIR 13 (PAIR 11 (PAIR 7 (PAIR 3 (PAIR 2 FALSE)))))))))))))) sort Selection sort:\nY (f:c:l: IF (EMPTY l) c ( (m: (f (PAIR m c) (FILTER l (x: NOT (EQ x m)) )) ) (ACC l MAX 0) ) ) FALSE trees NODE l:v:r:f: f l v r LEF t: t (l:v:r: l) RIG t: t (l:v:r: r) VAL t: t (l:v:r: v) BEMPTY Similar to checking empty list. Non-empty trees have the form of NODE l v r = f: f l v r,and empty tree is represented by FALSE := a:b: b. Using a tree t as a function: if empty tree, t A B = FALSE A B = B ~·¥áx·¥ò·¥á·¥Ñ·¥õ·¥á·¥Ö‚Üí TRUE, if non-empty t A B = (f: f l v r) A B = A l v r B ~·¥áx·¥ò·¥á·¥Ñ·¥õ·¥á·¥Ö‚Üí FALSE. Thus with B = TRUE, A = l:v:r:x: FALSE:\n(t: t (l:v:r:x: FALSE) TRUE ) FIND Check if tree t contains node with value v:\nY (f:t:v: IF (BEMPTY t) FALSE (IF (EQ (VAL t) v) TRUE (OR (f (LEF t) v) (f (RIG t) v)) ) ) BSIZE Calculate tree size:\nY (f:t: IF (BEMPTY t) 0 (SUC (ADD (f (LEF t)) (f (RIG t)))) ) BUILD Binary search tree construction:\nY (f:c:l: IF (EMPTY l) c ( f ( ( Y (f:v:t: IF (BEMPTY t) (NODE FALSE v FALSE) ( IF (EQ v (MIN v (VAL t))) (NODE (f v (LEF t)) (VAL t) (RIG t)) (NODE (LEF t) (VAL t) (f v (RIG t))) ) ) ) (FST l) c) (SND l) ) ) FALSE [ Seems like PREORDER and INORDER functions are swapped in the game? ]\nPREORDER Inorder traversal of binary tree:\nY (f:t: IF (BEMPTY t) FALSE (CONCAT (f (LEF t)) (PUSH (VAL t) (f (RIG t)) ) ) ) INORDER Preorder traversal of binary tree:\nY (f:t: IF (BEMPTY t) FALSE (PUSH (VAL t) (CONCAT (f (LEF t)) (f (RIG t)) ) ) ) SPLIT Split tree t using value v as boundary:\nY (f:t:v: IF (BEMPTY t) (PAIR FALSE FALSE) ( IF (EQ v (MAX v (VAL t))) ( (p: PAIR (NODE (LEF t) (VAL t) (FST p)) (SND p)) (f (RIG t) v) ) ( (p: (PAIR (FST p) (NODE (SND p) (VAL t) (RIG t) ))) (f (LEF t) v) ) ) ) KTH Find kth largest element in given binary search tree by getting kth item from inorder traversal list:\n(t:k: Y (f:c:l: IF (EQ c 0) (FST l) (f (PRE c) (SND l) ) ) k (PREORDER t) ) inverse 6 For given binary search tree t, find missing numbers from [1..6] in ascending order:\nt: IF (BEMPTY t) (PAIR 1 (PAIR 2 (PAIR 3 (PAIR 4 (PAIR 5 (PAIR 6 FALSE)))))) ( Y (f:c:m:n: IF (EMPTY n) (REVERSE c) ( IF (EQ (FST m) (FST n)) (f c (SND m) (SND n)) (f (PAIR (FST n) c) m (SND n)) ) ) FALSE (PREORDER t) (PAIR 1 (PAIR 2 (PAIR 3 (PAIR 4 (PAIR 5 (PAIR 6 FALSE)))))) ) ","date":"2025-02-02T21:29:00+08:00","permalink":"http://fyshxfish.github.io/p/basic-lambda-calculus-programming/","title":"Basic Lambda Calculus Programming"},{"content":"-Inspired by Algorithm Design and Analysis course, 2024 Fall-\nIntroduction In this semester\u0026rsquo;s algorithms course, we focused on two major categories of search algorithms: backtracking and branch-and-bound. Previously, I always treated various search algorithms like DFS and BFS separately, comparing their differences. In this article, I aim to abstract search algorithms, expecting to derive familiar search strategies from a concise abstract model.\nAbstracting the Search Model and Process Here\u0026rsquo;s the model I\u0026rsquo;ve summarized, demonstrated in Haskell:\nclass (Ord node) =\u0026gt; Search env node where initN :: env -\u0026gt; node check :: env -\u0026gt; node -\u0026gt; Bool child :: env -\u0026gt; node -\u0026gt; [node] search :: env -\u0026gt; node Search env node: A search requires two elements: the search environment env and the search node node. Since we need to determine the expansion order based on the priority of node, we want node to be orderable, hence the Ord constraint. initN :: env -\u0026gt; node: A search needs initialization. The search tree requires a root node, so we want to generate a simple root node from the search environment env. check :: env -\u0026gt; node -\u0026gt; Bool: A search needs a stopping condition. We need a function to determine if the current node is a solution based on the properties of env. child :: env -\u0026gt; node -\u0026gt; [node]: A search needs to continue. The live nodes of the search tree are expandable, so we need a function child to generate a list of child nodes [node] based on env and the current node. search :: env -\u0026gt; node: The main search function. Its goal is to search within the environment env and eventually return the terminal node node, which is the optimal solution we seek. To implement a search algorithm for a specific problem, we need to define the abstraction of the search environment env, design the node node, and implement the above functions: initN, check, child, and search.\nThe search model can be abstracted, and so can the search process. Therefore, I provide a default implementation of the search function (since initN, check, and child are often strongly tied to the specific problem and need to be provided during instantiation, they cannot rely on default implementations). This function abstracts the basic search process‚Äîstarting from the root node (initN), checking (check) if the highest-priority node is a solution, returning it if true, otherwise expanding (child) its child nodes, reordering the live node list based on priority, and repeating this process:\nsearch e = let step :: [node] -\u0026gt; node step (n:ns) | check e n = n | otherwise = step $ sort (ns ++ child e n) in step [initN e] Example: Instantiating the TSP Search from the Model Search Environment: The directed weighted graph Graph is abstracted as follows:\ntype Vertex = Int type Distance = Int type Edge = (Vertex, Vertex, Distance) data Graph = Graph { vertices :: [Vertex], edges :: [Edge] } Additionally, the search process relies on graph functions like minOut and distance:\nminOut :: Graph -\u0026gt; [(Vertex, Distance)] minOut (Graph vs es) = [ (v, minimum ds) | v \u0026lt;- vs, let es\u0026#39; = filter (\\(v1, _, _) -\u0026gt; v1 == v) es, let ds = [ d | (_, _, d) \u0026lt;- es\u0026#39;]] distance :: Graph -\u0026gt; (Int, Int) -\u0026gt; Maybe Distance distance (Graph _ []) _ = Nothing distance (Graph vs ((v1, v2, d):es)) (s, t) | s == v1 \u0026amp;\u0026amp; t == v2 = Just d | otherwise = distance (Graph vs es) (s, t) Node Design (TspNode):\nA node needs to store the current cost, the list of visited vertices, and the heuristic value (upper bound of the total cost):\ndata TspNode = TspNode { cost :: Int, visited :: [Vertex], -- reverse heuristic :: Int -- heuristic / priority } deriving (Show) The lower the heuristic value of a node, the higher its expansion priority.\ninstance Ord TspNode where compare :: TspNode -\u0026gt; TspNode -\u0026gt; Ordering compare n1 n2 | heuristic n1 \u0026gt; heuristic n2 = GT | heuristic n1 \u0026lt; heuristic n2 = LT | otherwise = EQ Search Function Instantiation:\nTo make Graph TspNode an instance of the Search type class, we can use the default search implementation. However, we still need to implement the initN, check, and child functions:\ninitN:\nThe root node\u0026rsquo;s cost is 0, the visited list is empty, and the heuristic value is irrelevant since the root node will always be the first to be checked and removed from the live node list, never participating in sorting. Thus, heuristic can be set to 0:\ninitN :: Graph -\u0026gt; TspNode initN _ = TspNode 0 [] 0 If the current node has visited all vertices (starting from the origin, traversing a loop, and returning to the origin), then it is considered a solution:\ncheck :: Graph -\u0026gt; TspNode -\u0026gt; Bool check g (TspNode _ vs _) | length vs == length (vertices g) = True | otherwise = False child:\nBased on the visited list, calculate unvisited adjacent nodes. If all other vertices have been visited, attempt to return to the origin:\nchild :: Graph -\u0026gt; TspNode -\u0026gt; [TspNode] child g n = let upBound :: [Vertex] -\u0026gt; Int upBound vs = sum [ d | (s,d) \u0026lt;- minOut g , s `notElem` vs ] at = if null (visited n) then 0 else head (visited n) -- then-clause only for initNode nodes = [TspNode cost\u0026#39; visited\u0026#39; heuristic\u0026#39; | v \u0026lt;- filter (\\v\u0026#39; -\u0026gt; v\u0026#39; `notElem` visited n \u0026amp;\u0026amp; isJust (distance g (at, v\u0026#39;))) -- or abstract this function to `checkChildValid` ((tail . vertices) g), -- `tail` for drop the origin vertex (0 here) let way = fromJust $ distance g (at, v), let cost\u0026#39; = cost n + way, let visited\u0026#39; = v: visited n, let heuristic\u0026#39; = upBound visited\u0026#39; + cost\u0026#39;] back = case distance g (at, 0) of Just wayback -\u0026gt; let cost\u0026#39; = cost n + wayback visited\u0026#39; = 0: visited n heuristic\u0026#39; = cost\u0026#39; in [TspNode cost\u0026#39; visited\u0026#39; heuristic\u0026#39;] Nothing -\u0026gt; [] in if length (visited n) == length (vertices g) - 1 then back else nodes Overall Program Framework:\nBrief Description of Other Instances We can also represent DFS and BFS using this model. In data structure courses, we often use recursion for DFS and queues + iteration for BFS. In this model, changing the priority criteria of nodes changes the strategy for selecting nodes to expand, thereby altering the search behavior.\nAssume we have a node like this:\ndata Node a = Node { info :: a, -- Problem-specific node information level :: Int, -- The level of the node in the search tree order :: Int -- The order in which the node was generated } DFS always expands the deepest live node in the current search tree. To perform depth-first search in any search environment using this node, the priority should be set to level:\ninstance Ord (Node a) where compare :: Node a -\u0026gt; Node a -\u0026gt; Ordering compare n1 n2 | level n1 \u0026gt; level n2 = LT -- DEPTH first | level n1 \u0026lt; level n2 = LT | otherwise = EQ BFS always expands the earliest generated live node in the current search tree. To perform breadth-first search in any search environment using this node, the priority should be set to order:\ninstance Ord (Node a) where compare :: Node a -\u0026gt; Node a -\u0026gt; Ordering compare n1 n2 | order n1 \u0026gt; order n2 = LT -- BREADTH first | order n1 \u0026lt; order n2 = LT | otherwise = EQ Limitations Lack of Application to More Specific Problems:\nI initially planned to implement classic textbook cases using this model, but‚Äîtime ran out. The deadline is approaching, so I only provided the instantiation of the TSP problem under this model.\nNumber of Solutions:\nHere, I limited the number of solutions to 1, defaulting to the first solution as the problem\u0026rsquo;s solution. This is effective in some cases, such as the TSP problem implemented here, where the heuristic calculation ensures the first solution is the optimal one. However, there may be other scenarios: (a) the first solution is only an approximation of the optimal solution, which may be found later, or (b) multiple solutions need to be retained. These cases are not handled by the current model.\n","date":"2024-11-24T12:09:00+08:00","permalink":"http://fyshxfish.github.io/p/abstractions-for-search-algorithms/","title":"Abstractions for Search Algorithms"},{"content":"This blog post provides supplementary material for the proof section of Lambda-Calculus and Combinator ¬ß 4C Theorem 4.20, the overall intention of the proof is to prove that total recursive functions conforming to Definition 4.18 can be represented using combinators. Here we briefly explain the key part of this proof - the construction of the iteration combinator. This can also be understood as: Writing an iterative program with specific termination conditions in Pure Lambda Calculus.\nRecursion and Iteration: In constructing the $R_{\\text{Bernays}}$ recursive combinator, to solve for the value $\\phi(n)$ of some recursive function $\\phi$, one feasible method is to start from $\\phi(0)$ and iterate $n$ times to get $\\phi(n)$ (roughly as follows: denoting the recursive step update function as $\\chi$, $\\phi(n) = \\chi^n \\phi(0)$). Iteration and recursion differ in forward versus reverse direction. The \u0026ldquo;recursion\u0026rdquo; in this article aims to describe the structural characteristic of \u0026ldquo;self-calling\u0026rdquo;, while the central focus is on solving iteration problems ($0 \\rightarrow 1 \\rightarrow \u0026hellip; \\rightarrow n$).\nConstruction Goal Assuming we have a check function $X$, with iteration termination condition $XY=_{\\beta,w}\\bar{0}$, we want to construct a combinator $P$ to obtain the minimal $Y$ satisfying the termination condition. Starting from $Y = \\bar{0}$, check if $(XY) =_{\\beta,w} \\bar{0}$. If the condition is met, return this $Y$, otherwise continue checking $X(\\bar{\\sigma}Y)$. We want to construct a combinator $P$ to automate this checking process. Formally, we expect $P$ to behave as follows:\n$$ PXY =_{\\beta,w}Y \\quad \\text{, if } XY = _{\\beta,w}\\bar{0};$$\n$$ PXY =_{\\beta,w}PX(\\bar{\\sigma}Y), \\text{ otherwise} $$\nFully respecting expectations, write a $P$ combinator: $\\textcolor{red}{P} \\equiv \\lambda xy.\\textbf{D}y(\\textcolor{red}{P}x(\\bar{\\sigma}y))(xy)$, where $\\textbf{D}=\\lambda xyz.z(\\textbf{K}y)x$. We can use the $\\textbf{Y}$ combinator to fix this $P$ ($P \\equiv \\textbf{Y}(\\lambda pxy.\\textbf{D}y(px(\\bar{\\sigma}y))(xy))$). The $P$ solved using the $\\textbf{Y}$ combinator has no normal form. We won\u0026rsquo;t use this $P$ here; instead, we\u0026rsquo;ll try to construct a $P$ combinator with normal.\nConstruction Process Basic Structure Express the existing $P$ in high-level language pseudocode:\ncombinator p(x,y): // L1: define p if (xy == 0): return const(y) else: return p(x, œÉ y) // L5: call p Recursive $\\lambda$, like $P \\equiv \\lambda x. MPN$, matches our experience in high-level language programming but doesn\u0026rsquo;t conform to Lambda Calculus rules, as Lambda Calculus\u0026rsquo;s inductive definition of $\\lambda$-terms doesn\u0026rsquo;t include rules for assigning identifiers to abstractions. We write identifiers like $P$ only to improve readability and clarify expression structure, not to define recursive functions through identifier reuse like in high-level languages. A detail worth noting is that the symbol we see in books for recording identifiers for $\\lambda$-terms is $\\equiv$ rather than $=$.\nThe fact that we can\u0026rsquo;t define recursion through identifier reuse doesn\u0026rsquo;t mean we can\u0026rsquo;t define recursion at all - we just need to rely on an additional layer of abstraction to construct something that is formally non-recursive but effectively recursive.\nFrom a high-level programming perspective, if we want to replace the call to p itself in L5, we can modify our code as follows. For consistency between branches, we design a function list t where two functions correspond to two branches - function getCurrentY will return the current y value, and recursion_p will handle recursion: (Let\u0026rsquo;s not worry about specific function structure and parameter design/passing yet, we\u0026rsquo;ll figure that out later, here we only care about the overall structure)\nt = [getCurrentY, recursion_p] // list of functions combinator p(x,y): if (xy == 0): return t[0] else: return t[1] How do we express this code in Lambda Calculus? To focus on our current level of abstraction, let\u0026rsquo;s first simplify the structure of $P \\equiv \\lambda xy.\\textbf{D}y(Px(\\bar{\\sigma}y))(xy)$ to $P \\equiv \\lambda xy.\\textbf{D}AB(xy)$\nBased on expectations/above pseudocode, we can write out the rough $\\lambda$ framework as follows:\n$$ P \\equiv \\lambda xy. T(xy)[params] $$ $$ T \\equiv \\textbf{D}AB $$ $$ A \\equiv \\lambda [params]. \\dots$$ $$ B \\equiv \\lambda [params]. \u0026hellip;$$\nNow $PXY = _{\\beta,w} T(XY) $, $ XY = _{\\beta, w} \\bar{0} \\longrightarrow PXY = A; XY \\neq _{\\beta, w} \\bar{0} \\longrightarrow PXY = B $ .\nWe expect to put branch-specific logic in $T$, and put branch selection and branch function parameter passing in $P$.\nSpecific Details We ignored many details above, now it\u0026rsquo;s time to consider them :)\nFirst note a fact: putting branch function parameter passing work in $P$ means that regardless of which branch the current $P$\u0026rsquo;s $(xy)$ will lead to, our parameter list must be consistent / can only be consistent. Since the case corresponding to $(xy) = _{\\beta,w}\\bar{0}$ is simpler, only needing to return the current $y$, we\u0026rsquo;ll consider it later and focus on the $(xy) \\neq _{\\beta,w}\\bar{0}$ case first, letting the former accommodate the latter (since both branches relate to $y$, the parameter list must include $y$ - this is a commonality between branches; moreover, we can even pass all parameters corresponding to both branch functions, then in specific implementations of $A$,$B$ not bind parameters irrelevant to that branch).\nConstructing the Recursive (Iterative) Branch Goal: $XY \\neq _{\\beta, w} \\bar{0} \\longrightarrow PXY = B \\xlongequal{\\text{expected}} PX(\\bar{\\sigma}Y) $. We want the $\\lambda$-term resulting from applying function $\\underline{B}$ with $[\\underline{params}]$ passed in $\\underline{P}$ to have the same structure as $\\underline{PXY}$ (note this is not that $B$ and $P$ abstractions themselves having the same structure), just with $Y$ replaced by $(\\bar{\\sigma}Y)$. To get the same structure as $P$, the simplest method is to pass $P$\u0026rsquo;s existing components as $[params]$ to $B$ (and also to $A$), then reassemble these components in $B$ to form $P$\u0026rsquo;s structure:\n$$ P \\equiv \\lambda xy. T(xy)Txy $$ $$ T \\equiv \\textbf{D}AB $$ $$ A \\equiv \\lambda tuv. \\dots$$ $$ B \\equiv \\lambda tuv. q(uv) $$\n($ T \\mapsto t, x \\mapsto u, y \\mapsto v$)\nDue to $[params]$ passing, $P$\u0026rsquo;s structure has changed, so we need to synchronize $B$ with the new $P$ structure; additionally, we need to change the passed-in $y$ (bound by $v$) to $\\bar{\\sigma}y$ inside $B$:\n$$ P \\equiv \\lambda xy. T(xy)Txy $$ $$ T \\equiv \\textbf{D}AB $$ $$ A \\equiv \\lambda tuv. \\dots$$ $$ B \\equiv \\lambda tuv. q(u(\\bar{\\sigma}v))qu(\\bar{\\sigma}v) $$\nLet\u0026rsquo;s check: when $XY \\neq _{\\beta, w} \\bar{0}$:\n$ \\quad PXY $ $ = _{\\beta,w} T(XY)TXY $ $ = _{\\beta,w} BTXY $ $ = _{\\beta,w} T(X(\\bar{\\sigma}Y))TX(\\bar{\\sigma}Y) $ $ = _{\\beta,w} PX(\\bar{\\sigma}Y) $ This matches our expectations, completing the iteration branch construction.\nConstructing the Iteration Termination Branch Goal: $XY = _{\\beta, w} \\bar{0} \\longrightarrow PXY = A \\xlongequal{\\text{expected}} Y $. During $B$\u0026rsquo;s construction, our existing parameter list is $ t \\mapsto T, u \\mapsto x, v \\mapsto y$. In $A$, we just need to extract $y$, so $A = \\lambda tuv.v$. If you want to stay consistent with Definition 4.8\u0026rsquo;s notation, then $A = \\Pi^3_3$.\nComplete $\\lambda$ $$ P \\equiv \\lambda xy. T(xy)Txy $$ $$ T \\equiv \\textbf{D}AB $$ $$ A \\equiv \\lambda tuv. v (= _{\\beta,w} \\Pi^3_3) $$ $$ B \\equiv \\lambda tuv. q(u(\\bar{\\sigma}v))qu(\\bar{\\sigma}v) $$\nBrief Note on $P$ in LCaC Theorem 4.20 The definition of $P$ given in LCaC Theorem 4.20 is:\n$$ T \\equiv \\lambda x.\\textbf{D}\\bar{0}(\\lambda uv.u(x(\\bar{\\sigma}v))u(\\bar{\\sigma}v)) $$ $$ P \\equiv \\lambda xy.Tx(xy)(Tx)y $$\nRewritten in format consistent with above:\n$$ P \\equiv \\lambda xy.Tx(xy)(Tx)y $$ $$ T \\equiv \\lambda x.\\textbf{D}AB $$ $$ A \\equiv \\bar{0} $$ $$ B \\equiv \\lambda uv.u(x(\\bar{\\sigma}v))u(\\bar{\\sigma}v) $$\nTreating $(Tx)$ as a whole at times makes the expression more concise, while letting $x$ and $T$ have a binding relationship ($T \\equiv \\lambda x\u0026hellip;.$) - still allowing separate use of $x$ inside $T$; the closure of $(Tx)$ in $P$ makes the parameter passing form $B(Tx)y$ - rather than $BTxy$ - making $A$\u0026rsquo;s design more concise with $A \\equiv \\bar{0}$.\nThough there are slight differences in details, the overall structure is consistent with the $P$ given in this article.\nOther Try expanding the above $P$:\n$$ \\lambda xy.\\lambda x.\\textbf{D}\\bar{0}(\\lambda uv.u(x(\\bar{\\sigma}v))u(\\bar{\\sigma}v))x(xy)(\\lambda x.\\textbf{D}\\bar{0}(\\lambda uv.u(x(\\bar{\\sigma}v))u(\\bar{\\sigma}v))x)y$$\nIf you\u0026rsquo;re willing to expand all of these too: $ \\textbf{D} = _{\\beta, w} \\lambda xyz.z(\\textbf{K}y)x, \\quad \\textbf{K} = _{\\beta, w} \\lambda xy.x $ $ \\bar{0} = _{\\beta, w} \\lambda xy.y $ $ \\bar{\\sigma} = _{\\beta, w} \\lambda nfz. f (n f z)$ $$ \\lambda xy.\\lambda x.(\\lambda xyz.z((\\lambda xy.x)y)x)(\\lambda xy.y)(\\lambda uv.u(x(\\lambda nfz. f (n f z)))u(\\lambda nfz. f (n f z)))x(xy)(\\lambda x.(\\lambda xyz.z((\\lambda xy.x)y)x)(\\lambda xy.y)(\\lambda uv.u(x(\\lambda nfz. f (n f z)))u(\\lambda nfz. f (n f z)))x)y$$\nWe can say that we\u0026rsquo;ve completed the construction of an iterative program using this pile of symbols + Pure Lambda Calculus computation rules - Programming in Pure Lambda Calculus., great!\n","date":"2024-09-17T23:48:00+08:00","permalink":"http://fyshxfish.github.io/p/the-construction-of-the-iteration-combinator-lcac-4c-theorem-4.20/","title":"The Construction of the Iteration Combinator - LCaC ¬ß 4C, Theorem 4.20"},{"content":"Motivation: Abstraction Level Up! Apply square 3 times to 2\n1 ]=\u0026gt; (square (square (square 2))) ;Value: 256 2 ‚Üí x: Apply square 3 times to some number x, use lambda to abstract 2 to x\n(define square3 (lambda (x) (square (square (square x))))) square ‚Üí f: Apply some function f 3 times to some value x, similarly, use lambda to abstract square to f\n(define three_times_f (lambda (f x) (f (f (f x))))) $3 ‚Üí i$ : Apply some function f to value x for $i$ times $(i \\in \\mathbb{N})$\n$i=0$\n(define zero_time_f (lambda (f x) (x))) $i=1$\n(define one_time_f (lambda (f x) (f x))) $i=2$\n(define two_times_f (lambda (f x) (f (f x)))) Recursive definition of $i$ applications\nBase case:\n(define zero_time_f (lambda (f x) (x))) Recursive step:\n(define (succ z) (lambda (f x) (f (z f x)))) Recursively solve for $i$ applications corresponding to $i$:\n(define (church i) (if (= i 0) zero_time_f (succ (church (- i 1))) ) ) This is the Church Encoding corresponding to natural number $i$.\nA simple test in REPL: Apply cube 2 times to 3 $((3^3)^3=19683)$\n1 ]=\u0026gt; (church 2) ;Value: #[compound-procedure 15] 1 ]=\u0026gt; ( #[compound-procedure 15] cube 3) ;Value: 19683 Understanding Church Encoding Church Encoding is NOT:\nNumbers that target to be stored in physical memory or represented in bits\nDesigned for arithmetic operations (like $3.14 √ó 2.17$)\nChurch Encoding is:\nAn abstraction of counting Church Encoding is an abstraction of the counting process. In the context of Lambda Calculus, the three rules for inductively defining $Œª-terms$ involve $atom$, $abstraction$, and $application$. Church Encoding can be understood as: given an initial $term$ and an $abstraction$, we want to apply this $abstraction$ to the $atom$ multiple times ($apply$). We use a higher-level $abstraction$ to abstract the process of counting these \u0026ldquo;multiple times\u0026rdquo;, and this layer of abstraction for the counting process is Church Encoding.\nChurch Encoding in Scheme $zeroÔºöŒªf.Œªx.x$\nApplying any $abstraction$ 0 times to a $term$ returns the original $term$.\n(define zero (lambda (f x) x)) $oneÔºöŒªf.Œªx.(f‚Äâx)$ $twoÔºöŒªf.Œªx.(f‚Äâ(f‚Äâx))$ $three: Œªf.Œªx.(f‚Äâ(f‚Äâ(f‚Äâx)))$\n(define one (lambda (f x) (f x))) (define two (lambda (f x) (f (f x)))) (define thr (lambda (f x) (f (f (f x))))) When writing thr, we notice the recursive structure. The base case is clearly zero, and the recursive step succ is as follows:\n(define (succ z) (lambda (f x) (f (z f x))) ) Application Examples Church Encoding is an abstraction of counting. If we want to square (square) the number 2 three times: $((2^2)^2)^2=256$\n1 ]=\u0026gt; (thr square 2) ;Value: 256 Verify the correctness of succ:\n1 ]=\u0026gt; (succ (succ (succ zero))) ;Value: #[compound-procedure 17] 1 ]=\u0026gt; (#[compound-procedure 17] square 2) ;Value: 256 References Church Encoding wiki\nTypes and Programming Languages, Chapter 5 The Untyped Lambda-Calculus\nA Zhihu answer\n","date":"2024-09-08T20:13:00+08:00","permalink":"http://fyshxfish.github.io/p/church-encoding-note/","title":"Church Encoding Note"},{"content":"Introduction SICP ¬ß 2.4.3 describes a generic system implemented using table lookup (type √ó operation two-dimensional table), where concrete functions are hidden under abstractions like \u0026ldquo;generic function + Selector\u0026rdquo;. What would it look like if we put concrete functions under \u0026ldquo;data + Selector\u0026rdquo; abstractions? This article presents a Boolean implementation that conforms to this abstraction (called Message Passing in SICP). The importance of data and functions in programming is self-evident. Let\u0026rsquo;s explore three perspectives on the possible relationships between data and functions: Message Passing ‚Ü¶ letting data carry its own functions; $ in Haskell ‚Ü¶ transforming data into functions; Algebraic data types in Haskell ‚Ü¶ constructing data using functions.\nGeneric Functions: Intelligent Operations In section 2.4.3, the author builds a generic system. What is generics? It\u0026rsquo;s a form of abstraction. For several types that share certain characteristics, if we can write a function for one type based on this characteristic, we want to extend this function to other types with the same characteristic. For example: for two Int values, I can calculate their maximum (max Int Int) because Int is Orderable, meaning the Int type provides implementations of comparison functions like \u0026gt; / \u0026lt; / etc. For other orderable types (those that provide comparison function implementations), we want to extend max to these types:\nmax :: (Ord a) =\u0026gt; a -\u0026gt; a -\u0026gt; a max x y = if x \u0026gt;= y then x else y We abstract the orderable characteristic into the Ord typeclass, and the max function can work with any member type of typeclass.\nWhen we apply the max function to a specific Ord class type, the compiler helps us find the concrete implementation of \u0026gt;= for that type.\nSo how to find it? One answer is: table lookup. When I need to execute max (operation) on Float (type), I can find the function (the non-generic concrete implementation of max for Float) corresponding to (Float, max) in the Cartesian product of type √ó operation.\nSICP Page 252: Generics breaks down the type √ó operation table row by row, with each generic function corresponding to one row. ‚ú®\nData and Functions Intelligent Operation? WHAT IF Intelligent Data Objects? In generic functions mentioned in the previous section, data exists as an object to be operated on. Data\u0026rsquo;s job is to be acted upon by functions. Our generics target functions (operations). In our expectation, we want functions to be \u0026ldquo;smart\u0026rdquo;. For example, max :: (Ord a) =\u0026gt; a -\u0026gt; a -\u0026gt; a is smart - it can \u0026ldquo;automatically\u0026rdquo; transform into the corresponding non-generic concrete implementation max :: Int -\u0026gt; Int -\u0026gt; Int for its specific type. Data just needs to wait to be acted upon.\nùêñùê°ùêöùê≠ ùê¢ùêü: Instead of letting generic functions find concrete implementations for data ‚Üí let data find concrete implementations for functions? From the perspective of decomposing the type √ó operation table, what if we break this table into columns, letting certain form of data (corresponding to generic operations, let\u0026rsquo;s call it generic? data) represent a column?\nThis was already presented in SICP 2.1.3 when discussing compound data extraction, and was mentioned in my previous blog post. The focus in SICP 2.1.3 was on operations on compound data itself (extracting fields): to ensure consistency before and after list element access, we provide the list as a procedure that accepts parameters and returns corresponding list elements based on those parameters.\nHere we care about how data behaves in programs - how data interacts with functions and other data. We want data to carry its own interaction methods rather than being static entities that can only be acted upon by other functions. Based on this idea, let\u0026rsquo;s try to write a Boolean that follows this behavioral specification.\nBoolean Carrying Functions First, let\u0026rsquo;s present a similar type √ó operation two-dimensional table. Since we\u0026rsquo;re doing simple modeling, we\u0026rsquo;ll only consider two operations - AND (logic_and) and OR (logic_or):\nSimilar to generic functions representing rows, we write \u0026ldquo;data\u0026rdquo; that can represent columns. The identifiers for TRUE and FALSE columns are tru and fls respectively. How to make data carry functions? One answer is to make the data itself a function that can accept parameters, using parameters to extract the functions carried by the data:\n(define tru ; (define tru (lambda ...)) (lambda (op) (cond ((eq? op \u0026#39;and) tru_logic_and) ((eq? op \u0026#39;or) tru_logic_or) ) ) ) (define fls ; (define fls (lambda ...)) (lambda (op) (cond ((eq? op \u0026#39;and) fls_logic_and) ((eq? op \u0026#39;or) fls_logic_or) ) ) ) The functions corresponding to lambda - cond (curried logical AND and OR) are implemented as follows:\n(define (tru_logic_and x) (if (eq? x tru) tru fls)) ; 1 AND x (define (tru_logic_or x) tru) ; 1 OR _ = 1 (define (fls_logic_and x) fls) ; 0 AND _ = 0 (define (fls_logic_or x) (if (eq? x tru) tru fls)) ; 0 OR x Checking tru fls in REPL: unsurprisingly both are compound procedures\n1 ]=\u0026gt; tru ;Value: #[compound-procedure 13 tru] 1 ]=\u0026gt; fls ;Value: #[compound-procedure 12 fls] Let\u0026rsquo;s do a simple test:\n1 ]=\u0026gt; ((tru \u0026#39;and) fls) ;Value: #[compound-procedure 12 fls] What did we do here? First, tru is a lambda expression that accepts symbol parameters. (tru 'and) returns tru_logic_and \u0026ndash; a curried logical AND (that is, logical AND with TRUE already passed in), then we apply tru_logic_and to fls, and the final return value is the compound procedure fls.\nHere\u0026rsquo;s an illustration:\nFor longer expressions: if we ignore some parentheses, it looks like infix logical expressions\n1 ]=\u0026gt; ((((fls \u0026#39;or) tru) \u0026#39;and) fls) ; ((0 or 1) and 0) ;Value: #[compound-procedure 12 fls] If you prefer prefix calls, we can add a small wrapper:\n(define (logic op x y) ((x op) y)) Testing logic:\n1 ]=\u0026gt; (logic \u0026#39;and tru fls) ;Value: #[compound-procedure 12 fls] 1 ]=\u0026gt; (logic \u0026#39;or (logic \u0026#39;and fls fls) tru) ; (or (and 0 0) 1) ;Value: #[compound-procedure 13 tru] ‚Üí Message Passing: Another Perspective on Data This style of building Boolean is called Message Passing: data is an entity that receives operation names (messages). For example: tru can receive messages like 'and / 'or and return corresponding curried functions for our subsequent use. From this perspective, the data itself is as important as the methods carried by the data, which is also a manifestation of \u0026ldquo;data as program\u0026rdquo;. You might notice a hint of object-oriented flavor here - objects are essentially \u0026ldquo;state + methods\u0026rdquo;, and here data contains \u0026ldquo;state + functions\u0026rdquo;, though the state here is immutable.\n$ in Haskell $ is an infix function with the following type signature and precedence. Its purpose is to change expression evaluation order, and one objective result is that using $ reduces the number of parentheses in code:\nghci\u0026gt; :i ($) ($) :: (a -\u0026gt; b) -\u0026gt; a -\u0026gt; b -- Defined in \u0026#39;GHC.Base\u0026#39; infixr 0 $ Applying $ (curried) to a value returns a function:\nghci\u0026gt; x = 5 :: Int ghci\u0026gt; :t ($ x) ($ x) :: (Int -\u0026gt; b) -\u0026gt; b One way to understand this is: ($ x) transforms x from static data into data waiting to be acted upon by function Int -\u0026gt; b (which is a function from the type signature). Based on this understanding, we can write code like this:\nghci\u0026gt; map ($ 5) [(* 2), (+ 10), (^ 3)] [10,15,125] Algebraic Data Types in Haskell Here\u0026rsquo;s the classic recursive definition of binary trees using algebraic data types:\ndata Tree a = Empty | Node a (Tree a) (Tree a) Empty and Node are value constructors for Tree a. Value constructors are functions that return values of some type. Empty is a nullary constructor, while Node takes three value parameters: a, Tree a, and Tree a.\nTree a is a type constructor. Type constructors are functions that return specific types. Tree a takes one type parameter a and returns the corresponding concrete Tree type. For example, Tree Int and Tree Char are Tree types with node data types of Int and Char respectively.\nThis shows Haskell\u0026rsquo;s elegant consistency in language design - there\u0026rsquo;s no special generic syntax, just functions throughout.\n","date":"2024-09-07T23:18:00+08:00","permalink":"http://fyshxfish.github.io/p/message-passing-perspective-on-bool-sicp-2.4.3-generic-data-and-functions/","title":"Message Passing Perspective on Bool - SICP ¬ß 2.4.3 | Generic | Data and Functions"},{"content":"Code Here: Huffman Tree in Haskell\nHaskell Implementation of Huffman Trees Data Abstraction type Weight = Int data Symbol = A | B | C | D | E | F | G | H deriving Show data HuffmanTree a = Empty | Leaf a Weight | Node (HuffmanTree a) (HuffmanTree a) [a] Weight deriving Show Symbol + Weight ‚Üí Leaf We encode symbols (Symbol / generic a) based on their frequency/weight (Weight), combining these two pieces of information into a Leaf abstraction, corresponding to SICP\u0026rsquo;s (define (make-leaf symbol weight) (list 'leaf symbol weight)).\nGeneric types and constraints: There are no type constraints on symbols. The weight constraint is that Weight belongs to the Ord typeclass because weights need to be comparable. Here we directly use Int as the weight type instead of making it generic.\nRecursive Definition of HuffmanTree Contains three constructors: Empty, Leaf, and Node:\nEmpty: Empty tree Leaf: Leaf node containing symbol a and weight Weight Node: Branch node containing left and right subtrees (HuffmanTree a), union of subtree symbols [a], and total subtree weight Weight. Building the Huffman Tree Getting Weight Get the weight of LeafÔºåNode through pattern matching.\ngetWeight :: HuffmanTree a -\u0026gt; Weight getWeight (Leaf _ w) = w getWeight (Node _ _ _ w) = w For simplicity, we haven't considered the `Empty` tree case. For better safety, we should write `getWeight :: HuffmanTree a -\u003e Maybe Weight`, returning `Nothing` when matching `Empty`.\nList Organization The starting point for building a Huffman tree is an ordered list of leaves. During construction, the [HuffmanTree a] list needs to maintain order. The functions in this section aim to organize an unordered list into an ordered one.\n¬ª adjoinLeaf: Insert a HuffmanTree a into an existing ordered [HuffmanTree a] based on weight (ascending order).\n¬ª initLeafs: Organize an existing unordered leaf list into an ordered leaf list.\n¬ª moveFirstNode: During Huffman Tree construction, the Merge operation combines the two HuffmanTree (Leaf / Node) with smallest weights‚Äîthe first two elements in the list‚Äîinto a new Node. This function helps reposition the newly generated Node after merging.\nadjoinTree :: HuffmanTree a -\u0026gt; [HuffmanTree a] -\u0026gt; [HuffmanTree a] adjoinTree t [] = [t] adjoinTree t (t\u0026#39;:ts) | w \u0026lt; w\u0026#39; = t: t\u0026#39;: ts | otherwise = t\u0026#39;: (adjoinTree t ts) where w = getWeight t w\u0026#39; = getWeight t\u0026#39; initLeafs :: [HuffmanTree a] -\u0026gt; [HuffmanTree a] -- I know pl(leaf) = leaves, btw. ^^ initLeafs [] = [] initLeafs (p:ps) = adjoinLeaf p (initLeafs ps) moveFirstNode :: [HuffmanTree a] -\u0026gt; [HuffmanTree a] moveFirstNode (t:ts) = adjoinLeaf t ts Tree Construction ¬ª makeNode: Combines two HuffmanTrees into a Node. ¬ª constructHuffTree: Bottom-up tree construction, building the Huffman Tree using tail recursion.\nRecursive step: Merge the first two elements in the current list into a parent Node using makeNode, move the parent node to get a new ordered list, and recursively process the new list.\nBase case: List contains only one element, which is the root node.\n¬ª initAndConstructHuffTree: Final encapsulation, using Point-less composition to combine leaf list initialization initLeafs and tree construction constructHuffTree.\nmakeNode :: HuffmanTree a -\u0026gt; HuffmanTree a -\u0026gt; HuffmanTree a makeNode (Leaf s1 w1) (Leaf s2 w2) = Node (Leaf s1 w1) (Leaf s2 w2) [s1, s2] (w1 + w2) makeNode (Leaf s w) (Node l r ss w\u0026#39;) = Node (Leaf s w) (Node l r ss w\u0026#39;) (s:ss) (w + w\u0026#39;) makeNode (Node l r ss w\u0026#39;) (Leaf s w) = Node (Node l r ss w\u0026#39;) (Leaf s w) (ss ++ [s]) (w + w\u0026#39;) makeNode (Node l1 r1 ss1 w1) (Node l2 r2 ss2 w2) = Node (Node l1 r1 ss1 w1) (Node l2 r2 ss2 w2) (ss1 ++ ss2) (w1 + w2) constructHuffTree :: [HuffmanTree a] -\u0026gt; HuffmanTree a constructHuffTree [] = Empty constructHuffTree [t] = t constructHuffTree (x:y:ts) = constructHuffTree $ moveFirstNode $ (makeNode x y): ts initAndConstructHuffTree :: [HuffmanTree a] -\u0026gt; HuffmanTree a initAndConstructHuffTree = constructHuffTree . initLeafs Huffman Tree Encoding and Decoding Getting Symbol Encoding The process of building a Huffman tree is the encoding process itself. A node\u0026rsquo;s position in the tree represents its encoding. Here we present the encoding in binary form.\nEncoding representation:\ndata Bit = L | R deriving Show type Bits = [Bit] L corresponds to binary 0, R corresponds to binary 1.\nGetting the encoding involves traversing and recording the Huffman tree:\ngetCode\u0026#39; :: HuffmanTree a -\u0026gt; Bits -\u0026gt; [(a, Bits)] getCode\u0026#39; (Node (Leaf s1 _) (Leaf s2 _) _ _) rec = [(s1, rec ++ [L]), (s2, rec ++ [R])] getCode\u0026#39; (Node (Leaf s\u0026#39; _) node _ _) rec = [(s\u0026#39;, rec ++ [L])] ++ getCode\u0026#39; node (rec++[R]) getCode\u0026#39; (Node node (Leaf s\u0026#39; _) _ _) rec = getCode\u0026#39; node (rec++[L]) ++ [(s\u0026#39;, rec ++ [R])] getCode\u0026#39; (Node nodel noder _ _) rec = getCode\u0026#39; nodel (rec++[L]) ++ getCode\u0026#39; noder (rec++[R]) getCode :: HuffmanTree a -\u0026gt; [(a, Bits)] getCode t = getCode\u0026#39; t [] ¬ª getCode': Traverse the Huffman tree Recursively\nRecursive step: For a node, match left and right subtrees, continue recursive traversal for non-leaf nodes (node), recording branch directions in rec.\nBase case: When matching a Leaf in left/right subtree, it indicates reaching a Symbol. At this point, rec ++ [L] / rec ++ [R] is the encoding for that Symbol.\nPattern matching explanation: Reviewing the Huffman tree construction process, we always merge two nodes into their parent node, so there\u0026rsquo;s no case where a subtree is Empty. Therefore, every branch node\u0026rsquo;s pattern is Node lhs rhs _ _. Also, we use Leaf as the base case without recursing on it, which is why we only pattern match different forms of the Node constructor and put the Leaf recursive base cases first.\n¬ª getCodeÔºöWraps getCode', giving rec an initial value of [], meaning no path record at the Huffman tree\u0026rsquo;s root node.\nDecoding Basic approach: Move through the tree based on Bit, L - move to left subtree, R - move to right subtree. When reaching a Leaf subtree, one character is decoded. Then return to the root node to continue decoding the next character until the Bit list is empty.\n-- decode one symbol decodeOne :: HuffmanTree a -\u0026gt; Bits -\u0026gt; (a, Bits) decodeOne (Node (Leaf s _) _ _ _) (L:bs) = (s, bs) decodeOne (Node _ (Leaf s _) _ _) (R:bs) = (s, bs) decodeOne (Node node _ _ _) (L:bs) = decodeOne node bs decodeOne (Node _ node _ _) (R:bs) = decodeOne node bs -- decode from scratch decode :: HuffmanTree a -\u0026gt; Bits -\u0026gt; [a] decode _ [] = [] decode t bs = let (s, remainBits) = decodeOne t bs in s: decode t remainBits ¬ª decodeOne:\nBase case: When the current Bit\u0026rsquo;s corresponding subtree is a Leaf, one character is decoded. Return that character and the remaining Bits.\nRecursive step: When the current Bit\u0026rsquo;s corresponding subtree is a Node, continue recursive decoding on that Node until reaching the base case.\n¬ª decode:\nBase case: Empty Bit list means decoding is complete.\nRecursive step: For non-empty Bit list, pass the root node and current Bit list to decodeOne for single character decoding. After one character is decoded, continue decoding remaining Bits from the root node until the Bit list is empty.\n¬ª How to return to root node:\nInitially, the function signature I wrote was decode :: HuffmanTree a -\u0026gt; HuffmanTree a -\u0026gt; Bits -\u0026gt; [a], with two HuffmanTree parameters representing the original root node and current node. Implementation was roughly:\ndecode\u0026#39; :: HuffmanTree a -\u0026gt; HuffmanTree a -\u0026gt; Bits -\u0026gt; [a] decode\u0026#39; originT (Node (Leaf s _) _ _ _) (L:bs) = s: (decode\u0026#39; originT originT bs) --snip-- This didn\u0026rsquo;t feel quite right since the originT parameter never changed during recursion, so I slightly modified the recursive structure to write the above decode and decodeOne. SICP uses closures to remember the initial root node.\nStructure and Destructure of Compound Data SICP: Data, but Functions? Consistency We want to use structured data‚Äîrather than scattered variables‚Äîas program components, thus we have compound data like struct / class. The question then becomes how to extract the fields used to construct compound data. One thing extraction needs to ensure is consistency of fields before and after extraction. This is mainly the compiler\u0026rsquo;s work, but if we want to demonstrate this at the source code level, how can we do it? SICP 2.1.3 (Page 124) does it this way:\n(define (cons x y) (define (dispatch m) (cond ((= m 0) x) ((= m 1) y) (else (error \u0026#34;Argument not 0 or 1: CONS\u0026#34; m)))) dispatch) (define (car z) (z 0)) (define (cdr z) (z 1)) Exercise 2.4 (Page 125) has an elegant implementation using lambda:\n(define (cons x y) (lambda (m) (m x y))) (define (car z) (z (lambda (p q) p))) ÔºàFor Pure Lambda Calculus implementation of this example, see the last section of this article.Ôºâ\nA key point this chapter of SICP emphasizes is: The boundary between data and procedures isn\u0026rsquo;t so clear-cut. The above two programs demonstrate this precisely: the list constructor returns a procedure that provides an interface to access the elements composing the list, which enables the definition of car / cdr.\nData Combination and Extraction ‚Üí Program Construction: Abstraction Layer Combination in LISP (LISt Programming) can be simple - data is combined by constructing lists, like (list 1 2 3) / (list 3 4 (list 9 7) 5), you can implement pair, tree, etc. with lists.\nHowever, data within programs can\u0026rsquo;t directly flow between functions in this form, so we have abstraction layers:\nConstructor (make-rat) and selector (denom, numer) represent one level of abstraction from primitive data types to compound data, giving programs (functions above this abstraction layer, like add-rat / sub-rat) a higher perspective to view data. Data is no longer just scattered integers/floats, but rat that can be constructed/extracted/analyzed. Functions above add-rat / sub-rat don\u0026rsquo;t need to care about rat\u0026rsquo;s implementation details, they just need to use operations like add-rat to solve problems. The process of program construction is a process of raising abstraction levels.\nHaskell: Pattern Match In Haskell, how do we handle the issue of data construction and extraction?\nConstruction:\nThe syntax for declaring compound data is:\ndata Point = Point Int Int This defines the Point type with a constructor Point Int Int, which can then be used to construct compound data of type Point, like p = Point 1 2.\nExtraction:\nPattern Match\nA simple example:\ngetX :: Point -\u0026gt; Int getX (Point x _) = x Notably: How you construct the compound data (Point Int Int) is how you match it (Point x _). That is‚Äîhow you structure is how you destructure.\nOne advantage of this syntax is that you can parse function parameters through Pattern Matching. For example:\nconstructHuffTree :: [HuffmanTree a] -\u0026gt; HuffmanTree a constructHuffTree [] = ... -- empty leaf list ‚Üí return empty tree constructHuffTree [t] = ... -- only one leaf ‚Üí return tree with just root node constructHuffTree (x:y:ts) = ... -- two or more leaves ‚Üí recursively build Huffman tree This demonstrates that: The way function parameters are destructured determines the function\u0026rsquo;s behavior.\nFor example, consider this problem: counting the number of nodes in a binary tree\ndata Tree a = Empty | Node a (Tree a) (Tree a) treeSize :: Tree a -\u0026gt; Int treeSize Empty = 0 treeSize (Node _ left right) = 1 + treeSize left + treeSize right Empty tree constructed with Empty constructor ‚Üí directly return 0 (base case)\nNon-empty tree constructed with Node constructor ‚Üí solve recursively (recursive step)\nHow we construct data determines how we process it, and in Haskell, the form of constructing data matches the form of pattern matching on data, so we can do pattern matching in function parameter positions, with each pattern corresponding to a function behavior.\nLambda Calculus - pair abstraction pair abstraction in Pure Lambda Calculus ‰∏äThe example mentioned in the Consistencysection can be implemented in pure Lambda Calculus:1Ôºö\npair = Œªm Œªn Œªb. b m n pair v w = Œªb. b v w This abstraction provides this perspective: through two applications of pair, we instantiate m and n, determining the elements contained in the pair, leaving b as an interface for subsequent operations on the pair elements. To extract elements from the pair in order, we can define fst and snd:\nfst = Œªa Œªb. a snd = Œªa Œªb. b (pair v w) fst ‚Üí v // parentheses here can be omitted , according to left associativity convention (pair v w) snd ‚Üí w If you prefer programming style like fst (pair v w), that\u0026rsquo;s also possible:\ntru = Œªt Œªf. t // Œ±-equivalent to `fst` defined in previous code block, we can understand the same abstraction differently fls = Œªt Œªf. f // ... `snd` ... fst = Œªp. p tru snd = Œªp. p fls fst (pair v w) ‚Üí v snd (pair v w) ‚Üí w Let\u0026rsquo;s examine this abstraction again: pair = Œªm Œªn Œªb. b m n. In Lambda Calculus, what we commonly call functions are termed abstractions, and this pair abstraction provides an abstraction over the construction and operation of pairs. We first determine the contained elements through outer parameters m and n to build the pair, then use inner parameter b to execute operations on the existing elements. From this perspective, pair naturally possesses the ability to interact with other functions (abstractions) within the Lambda Calculus system, because after instantiating the pair elements, it provides the interaction interface b, waiting for other abstractions to interact with the pair\u0026rsquo;s existing elements through application.\nTypes and Programming Languages - Chapter 5 The Untyped Lambda-Calculus\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-09-02T01:53:00+08:00","permalink":"http://fyshxfish.github.io/p/huffman-trees-in-haskell-structure-and-destructure-of-compound-data/","title":"Huffman Trees in Haskell | Structure and Destructure of Compound Data"},{"content":"Problem Description Problem: Given a positive integer $n$, find all ordered pairs of distinct positive integers $i$ and $j$, where $ 1 \\leq i \\leq j \\leq n $, such that $ i + j $ is prime.\nImplementation in Haskell isDivisible :: Int -\u0026gt; Int -\u0026gt; Bool isDivisible x y | mod x y == 0 = True | otherwise = False isPrime :: Int -\u0026gt; Bool isPrime x | x \u0026lt;= 2 = True | otherwise = not (foldr (||) False (map (isDivisible x) [2..((floor . sqrt . fromIntegral) x)])) genPairs :: Int -\u0026gt; [((Int, Int), Int)] genPairs n = do x \u0026lt;- [1..n] y \u0026lt;- [1..(x-1)] return ((y, x), (x + y)) sumPrimePairs :: Int -\u0026gt; [((Int, Int), Int)] sumPrimePairs = (filter (\\(_, s) -\u0026gt; (isPrime s))) . genPairs About List Monad: Context, Nested lambda and do-notation Context of List Monad : nondeterministic result.\nThe title of this section is Nested Mappings, represented in code with nested lambdas. In Haskell, do notation is syntactic sugar for nested lambdas.\nAnd flatMap defined in this chapter is actually Haskell \u0026gt;\u0026gt;= (bind) in Haskell.\nFor further details, consult Learn You a Haskell for Great Good: A Fistful of Monads - the List Monad\nAnother Example: The List Monad for Permutation An intuitive way to understand this is that nondeterministic results are well-suited for solving permutations.\npermutations :: Eq a =\u0026gt; [a] -\u0026gt; [[a]] permutations [] = [[]] permutations xs = do x \u0026lt;- xs perm \u0026lt;- permutations $ removeByElem x xs return (x: perm) removeByElem :: Eq a =\u0026gt; a -\u0026gt; [a] -\u0026gt; [a] removeByElem x = filter (/= x) ","date":"2024-08-29T00:00:00+08:00","permalink":"http://fyshxfish.github.io/p/nested-mapping-examples-implemented-in-haskell-sicp-2.2.3-list-monad/","title":"Nested Mapping Examples Implemented in Haskell - SICP ¬ß 2.2.3  | List Monad "},{"content":"Preface Inspiration came from a lecture by Yanyan Jiang: [ÁÆóÊ≥ïÁ´ûËµõÂÖ•Èó®] ‰∏∫‰ªÄ‰πàË¶ÅÈÄºÂ§ßÂÆ∂Áî® NOILinuxÔºü, referenced but not entirely the same.\nMastering this skill will allow you to‚Äîdisplay \u0026ldquo;slides\u0026rdquo; in the terminal. Its practicality is limited, but it‚Äôs fun to play with ¬∑^v^¬∑.\nDemo \u0026#10094; \u0026#10095; Implementation Overall Framework Directory .sh files are bash scripts for displaying a single slide, .md files are the Markdown content to be rendered, and .png files are the images to be displayed.\nLauncher First, print the cover (essentially outputting a page of rendered text in the terminal), then use read to take input and control slide behaviors such as page flipping, image display, exiting, etc.\n0_flow.shÔºö\n#!/bin/bash bash ./1_banner.sh ## print the cover pc=1\t# page counter while true do read -p \u0026#34;:\u0026#34; choice ## take input and control slide behaviors if [ \u0026#34;$choice\u0026#34; == \u0026#34;p\u0026#34; ]; then # previous page ((pc--)) bash ./${pc}* elif [ \u0026#34;$choice\u0026#34; == \u0026#34;g\u0026#34; ]; then # display an image xdg-open ./load_init.png elif [[ $choice =~ ^[1-7]$ ]]; then # go to the specific page pc=$choice bash ./${pc}* elif [ \u0026#34;$choice\u0026#34; == \u0026#34;E\u0026#34; ]; then # exit the script break else # default: next page ((pc++)) bash ./${pc}* fi done Single Page Display Displaying a single page essentially means showing a page of text. The basic steps are:\nClear the previous page\u0026rsquo;s content using clear; Calculate the total number of lines of the rendered text; To center the content vertically, calculate the padding for the top and bottom; Print the top padding, render and print the content text, then print the bottom padding. For example: (2_question.sh)\nclear length=`python3 renderer.py question.md | wc -l` total=`tput lines` sus=$((($total-$length)/2)) for ((i=1; i\u0026lt;=$sus; i++)) do echo done python3 renderer.py question.md for ((i=1; i\u0026lt;$sus; i++)) do echo done Image Display and External Program Calls Use read to take input. When the input is a specific character, use xdg-open to open a specific image. Close it with the ESC key after displaying.\nread -p \u0026#34;:\u0026#34; choice if [ \u0026#34;$choice\u0026#34; == \u0026#34;g\u0026#34; ]; then xdg-open ./picture.png fi Similarly, replacing xdg-open ... with other commands can play audio/video or execute various programs.\nText Rendering ASCII Art for Cover Pages Use figlet to display the theme word and lolcat to color it. Besides the font styles that come with figlet, you can find and download more font styles from figlet-fonts. The \u0026ldquo;Boot\u0026rdquo; shown above corresponds to the command figlet \u0026quot; Boot\u0026quot; -f roman | lolcat -S 30. (Another optional command-line tool is toilet.)\nESC Escape Sequences The printf command can output fancier text in the terminal using \\033 escape sequences. It can achieve simple effects like color, bold, italics, etc., and multiple effects can be combined. For example, the last line in the image corresponds to printf \u0026quot;\\033[2;34;01;21;09myour text\\033[0m\\n\u0026quot;. (This also applies to output in other programming languages. 033 is the octal ASCII code for ESC. The specific colors depend on the terminal\u0026rsquo;s color scheme.)\nMarkdown Rendering glow: glow is a command-line tool, used as glow foo.md. rich: rich is a Python library that can render Markdown. Other Interesting Command-Line Tools asciiquarium\nASCII Art aquarium, very beautiful. You can find the ASCII fish in my avatar here, above the third seaweed from the left in the image below:\noneko\nSummon a little cat, VERY cute:\ncowsay\ndialog\nInteractive TUI dialog boxes, which are also very suitable for single-page slide presentations, for example:\n#!/bin/bash choice=$(dialog --clear --title \u0026#34;Menu\u0026#34; --menu \u0026#34;Make Your Choice\u0026#34; 10 40 3 \\ 1 \u0026#34;Show Greeting\u0026#34; 2 \u0026#34;Enter Something\u0026#34; 3 \u0026#34;Show Figure\u0026#34; 2\u0026gt;\u0026amp;1 \u0026gt;/dev/tty) case $choice in 3) xdg-open ./figure_1.png ;; # SNIP # esac ","date":"2025-02-07T22:52:00+08:00","permalink":"http://fyshxfish.github.io/p/slides-but-in-terminal/","title":"Slides, But in Terminal"},{"content":"Introduction Recently, while studying compiler theory materials, I pondered the question \u0026ldquo;why do we need lexical, syntactic, and semantic analysis?\u0026rdquo; This is actually not quite the right question, because for programming languages, design precedes implementation‚Äîfirst, we design the language\u0026rsquo;s syntax and semantics, then write a compiler to check if a program is syntactically correct and conforms to semantic rules, and convert it to target machine code based on predefined semantics. From a \u0026ldquo;context\u0026rdquo; perspective, typically, syntax is context-free, while semantics handles context-dependent issues. For example, in x = 1; print(x); and x = 2; print(x);, although both use print(x), they have different contexts, leading to different results.\nExample 1 - = For instance:\nfoo = 3 foo = 4 If we only perform syntax analysis, this program follows both Python and Haskell syntax. However, when we do semantic analysis, as a Python program, it means \u0026ldquo;first assign 3 to foo, then assign 4 to foo\u0026rdquo;. As a Haskell program, it\u0026rsquo;s invalid because Haskell semantics don\u0026rsquo;t allow repeated bindings. The core reason is that Python\u0026rsquo;s = semantically means assignment (memory overwrite), while Haskell\u0026rsquo;s = means binding (name binding), allowing only single bindings to ensure no side effects and order independence.\nExample 2 - polyglot The following program is modified from polyglot(computing) wikipedia\n#define a /* echo -e \u0026#34;\\033[34mHello, World! from echo\\033[0m\u0026#34;;// \u0026amp;\u0026gt; /dev/null; x=5; if (($x)) // 2\u0026gt; /dev/null; then return 0; // 2\u0026gt; /dev/null; fi #define e ?\u0026gt; #define b */ #include \u0026lt;stdio.h\u0026gt; #define main() int main(void) #define printf printf( #define true ) #define function function main() { printf \u0026#34;\\033[31mHello, World! from main\\033[0m\\n\u0026#34;true/* 2\u0026gt; /dev/null | grep -v true*/; return 0; } #define c /* main #*/ It conforms to both C and Bash syntax, but compiling/interpreting it yields different results because the two programs have different semantics (of course, C and Bash syntax are also different; the core of polyglot writing is utilizing different symbols for comments/macros/\u0026hellip; between languages. The use and layout of symbols (broadly speaking) is what syntax\u0026amp;lexical analysis concerns):\n","date":"2025-02-17T16:32:00+08:00","permalink":"http://fyshxfish.github.io/p/context-syntax/semantic-analysis/","title":"Context \u0026 Syntax/Semantic Analysis"},{"content":"From Types and Programming Languages ¬ß 1.2 What Type Systems Are Good For\nA safe language is one that protects its own abstractions. A safe language is completely defined by its programmer\u0026rsquo;s manual.\nComplete abstraction means that users can fully trust the language design, focusing only on the high-level language abstraction layer, without needing to concern themselves with the specific implementation at the hardware level.\nHigh-level languages provide abstractions over physical devices. For example, arrays are abstractions over memory. Programmers expect that arrays can only be modified through explicit update operations (e.g., arr[1] = 1024). \u0026ldquo;Modifying a variable, and some elements in an array are inexplicably changed\u0026rdquo; (e.g., buffer overflow attacks) is a manifestation of broken abstraction. This means that programmers must have a detailed understanding of the layout of variables (abstractions provided by high-level languages) in memory (real physical devices) to write programs that meet expectations.\nThis reminds me of a series of experiments in CSAPP. Since the goal of CSAPP is to examine computer systems from the programmer\u0026rsquo;s perspective, i.e., viewing hardware from a software perspective, if the programming language used is safe, then we can fully trust the abstractions it provides. Consequently, we cannot see the hardware through the software. If C were safe, then the experiments in CSAPP couldn\u0026rsquo;t be done üßê.\n","date":"2024-09-10T14:10:00+08:00","permalink":"http://fyshxfish.github.io/p/safety-abstraction/","title":"Safety \u0026 Abstraction"},{"content":" Semantics of let Key point: A let scope is evaluated immediately (including both bindings and expressions after bindings, i.e., everything within the outer parentheses of the let), even if the let is nested inside an inner function that hasn\u0026rsquo;t been called yet.\nExample:\n(define (comp x) (if (\u0026gt; 3 x) (display \u0026#34;then-clause\u0026#34;) (display \u0026#34;else-clause\u0026#34;) ) #| (define foo1 (let ((bar1 (/ 2 0))) ; * evaluted immediately (display \u0026#34;should not be printed\u0026#34;) ) ) |# (define foo2 (let ((bar2 (/ 5 2))) ; * evaluted immediately (newline) (display \u0026#34;let in `foo2`, bar2: \u0026#34;) (display bar2) ) ) ) Running examples:\nfoo1: We can see that the let binding is evaluated, otherwise we wouldn\u0026rsquo;t get a division by zero exception.\nprompt\u0026gt; (comp 4) else-clause ;Division by zero signalled by /. ;To continue, call RESTART with an option number: ;snip foo2: We can see that the expressions after the let binding are evaluated, otherwise we wouldn\u0026rsquo;t see the display output.\nprompt\u0026gt; (comp 2) then-clause let in `foo2`, bar2: 5/2 ;Unspecified return value Semantics of if The semantics of if: It evaluates the condition first, then decides whether to evaluate the then-clause or else-clause based on the result.\nA good reference for this is SICP (2nd Edition) Exercise 1.6, where an abstraction is used to define new-if using cond:\n(define (new-if predicate then-clause else-clause) (cond (predicate then-clause) (else else-clause) ) ) The semantics of function application (applicative order evaluation) requires evaluating arguments first (like then-clause and else-clause here) before applying the function. This is why you can\u0026rsquo;t write recursive expressions in then-clause or else-clause - they would be evaluated regardless of the predicate\u0026rsquo;s value, leading to infinite recursion. if/cond/\u0026hellip; are special forms with different semantics compared to abstractions defined through define. I like the new-if example because it elegantly demonstrates Lisp\u0026rsquo;s metaprogramming features. Following the substitution model, predicate, then-clause, and else-clause can be replaced with any expressions you need, where expressions are enclosed in parentheses - the parentheses mark expression boundaries, and you can put parenthesized expressions in any parameter position (as long as they satisfy the implicit type constraints of the abstraction).\nAn Error Caused by Immediate let Evaluation Consider this prime number checking code:\n(define (prime? x) (if (or (= x 1) (= x 2)) #t test_prime ) (define (divisible? y) (= 0 (remainder x y)) ) (define (iter_biggest_divisor y) (cond ((= y 1) 1) ((divisible? y) y) (else (iter_biggest_divisor (- y 1))) ) ) (define test_prime (let ((biggest_divisor (iter_biggest_divisor (quotient x 2)) )) ; Notice (display biggest_divisor) (if (= biggest_divisor 1) #t #f ) ) ) ) The results when running:\nprompt\u0026gt; (prime? 1) ;The object 0, passed as the second argument to integer-remainder, is not in the correct range. prompt\u0026gt; (prime? 2) 1 ;Value: #t According to programmers\u0026rsquo; expectations, both (prime? 1) and (prime? 2) should directly return #t, rather than the former throwing an error and the latter showing the behavior of (display biggest_divisor). As stated earlier, this occurs because the entire let scope is evaluated immediately.\n","date":"2024-08-29T00:00:00+08:00","permalink":"http://fyshxfish.github.io/p/semantics-of-let-in-schemefeat.-semantics-of-if/","title":"Semantics of `let` in Scheme(feat. Semantics of `if`)"},{"content":"Code, easier‚ú®\nYour VSCode Assistant Ctrl + Shift + P\nIf you need to do something in VSCode, you can press Ctrl + Shift + P to search for it. For example, if you want to change settings but manually opening settings.json is too tedious, you can:\nAfter pressing Enter, settings.json will be right in front of you. If you need to frequently perform this action, you can bind a shortcut for it in Keyboard Shortcuts (open with Ctrl-k Ctrl-s):\nLayout Hide Activity Bar and Status Bar I‚Äôve configured shortcuts in the image below to toggle the Activity Bar and Status Bar. Hiding these can make the interface cleaner.\nPlace Terminal Tab and Code Tab Together Press Ctrl+Shift+P ‚Üí Search for Terminal: Move Terminal to Editor Area in the command palette to move the terminal into the Editor Area. Other similar actions include Move Terminal to Panel, Create New Terminal in Editor Area, etc. Of course, you can bind a shortcut for frequently used actions.\nAn applicable scenario is: if you are learning a programming language that has a REPL (like Haskell, Lisp, Python\u0026hellip;), you can split the Editor Area into two parts, one for the code and one for the Terminal REPL. If needed, you can edit files and import them in the REPL (like :l foo.hs in GHCi). This way, it‚Äôs more convenient, and you can switch focus between the code tab and terminal tab with Ctrl+1 / Ctrl+2.\nAnother similar solution: Open the Secondary Side Bar with Ctrl+Shift+B, then drag the terminal to the Secondary Side Bar.\nEditor Area Rainbow Guidelines In Settings (GUI), type @id:editor.bracketPairColorization.enabled @id:editor.guides.bracketPairs and select the options you need. editor.bracketPairColorization.enabled is enabled by default, while editor.guides.bracketPairs is off by default. You can set it to true or active to enable. The true effect colors all parentheses, and the active effect only colors the outer parentheses closest to the cursor. I think active is enough, and here‚Äôs the result:\nUse Ctrl+Shift+\\ to jump between the closest paired parentheses to the cursor, useful for checking nested expressions, corresponding to % in Vim Normal Mode. If your focus is in the Terminal, you can use Ctrl+Shift+\\ to jump between terminal tabs.\nShortcuts Tip\nHover your cursor over a button in the GUI, and if the button has a corresponding shortcut, a tooltip will show the shortcut key (many programs follow this design philosophy). So, if you find yourself frequently clicking a button, stop and check its hotkey.\nCtrl-bÔºötoggle side bar.\nHere\u0026rsquo;s a related story: someone submitted an issue requesting a toggleExplorerVisibility configuration in VSCode. A user replied \u0026ldquo;Ctrl-B to toggle side bar\u0026rdquo; and closed the issue. Why do I know this? Because I also thought my need was toggleExplorerVisibility, and the lesson learned is: knowing the correct names of components is important üò£.\nAlt-‚Üê/‚ÜíÔºöGo back to the previous cursor position / move forward to the next cursor position.\nThis is particularly useful when navigating through function calls, in combination with F12.\nCtrl-[ / Ctrl-]ÔºöIndent the current line left/right.\nSimilar to Vim‚Äôs \u0026gt; / \u0026lt; in Visual Mode. I don‚Äôt find Vim‚Äôs version very smooth because you can only perform the operation once after selecting, and to make further indentations, you need to select again.\nAlt-‚Üë/‚ÜìÔºöMove the current line up/down.\nShift-Alt-f: Format code, provided a formatter is configured.\nCtrl-(Shift-)Enter: Create a new line below (or above) the current cursor position, with the cursor jumping to the start of the new line.\nCorresponds to o(O) in Vim Normal Mode.\nFrom the 2025-02-19 update: After the VSCode update, Copilot Suggestions (GitHub Copilot: Open Completion Panel) now occupy Ctrl-Enter, which can be changed in Keyboard Shortcuts. Ctrl-k Ctrl-w\nClose all tabs in the Editor Area.\nConflict Avoidance\nDirect conflicts are shown when performing keybinding actions, but in cases like this, where the leading key = other shortcut keys, no conflict is shown. However, in this case, Copy is essentially broken because Ctrl-c will act as the leading key, and after pressing it, VSCode will wait for the chord key. You can observe this in the status bar.\nExtensions Bluloco Light Theme (Author: Umut Topuzoƒülu)\nA very beautiful theme.\nRemove empty lines (Author: Alexander)\nDeletes all empty lines in the selected area. You can call it via Ctrl + Shift + P or bind a shortcut for it.\nMiscellaneous Some small settings in User Settings (JSON) include:\nChange the background color of hover widgets (e.g., function descriptions provided by the Language Server);\nChange the zoom level;\nRainbow bracket guide line.\n{ \u0026#34;workbench.colorCustomizations\u0026#34;: { \u0026#34;editorHoverWidget.background\u0026#34;: \u0026#34;#edeeee\u0026#34;, // Set the hover widget background color }, \u0026#34;window.zoomLevel\u0026#34;: 1, \u0026#34;editor.guides.bracketPairs\u0026#34;: \u0026#34;active\u0026#34; } Some Useful Windows Shortcuts Ôºàü™ü epresents the Windows key.Ôºâ\nü™ü\nPress the Windows key and type text to search for apps, settings, files, etc. After finding the match, press Enter to open it.\nü™ü + Arrow keys\nWin + ‚ÜëÔºöMaximize the current window Win + ‚Üê/‚ÜíÔºöSnap the window to the left/right\nWin + ‚ÜìÔºöExit fullscreen / Minimize\nü™ü + v\nShow clipboard history (the maximum capacity is unknown, but records are lost when shutting down). You can also select and enter emojis, symbols, and emoticons here.\nAlt-Tab\nSwitch between windows on the current desktop.\nCtrl-(Shift-)Tab\nSwitch between tabs in the current application (browser, VSCode). Different applications may sort the tabs differently‚Äîsome by access order (VSCode), others by creation order (Edge).\nAlt-F4\nClose the current window.\nCtrl-w\nClose the current tab in Edge.\n","date":"2024-08-26T00:00:00+08:00","permalink":"http://fyshxfish.github.io/p/my-common-vscode-shortcuts/","title":"My Common VSCode Shortcuts"},{"content":" Perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away. \u0026ndash; Antoine de Saint-Exup√©ry\nInstalling MIT-Scheme via Package Manager MacOS:\nbrew install mit-scheme Ubuntu:\nsudo apt-get update sudo apt-get install mit-scheme Basic REPL Usage ÔºàREPL: Read-Evaluate-Print LoopÔºâ\nStart the REPL with a single command mit-scheme.\nLoad Scheme code into the REPL:\n1 ] =\u0026gt; (load \u0026#34;path/to/file.scm\u0026#34;) (The .scm extension can be omitted.)\nView the manual:\nUse the man mit-scheme command in the terminal to view the brief mit-scheme CLI manual.\nWhen in REPL, press Ctrl-C and then type H to see the interrupt manual:\nCtrl-C: Waits for the next keyboard input to decide the interrupt behavior.\nCtrl-G: Returns to the top-level REPL.\nCtrl-Z: Suspends the current mit-scheme process.\nPress Ctrl-C and then type ? to see the manual for the next key input (option) and how it corresponds to REPL behavior (clear screen, suspend, exit, ignore interrupts, etc.).\nIf the REPL doesn\u0026rsquo;t respond:\nCheck if parentheses are properly matched; ( ( ) ( ( ) )\nAfter interrupting with Ctrl-C, the prompt (1 ] =\u0026gt; / 2 error\u0026gt;) may not reappear, which results in the \u0026ldquo;frozen\u0026rdquo; REPL.\nWorried about deep recursion? If the recursion depth exceeds the limit, the REPL will show Recursion depth limit exceeded. Aborting!. (According to mit-scheme manual, which you can get by man mit-scheme, stack size can be specified with CLI parameters, meaning MIT-Scheme has limited stack resources.)\nScHeMe Scheme is case-insensitive.\nSo (LoAd \u0026quot;path/to/file.scm\u0026quot;)/(DEFINE x 1)/(define x 1)/(defiNE x 1), etc. won\u0026rsquo;t cause errors.\nHistory variable (procedure): Reuse procedures returned after evaluating expressions in the REPL:\n1 ]=\u0026gt; (average-dump square) ;Value: #[compound-procedure 12] ; Can be reused in subsequent expressions, similar to GDB\u0026#39;s history variable `$1` 1 ]=\u0026gt; (#[compound-procedure 12] 10) ; Not very convenient to use directly, but it works ;Value: 55 1 ]=\u0026gt; (define newfunc #[compound-procedure 12]) ; Can be bound to a new identifier for reuse ;Value: newfunc 1 ]=\u0026gt; (newfunc 10) ;Value: 55 Afterword This Scheme REPL is quite basic. It doesn‚Äôt support history backtracking or cursor movement, however, since I don\u0026rsquo;t need it for anything too complex, it\u0026rsquo;s good enough for me.\n","date":"2024-08-24T00:00:00+08:00","permalink":"http://fyshxfish.github.io/p/mit-scheme-basic-usage/","title":"MIT-Scheme Basic Usage"},{"content":"‚ÄÉHow to debug a Rust program? $ gdb excutable Simple example:\nViewing a variable\u0026rsquo;s address:\nFormatted output of p s:\n$17 = alloc::string::String { vec: alloc::vec::Vec\u0026lt;u8, alloc::alloc::Global\u0026gt; { buf: alloc::raw_vec::RawVec\u0026lt;u8, alloc::alloc::Global\u0026gt; { ptr: core::ptr::unique::Unique\u0026lt;u8\u0026gt; { pointer: core::ptr::non_null::NonNull\u0026lt;u8\u0026gt; { pointer: 0x5555555abb80 }, _marker: core::marker::PhantomData\u0026lt;u8\u0026gt; }, cap: alloc::raw_vec::Cap (16), alloc: alloc::alloc::Global }, len: 16 } } Key points: p \u0026lt;variable\u0026gt; p \u0026amp;\u0026lt;variable\u0026gt; ptype \u0026lt;variable\u0026gt;\nOwnership issues with dbg! when outputting debug information Incorrect:\ndbg!(var); // move dbg!(var); // invalid reference dbg! will take ownership of var (Move), so var can\u0026rsquo;t be used again.\nCorrect:\ndbg!(\u0026amp;var); // or let new_var = dbg!(var); dbg!(\u0026amp;new_var); // if you want to Explore with gdb For things you want to explore, use gdb, for example: [How is enum represented at a low level?] -\u0026gt; Write a simple program, compile it to an executable, then use gdb, using print var print \u0026amp;var x/x \u0026lt;addr\u0026gt; to explore.\nAbout: reference to vector An excerpt from ch08-01\n/* CANNOT COMPILE */ let mut v = vec![1, 2, 3, 4, 5]; let first = \u0026amp;v[0]; v.push(6); println!(\u0026#34;The first element is: {first}\u0026#34;); The code in Listing 8-6 might look like it should work: why should a reference to the first element care about changes at the end of the vector? This error is due to the way vectors work: because vectors put the values next to each other in memory, adding a new element onto the end of the vector might require allocating new memory and copying the old elements to the new space, if there isn‚Äôt enough room to put all the elements next to each other where the vector is currently stored. In that case, the reference to the first element would be pointing to deallocated memory. The borrowing rules prevent programs from ending up in that situation.\nA question: How to make a Vector appear to store multiple types of data? Answer: Have the Vector store enums. An enum can have variants of different types, so in a sense, the Vector can store multiple types of data.\nfn main(){ let v: Vec\u0026lt;CellType\u0026gt; = vec![ CellType::Int(12), CellType::Text(String::from(\u0026#34;word\u0026#34;)), CellType::Float(3.14), ]; let v1 = \u0026amp;v[0]; } enum CellType { Int(i32), Float(f64), Text(String), } Debugging enums with gdb and using history variables in gdb (and other REPLs) Source code:\nfn main(){ let v: Vec\u0026lt;CellType\u0026gt; = vec![ CellType::Int(12), CellType::Float(3.14), ]; let v1: \u0026amp;CellType = \u0026amp;v[0]; let v2: \u0026amp;CellType = \u0026amp;v[1]; println!(\u0026#34;END\u0026#34;); } enum CellType { Int(i32), Float(f64), } Debugging session:\np v1ÔºöPrints the value of v1: \u0026amp;CellType, which is a pointer value, meaning the address where the associated data is stored on the heap. Note that the data corresponding to v1, v2 each occupies 16 bytes. x/4x $1ÔºöExamines the 16 bytes pointed to by v1. p *v1ÔºöDereferences v1 to view the actual value stored at that memory location. Analysis of how enum is actually stored in memory:\nThe first byte is likely the variant identifier, with the mapping: 0-Int 1-Float\nInt: Associated data is stored in the second byte, 0x0000000c represents Int(12) from the code\nFloat: Associated data is stored in the third and fourth bytes 0x40091eb8_51eb851f which is the IEEE 754 64-bit representation of 3.14\nRemaining question: Why are the associated data stored in different positions for these two variants, and what is 0x00005555 in Float?\nRediscovering gdb features (history variable)Ôºö\nThe $x in p var output is a history variable for later reuse. Similar REPL behaviors include bash\u0026rsquo;s echo $(ls) and mit-scheme, which also provides referenceable history variables for returned procedures (though those variables are long and contain special characters like #[], so to truly reuse them you still need to copy the identifier and bind it to another identifier for reuse).\nRUST_BACKTRACE and command line tips $ RUST_BACKTRACE=1 cargo run $ A=12 B=23 echo \u0026#34;$A $B\u0026#34; You can write temporary environment variables at the leftmost part of the command.\nFancy technique: color escape sequences in Rust\u0026rsquo;s println println!(\u0026#34;\\x1b[34mMESSAGE\\x1b[0m\u0026#34;); Using \\x1b[34m for escape sequences\nWhat is \\x1b?\n\\x indicates hexadecimal, 1b is the ASCII hex code for ESC.\nDifference between unwrap and expect in Result\u0026lt;T, E\u0026gt;: Looking at library function implementations can give you a better understanding of pre-packaged functions. For example, with Result\u0026lt;T, E\u0026gt;\u0026rsquo;s unwrap and expect, looking at the source code reveals that the difference is in the msg parameter of unwrap_failed (and unwrap_failed is just a wrapper around panic!):\nimpl\u0026lt;T, E\u0026gt; Result\u0026lt;Result\u0026lt;T, E\u0026gt;, E\u0026gt; { ... pub fn expect(self, msg: \u0026amp;str) -\u0026gt; T where E: fmt::Debug, { match self { Ok(t) =\u0026gt; t, Err(e) =\u0026gt; unwrap_failed(msg, \u0026amp;e), } } pub fn unwrap(self) -\u0026gt; T where E: fmt::Debug, { match self { Ok(t) =\u0026gt; t, Err(e) =\u0026gt; unwrap_failed(\u0026#34;called `Result::unwrap()` on an `Err` value\u0026#34;, \u0026amp;e), } } ... } fn unwrap_failed(msg: \u0026amp;str, error: \u0026amp;dyn fmt::Debug) -\u0026gt; ! { panic!(\u0026#34;{msg}: {error:?}\u0026#34;) } ","date":"2024-08-05T00:00:00Z","permalink":"http://fyshxfish.github.io/p/explore-rust-basic-revisiting-gdb/","title":"Explore Rust (Basic) \u0026 Revisiting gdb"},{"content":"Simple Introduction Based on materials I prepared for Computer System course\nI\u0026rsquo;ve seen many people claim that Bash syntax is uncomfortable, but I had already gotten used to Bash syntax before encountering such opinions - \u0026ldquo;I met you before the rumors did\u0026rdquo;?? üò∂‚Äçüå´Ô∏è\nThe topic of the related discussion session was: how does the compiler handle switch-case statements in C? Specifically, under what distribution of case statements (continuous/discontinuous, size of intervals) will the compiler generate a jump table? Since we needed to explore different case scenarios, we first needed to generate C source files with different case patterns. This seemed rather mechanical, so we considered using an automated script. Our expectation for this script was that generator -b 10 -s 2 -d dest_dir -f file_name would produce a file with 10 branches (-b), branch intervals (-s) of 2, in the directory (-d) dest_dir, with the filename (-f) file_name.c. With a single file generator in hand, we could then write another generator to call this one and create a batch of C source files with varying numbers of branches and intervals.\nCommand Line Argument Capture The most obvious benefit of command line interfaces is that you can control a command\u0026rsquo;s specific behavior through options. For example, cat displays file contents, while cat -n adds line numbers. To capture command line arguments, we use getopts:\nwhile getopts \u0026#34;:b:d:f:s:\u0026#34; opt; do case $opt in b) branch=$OPTARG # number of switch branches ;; :) echo \u0026#34;Option -$OPTARG requires an argument.\u0026#34; ;; ?) echo \u0026#34;Invalid option: -$OPTARG\u0026#34; ;; esac done The Simplest Metaprogramming The metaprogramming here refers to using code to generate code. This can be complex, but here we take the simplest approach - code is just a text file, right? So we can simply echo code text and append it to the target file:\ntargetpath=\u0026#34;./${dir}/${filename}\u0026#34; echo -e \u0026#34;/* Created by switch_generator */\\n\u0026#34;\\ \u0026gt; ${targetpath} # sleep 0.1 echo -e \\ \u0026#34;int main(){\\n\\n\\ int i = 0, j = 0;\\n\\ switch (i) {\\ \u0026#34; \u0026gt;\u0026gt; ${targetpath}; # sleep 0.1 for (( i = 1;i \u0026lt;= $branch; i++ )); do record=$i i=$(( i*seperate )) echo -e \\ \u0026#34; case $i:\\n\\ j += $i;\\n\\ break;\\n\\ \u0026#34; \u0026gt;\u0026gt; ${targetpath}; # sleep 0.1 i=$record done echo -e \\ \u0026#34; default:\\n\\ j += 1000;\\n\\ break;\\n\\ }\\n\\ return 0;\\n\\ }\u0026#34; \u0026gt;\u0026gt; ${targetpath} Source File Pipeline Raising the level of abstraction, we use another script to call the above script, implementing batch production of source files. The core code is:\nfor (( branch_num = 1; branch_num \u0026lt;= $size; branch_num++ ));do filename=\u0026#34;${compiler}_branch_${branch_num}\u0026#34; bash ./switch_generator.sh -b $branch_num -d $dir -f ${filename}.c # $compiler -S ./${dir}/${filename}.c -o ./${dir}/${filename}.s # ... done By batch compiling these files to assembly, then using grep to check for and report jump tables, our task was complete. The principles are similar, so I won\u0026rsquo;t go into further detail. If you\u0026rsquo;re curious about the answers to the discussion questions:\nCompilers use jump tables when the number of consecutive branches is ‚â• 4 (clang) / 5 (gcc); otherwise, they use subl, je conditional jump instructions; When branch constant intervals are ‚â• 12 (clang) / 10 (gcc), compilers no longer use jump tables, but directly use subl, je for conditional testing and jumping; When branch variables form two consecutive segments with a large gap between them, such as 1,2,\u0026hellip;,6, 101,102,\u0026hellip;106, gcc generates two jump tables (this conclusion comes from my teammate LYT) ","date":"2024-04-03T00:00:00Z","permalink":"http://fyshxfish.github.io/p/simple-bash-cli-programs-simple-metaprogramming/","title":"Simple Bash CLI Programs \u0026 Simple Metaprogramming"},{"content":"Simple Introduction Although the date here is March 20, 2024, I\u0026rsquo;m actually writing this blog on February 18, 2025, based on materials from my Computer System discussion course. If you want to know a file\u0026rsquo;s type, you might use the file command. But how does file determine file types, or more specifically, how do files in the system tell file (or any program wanting to know its type) what type they are? Where do files store their type information?\nManuals Are Always Your Friend The first second third method to understand a command is usually through whatis / man / tldr.\nman whatis will tell you that whatis actually comes from man:\nEach manual page has a short description available within it. whatis searches the manual page names and displays the manual page descriptions of any name matched.\nman file will tell that file checks file types like thisÔºö\nfile tests each argument in an attempt to classify it. There are three sets of tests, performed in this order: filesystem tests, magic tests, and language tests. The first test that succeeds causes the file type to be printed.\nfilesystem tests System call stat, using its return value to determine the file type; stat can identify empty files / file types defined in \u0026lt;sys/stat.h\u0026gt;. magic tests Check if the file header contains specific magic bytes. For example, if the first five bytes of the file correspond to the ASCII characters \u0026ldquo;%PDF-\u0026rdquo;, it\u0026rsquo;s identified as a PDF file. If no magic bytes exist, it\u0026rsquo;s determined to be a text file, and file will continue to determine its encoding as ASCII/UTF-8/\u0026hellip; language tests Determine the file\u0026rsquo;s language through keywords, such as inferring a text file is a C source file from main, struct, printf. A closer way to observe this command\u0026rsquo;s execution process is strace file foo.bar; you can also redirect the output to a file and use Vim to view it for keyword searching / readability, like strace file foo.bar \u0026amp;\u0026gt; strace.out; vim strace.out.\nFooling file? Exploiting the magic test Exploiting the language test Simple Conclusion To answer the initial question‚Äîfile determines file types through filesystem tests, magic tests, and language tests. Files \u0026ldquo;express\u0026rdquo; their types through magic bytes in the file header, text encoding, or programming language keywords.\n","date":"2024-03-20T20:50:00+08:00","permalink":"http://fyshxfish.github.io/p/a-quick-look-at-the-file-command/","title":"A Quick Look at the `file` Command"}]