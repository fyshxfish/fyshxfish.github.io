[{"content":" 引言 标题的这个问题，其实是一个不太正确的问题，因为对于语言而言，设计先于实现——先设计语言的语法和语义，然后写编译器去检查一个程序语法是否正确，然后根据设定好的语义将它转写成目标机器代码。从“上下文”这个视角去思考，常见情况下，语法是上下文无关的，而语义正是用来处理上下文相关的问题的，x = 1; print(x); 和 x = 2; print(x);，同样是 print(x)，它的上文是不一样的，所以它导致的结果也不一样.\n举例 1 比如：\nfoo = 3 foo = 4 假设对这个程序只做语法分析，那么它符合 Python 语法，也符合 Haskell 语法，但是对它做语义分析，作为一个 Python 程序，它的意思是，“先将 3 赋值给 foo，然后将 4 赋值给 foo”；作为一个 Haskell 程序，它不是一个合格的 Haskell 程序，因为 Haskell 语义不允许做重复的绑定，所以核心原因是，Python 的 = 的语义是赋值（assign），内存覆写，Haskell 的 = 的语义是绑定（name binding），为了保证无副作用、执行顺序无关等特性，只允许单次绑定.\n举例2 - polyglot 下面这个程序改写自 polyglot(computing) wikipedia\n#define a /* echo -e \u0026#34;\\033[34mHello, World! from echo\\033[0m\u0026#34;;// \u0026amp;\u0026gt; /dev/null; x=5; if (($x)) // 2\u0026gt; /dev/null; then return 0; // 2\u0026gt; /dev/null; fi #define e ?\u0026gt; #define b */ #include \u0026lt;stdio.h\u0026gt; #define main() int main(void) #define printf printf( #define true ) #define function function main() { printf \u0026#34;\\033[31mHello, World! from main\\033[0m\\n\u0026#34;true/* 2\u0026gt; /dev/null | grep -v true*/; return 0; } #define c /* main #*/ 它既符合 C 语法，又符合 Bash 语法，然而编译/解释执行它得到的结果不同，因为两个程序的语义不同（当然 C 和 Bash 的语法也是不一样的，polyglot 编写的核心就是利用各语言之间的注释/宏/\u0026hellip;使用的符号不同，符号（广义）的使用和布局正是语法侧关心的事情）：\n","date":"2025-02-17T16:32:00+08:00","permalink":"http://localhost:1313/p/context-syntax-/-semantic-analysis/","title":"Context \u0026 Syntax / Semantic Analysis"},{"content":"Preface Inspiration came from a lecture by Yanyan Jiang：[算法竞赛入门] 为什么要逼大家用 NOILinux？，有参考，但不完全一样.\nMastering this skill will allow you to—display \u0026ldquo;slides\u0026rdquo; in the terminal. Its practicality is limited, but it’s fun to play with ·^v^·.\nDemo Implementation Overall Framework Directory .sh files are bash scripts for displaying a single slide, .md files are the Markdown content to be rendered, and .png files are the images to be displayed.\nLauncher First, print the cover (essentially outputting a page of rendered text in the terminal), then use read to take input and control slide behaviors such as page flipping, image display, exiting, etc.\n0_flow.sh：\n#!/bin/bash bash ./1_banner.sh ## print the cover pc=1\t# page counter while true do read -p \u0026#34;:\u0026#34; choice ## take input and control slide behaviors if [ \u0026#34;$choice\u0026#34; == \u0026#34;p\u0026#34; ]; then # previous page ((pc--)) bash ./${pc}* elif [ \u0026#34;$choice\u0026#34; == \u0026#34;g\u0026#34; ]; then # display an image xdg-open ./load_init.png elif [[ $choice =~ ^[1-7]$ ]]; then # go to the specific page pc=$choice bash ./${pc}* elif [ \u0026#34;$choice\u0026#34; == \u0026#34;E\u0026#34; ]; then # exit the script break else # default: next page ((pc++)) bash ./${pc}* fi done Single Page Display Displaying a single page essentially means showing a page of text. The basic steps are:\nClear the previous page\u0026rsquo;s content using clear; Calculate the total number of lines of the rendered text; To center the content vertically, calculate the padding for the top and bottom; Print the top padding, render and print the content text, then print the bottom padding. For example: (2_question.sh)\nclear length=`python3 renderer.py question.md | wc -l` total=`tput lines` sus=$((($total-$length)/2)) for ((i=1; i\u0026lt;=$sus; i++)) do echo done python3 renderer.py question.md for ((i=1; i\u0026lt;$sus; i++)) do echo done Image Display and External Program Calls Use read to take input. When the input is a specific character, use xdg-open to open a specific image. Close it with the ESC key after displaying.\nread -p \u0026#34;:\u0026#34; choice if [ \u0026#34;$choice\u0026#34; == \u0026#34;g\u0026#34; ]; then xdg-open ./picture.png fi Similarly, replacing xdg-open ... with other commands can play audio/video or execute various programs.\nText Rendering ASCII Art for Cover Pages Use figlet to display the theme word and lolcat to color it. Besides the font styles that come with figlet, you can find and download more font styles from figlet-fonts. The \u0026ldquo;Boot\u0026rdquo; shown above corresponds to the command figlet \u0026quot; Boot\u0026quot; -f roman | lolcat -S 30. (Another optional command-line tool is toilet.)\nESC Escape Sequences The printf command can output fancier text in the terminal using \\033 escape sequences. It can achieve simple effects like color, bold, italics, etc., and multiple effects can be combined. For example, the last line in the image corresponds to printf \u0026quot;\\033[2;34;01;21;09myour text\\033[0m\\n\u0026quot;. (This also applies to output in other programming languages. 033 is the octal ASCII code for ESC. The specific colors depend on the terminal\u0026rsquo;s color scheme.)\nMarkdown Rendering glow: glow is a command-line tool, used as glow foo.md. rich: rich is a Python library that can render Markdown. Other Interesting Command-Line Tools asciiquarium\nASCII Art aquarium, very beautiful. You can find the ASCII fish in my avatar here, above the third seaweed from the left in the image below:\noneko\nSummon a little cat, VERY cute:\ncowsay\ndialog\nInteractive TUI dialog boxes, which are also very suitable for single-page slide presentations, for example:\n#!/bin/bash choice=$(dialog --clear --title \u0026#34;Menu\u0026#34; --menu \u0026#34;Make Your Choice\u0026#34; 10 40 3 \\ 1 \u0026#34;Show Greeting\u0026#34; 2 \u0026#34;Enter Something\u0026#34; 3 \u0026#34;Show Figure\u0026#34; 2\u0026gt;\u0026amp;1 \u0026gt;/dev/tty) case $choice in 3) xdg-open ./figure_1.png ;; # SNIP # esac ","date":"2025-02-07T22:52:00+08:00","permalink":"http://localhost:1313/p/slides-but-in-terminal/","title":"Slides, But in Terminal"},{"content":"Following exercise is from functional and is available on Steam for 29 CNY.\nBasic anything 写出任意一个符合 Lambda Calculus 语法 (1. variable 2. abstraction 3. application) 的 term 即可.\nidentity x: x two arguments x:y: y x squaring f:x: f (f x) indirection f:x:y: f y x Boolean 定义：\nTRUE = t:f: t FALSE = t:f: f IF p:t:f: p t f Simple LC 没有类型系统，所以编程者需要自己确保 p 一定能求值到 TRUE / FALSE，然后 p t f 进一步求值到 t/ f，如果 p 不能被求值到 TRUE / FALSE，那么 p t f 会被保留下来或者产生预期外的求值行为.\n你可以轻松注意到的一点是：IF P A B ≡ P A B，你完全可以在所有使用 IF 的场合省略掉 IF，这不改变语义，同时可以减少一次 reduction，不过为了保证可读性，还是有理由在有点复杂的程序里保留 IF.\nNOT b: b FALSE TRUE 这个看着有点隐隐约约的巧妙. 可以直白地通过 b: IF b FALSE TRUE → b FALSE TRUE 得到，或者利用 TRUE / FALSE 的意义——选第一个 / 第二个——直接得到.\nAND p:q: p q p 如果 p = TRUE，那么 AND p q ≡ q；如果 p = FALSE，那么 AND p q ≡ FALSE ≡ p.\nOR p:q: p p q 如果 p = TRUE，那么 OR p q ≡ p ≡ TRUE；如果 p = FALSE，那么 OR p q ≡ q.\nXOR p:q: p (NOT q) q 类似 AND, OR，可以画个真值表整理思绪.\nPair and List PAIR x:y:f: f x y PAIR A B → (x:y:f: f x y) A B → (f: f A B) 是一个这样的抽象：有序地内涵 A, B，等待一个函数 f 作用于内涵的 A, B，比如当 A, B 是 Boolean，那么，f 可以是 AND / OR / \u0026hellip;（当然语法并不约束 f,A,B 的形状，如果你想写 PAIR TRUE 0 PAIR 解释器不会拦你）\nFST p: p TRUE 当 p = PAIR A B 时, p TRUE → (PAIR A B) TRUE → (f: f A B) TRUE → TRUE A B → A，注意 p 是一个可以接收一个参数 f 的函数，这里我们让它接收 TRUE 函数来选取第一个元素. 在 LC 里，TRUE / FALSE 更恰当的解释是选取其后跟随的第一 / 二个项，而不是表达某个命题的真 / 假，这是有意义的，因为我们写其他高级语言程序的时候，如果我们需要一个 Boolean 值 X ，X 最终的效用往往还是发挥在 then-clause / else-clause 的选择上.\nSND p: p FALSE 类似 FST.\nsimple list 取出列表的第 3 项 (1-indexed)：\nl: FST ( SND ( SND l ) ) 列表是一种简单的递归结构，递归基是空列表，这里用 FALSE 表示，递归步是向某个列表添加元素，这里用 PAIR 实现，e.g. [] ↦ FALSE, 1 ↦ (PAIR 1 FALSE), [1,3] ↦ (PAIR 1 (PAIR 3 FALSE))，注意 [1,3]的例子，如果从向列表添加元素的视角看，表头是最接近 FALSE 的项，越接近 FALSE 的元素索引越小，因为它比较早地被添加进来，在这种解释下，[1,3] ↦ (PAIR 3 (PAIR 1 FALSE))，然而游戏里不采取这个解释，而是和我们熟悉的 [a,b,..] 保持视觉上的对齐，将最晚被添加的项——最左的项——作为表头，在后续涉及升降序的问题的时候记得留意这一点.\nANY 对一个含 3 个 Boolean 的列表，若任一项为 TRUE，返回 TRUE，否则返回 FALSE：\n(l: IF (OR (FST (SND (SND l))) (OR (FST l) (FST (SND l)) ) ) TRUE FALSE ) 直白地按逻辑写即可. 这里的列表是定长的，比较方便，非定长列表就需要递归，见后.\nPUSH (m:l: PAIR m l) 用 PUSH 向列表 l 添加新项 m，根据 $\\eta$-reduction，PUSH ≡ PAIR，所以这里直接写 PAIR 也足够了.\nPOP SND 弹出最外层的项.\nEMPTY l: l (t:x:y: FALSE) TRUE 首先 EMPTY 要接收一个列表，所以它的基本形状是 EMPTY = l: ...，考虑 l' = FALSE 的情形，EMPTY l' ~ᴇxᴘᴇᴄᴛᴇᴅ→ TRUE，根据 FALSE 的选择能力，我们使 EMPTY = l: l 𝕏 TRUE；考虑 l* = PAIR a (PAIR b (...)) = (f: f a (PAIR b (...))) ≈ (f: f a _tail)，把 l* 视作接收一个参数的函数，EMPTY l* = (f: f a _tail) 𝕏 TRUE → 𝕏 a _tail TRUE ~ᴇxᴘᴇᴄᴛᴇᴅ→ FALSE, 那么 𝕏 的工作就是接收后面的 3 项，然后返回 FALSE，所以 𝕏 = (t:x:y: FALSE)，综合以上得到最终的解 EMPTY = l: l (t:x:y: FALSE) TRUE\nRecursion create recursion - Y combinator 动机：LC 中的递归 尝试着在 LC 中定义递归的阶乘函数：\nf = a: IF (EQ a 1) 1 (a * f (a - 1)) 上述的定义是不符合 LC 的语法的，因为 LC 的函数都是匿名函数，不支持通过名称来调用函数（如上面的 f），而递归函数不可避免的需要自指，如何解决这个问题？\n将函数 $F$ 应用于参数 $A$，可以这样表达 $F A$，也可以利用高阶函数这样表达：$(\\lambda fa.\\ f\\ a) F A$，在此基础上，添加一些逻辑，比如表达\u0026quot;参数为 $a$ 和 $p$，函数为 $f$，若 $p\\ a$ 为真，那么返回 $f\\ a$，否则直接返回 $a$ 本身\u0026quot;：$(\\lambda fap.\\ IF\\ (p\\ a)\\ (f\\ a)\\ a)$. 根据这个想法，假设我们的目标阶乘函数为 F，那么 F 满足这个等式，将 (f:a: ..) 记作 F'：\nF = (f:a: IF (EQ a 1) 1 (a * f (a - 1)) ) F ≡ F\u0026#39; F 看等式的右侧，F' 的涵义是，接收函数 f 和参数 a，若 EQ a 1 那么返回 1，否则返回返回 a * f (a - 1). 向 F' 传递递归函数 F，由此得到的函数 F' F 的行为和我们目标的阶乘函数 F 是一致的，从语义上来讲，左右侧相等.\n目前我们有的等式是 F = F' F ①，其中 F' 是已知的 closed term，因为 F 涉及自引，所以不存在 normal form，于是考虑是否存在某个 Y s.t. Y F' = F②，将 ② 代入 ①，Y F' = F' (Y F')，接下来的目标就是解出 Y 的 normal form，得到 Y 之后，目标递归函数 F = Y F' 也随之得到了.\n为什么要试图将 F 分解成 Y F'？\n不严谨地说，从方程的角度看 F = F' F 只有一个未知量 F，将 F 转化成 Y F'，同样只含一个未知量 Y，而 F'已知且和我们的求解目标（递归函数 F）紧密相关.\nY combinator 设计 Y 是一个这样的 term：Y F = F (Y F) = F (F (Y F)) = ....\n为设计满足以上目标的 Y ，做出如下的初步分析：\n根据 inversion lemma，Y 的形状毫无疑问是 (f: ...).\nY 的自指？—— 我们需要重复 Y，或者说构建右侧的 Y.\nFunction / Abstraction is All You Need —— 因为 LC 没有存储，所以 Y F = F (Y F)，等号左右的 Y 并不是同一个 Y，不是值拷贝或者地址拷贝（因为 LC 不提供存储的概念，无处安放值或者地址，这里只有函数），右侧的 Y 需要通过构建得到，与左侧的 Y 在 alpha-conversion 的意义下相等.\n如何重复 F？这很简单，Y = (f: ...) 接收参数 F，在 Y 的函数体内，想怎么重复就怎么重复.\n设计一个 abstraction M 做构建，M 将接收一些必要的参数，在函数体内组织这些参数，形成和 Y 一样的结构.\nY = f: M f ... ~ᴇxᴘᴇᴄᴛᴇᴅ→ M = f: f (Wai f)：毫无疑问，M 需要拿到 Y 的参数 f，M 内部需要建立起和 Y F 一致的结构； Y = f: M f M ... ~ᴇxᴘᴇᴄᴛᴇᴅ→ M = f:m: f (m f m)：因为我们希望 M 可以建立起和 Y F 一致的结构，而 Y 包含了 M，那么 M 也需要包含 M，所以通过参数 m 将 M 原封不动地传进 M. M 的函数体中，最左的 f 实现 f 的再次应用，(m f m) 构建了和左侧的 Y F alpha 等价的结构. Y = f: M f M, 其中 M = f:m: f (m f m)，可以验证这已经是一个可行的 Y 组合子了，Y F = M F M = (f:m: f (m f m)) F M = F (M F M) = F (M F M) = F (Y F). Y 组合子可以有无数种，比如 (a) Y = f: M M f, M = m:f: f (m m f) 这和上文所呈现的 Y 组合子是几乎一样的，只是改变了 M, f 参数的顺序，利用一步 $\\eta$ 规约，使之更简洁——Y = M M, M = ...，这也是图灵给出的 Y 组合子；(b) Y = f: E (E f) E f, E = r:s:f: f (s r s f) 也是可以的，看起来不够简洁，但是理念和上面的陈述是一致的，用 E 接收需要知道的参数，然后做构建，你会发现 E 接收了 E 和 f，又多余地接收了 (E f)，把 (E f) 拿掉并做相应的修改，就得到了本段落陈述的第一种 Y 组合子；(c) 最简洁的 Y = f: (x: f (x x)) (x: f (x x))，它和前面提到的 Y 组合子的区别在于，前面的 Y 组合子是用组合子组成的，比如 4 中的 Y = f: M f M 中的 M 本身也是组合子，而这个 Y 组合子不包含组合子子项.\n小练习：如何实现满足双边延展的 D F D = D (D F D) D = ... 的组合子 D？\n一种解法可以是 D = f:d: d (d f d) d，道理和之前所说的是一致的.\nY 一定要是组合子吗，可以引入自由变量吗？\n假设 Y 包含自由变量 z，因为 Y 包含 z，那么用 M 构建 Y 时也要考虑到 z：\nclosed M：将 z 作为参数传给 M，那么可以在之前的 Y 组合子的基础上修改，得到 Y = f: M f c M, M = f:c:m: f (m f c m)，可以验证，这可以达成 Y F = F (Y F) = ... 的目标，同时你可以注意到引入 z 并没有什么意义，只是平添负担; open M：即 M 本身包含了自由 z，可以尝试 Y = f: K f K z, K = f:k: f (k f k z)这个例子，你会发现这是行不通的： Y F = F (K F K z) z = F (Y F) z = F (F (Y F) z) z，这个 Y 的效果是在左侧不断做 F 的应用，右侧不断产生新的 z. 根据以上的讨论，这个问题的答案是：可以，但没必要. 且从直觉上去理解，随意地引入自由变量也没有意义. 我提出这个问题的原因是，有一瞬间突然觉得 Y 组合子太熟悉了，第一次在 LC 里见到 Y 这个大写字母后面接的就是\u0026quot;组合子\u0026quot;三个字，所以开始考虑，如果不是组合子是否可以.\nY combinator 使用 承接动机部分，我们用 F' = f:a: ... 表达递归函数 f 与其参数 a 之间的应用逻辑，将目标递归函数为 F，那么 F = F' F，因为自引的不合法，考虑用 Y F' 来表示 F，在上一节中我们涉及出了可行的 Y，于是 F = Y F' 就是我们希望得到的目标函数.\n想明白 Y 组合子的使用，本 section 的关卡都很简单了，唯一值得提示的是 1. 使用以往关卡已定义过的函数时，注意函数的参数顺序，例如 FILTER 先传列表，再传过滤依赖的函数，因为 Simple LC 语法层面的约束很少，所以编程者自己要多当心一些 2. 有若干个关卡可能涉及列表反转，所以 REVERSE 可以先写，然后直接拿来用 3. 注意括号配对，可以现在先进的编辑器里先写，确保不犯低级错误，再复制进来评测. 下面给出的答案仅供参考，可以过评测，但未必最简.\nstrip prefix 去除不定长列表前缀的 FALSE：\nY (f:l: IF (FST l) l (f (SND l)) ) ACC Y (a:l:f:i: IF (EMPTY l) i (a (SND l) f (f i (FST l))) ) ALL l: ACC l AND TRUE REVERSE Y (i:c:l: IF (EMPTY l) c (i (PAIR (FST l) c) (SND l)) ) FALSE MAP Y (m:c:l:f: IF (EMPTY l) (REVERSE c) (m (PAIR (f (FST l)) c) (SND l) f) ) FALSE NONE (l: ALL (MAP l NOT)) FILTER Y (m:c:l:f: IF (EMPTY l) (REVERSE c) ( IF (f (FST l)) (m (PAIR (FST l) c) (SND l) f) (m c (SND l) f) ) ) FALSE ZIP Y (z:c:m:n: IF (EMPTY m) (REVERSE c) (z (PAIR (PAIR (FST m) (FST n)) c) (SND m) (SND n)) ) FALSE EQBLIST (m:n: ALL (MAP (MAP (ZIP m n) (p: XOR (FST p) (SND p)) ) NOT ) ) CONCAT (m:n: (Y (g:c:r: IF (EMPTY r) c (g (PAIR (FST r) c) (SND r)) ) ) n (REVERSE m) ) Numerals Church Numeral 用函数表达自然数，两个关键点是 1. 基 (0 := f:x: x) 2. 后继 (SUC)，在基之上不断做后继，就可以得到所有 Church Numeral.\nSUC 给定 Church Numeral n，n 是一个函数，参数为 f, x，n f x 表示将 f 应用于 x $n$ 次，SUC n 是一个函数，这个函数的能力是接收 f, x，将 f 应用于 x $(n+1)$ 次.\n(n: (f:x: f (n f x) ) ) ZERO 利用逻辑运算来判断给定的 n 是不是 f:x: x.\n(n: n (x: AND FALSE x) TRUE) PRE 一个基本的观察是 n = n SUC 0，这里的等号表示内涵等价（intensional equality），那么在 PAIR 0 0 上做 $n$ 次迭代，一轮迭代的工作是：1. 右侧数对齐左侧数 2. 左侧数做一次后继，那么右侧数始终慢左侧数一步，即 $n$ 轮迭代后，左侧数是 n，右侧数是左侧数的后继.\n(n: SND (n (p: PAIR (SUC (FST p)) (FST p)) (PAIR 0 0) ) ) ADD 给定 x, y，目标是给出 x+y，x+y 的含义是：预备接收 f, z，将 f 应用于 z $(x+y)$ 次. 先将 f 应用于 z $x$ 次，得到结果 x f z，再将 f 应用于 (x f z) $y$ 次.\n(x:y: (f:z: y f (x f z)) ) SUB (x:y: (f:z: (y PRE x) f z)) MUL (x:y:f:z: y (x f) z ) DIV (Y (d:c:x:y: IF (ZERO x) 0 ( IF (ZERO (y PRE x)) (SUC c) (d (SUC c) (y PRE x) y) ) ) ) 0 EQ (x:y: AND (ZERO (x PRE y)) (ZERO (y PRE x)) ) MIN (x:y: IF (ZERO (x PRE y)) y x ) MAX (x:y: IF (ZERO (x PRE y)) x y ) More Numerals is odd (n: (n NOT FALSE)) 顺便想起了判断奇偶的递归方法：（看起来还挺有意思的，比熟悉的 mod 2 新鲜一些）\nisEven :: Int -\u0026gt; Bool isEven 0 = True isEven x = isOdd (x-1) isOdd :: Int -\u0026gt; Bool isOdd 0 = False isOdd x = isEven (x-1) increasing list 尾递归：\n(Y (f:c:n: IF (ZERO n) (PAIR 0 c) (f (PAIR n c) (PRE n)) ) ) FALSE 非尾递归：\n(n: REVERSE ( (Y (f:x: IF (ZERO x) (PAIR 0 FALSE) (PAIR x (f (PRE x)))) ) n ) ) decomposition 将给定数分解成 2 的幂之和：\n(Y (f:c:k:n: IF (ZERO n) c (IF (AND (EQ n (MIN k n)) (NOT (EQ k n))) (f c (DIV k 2) n) (f (PAIR k c) (DIV k 2) (SUB n k) ) ) ) ) FALSE 8 * primes 和 sort 都需要大把时间运行（本机测试两关各自耗时都在 30min 左右）\nprimes Y (f:l:p:n: IF (EQ n (FST p)) (PAIR n l) (IF (EQ (FST p) (MAX n (FST p))) (f l (SND p) n) ( IF ( (Y (f:n:p: IF (EQ n (MIN n p) ) (IF (EQ n p) TRUE FALSE ) (f (SUB n p) p) ) ) n (FST p) ) (f (PAIR (FST p) l) p (DIV n (FST p))) (f l (SND p) n) ) ) ) FALSE (PAIR 47 (PAIR 43 (PAIR 41 (PAIR 37 (PAIR 31 (PAIR 29 (PAIR 23 (PAIR 19 (PAIR 17 (PAIR 13 (PAIR 11 (PAIR 7 (PAIR 3 (PAIR 2 FALSE)))))))))))))) sort 选择排序：\nY (f:c:l: IF (EMPTY l) c ( (m: (f (PAIR m c) (FILTER l (x: NOT (EQ x m)) )) ) (ACC l MAX 0) ) ) FALSE trees NODE l:v:r:f: f l v r LEF t: t (l:v:r: l) RIG t: t (l:v:r: r) VAL t: t (l:v:r: v) BEMPTY 类似于列表判空，NODE l v r = f: f l v r，空树用 FALSE := a:b: b，将一个树 t 作为函数使用，若是空树，t A B = FALSE A B = B ~ᴇxᴘᴇᴄᴛᴇᴅ→ TRUE，若不是空树 t A B = (f: f l v r) A B = A l v r B ~ᴇxᴘᴇᴄᴛᴇᴅ→ FALSE，根据以上，B = TRUE, A = l:v:r:x FALSE，所以：\n(t: t (l:v:r:x: FALSE) TRUE ) FIND 判断树 t 中是否存在值为 v 的结点：\nY (f:t:v: IF (BEMPTY t) FALSE (IF (EQ (VAL t) v) TRUE (OR (f (LEF t) v) (f (RIG t) v)) ) ) BSIZE 计算树的规模：\nY (f:t: IF (BEMPTY t) 0 (SUC (ADD (f (LEF t)) (f (RIG t)))) ) BUILD 二叉搜索树的构造：\nY (f:c:l: IF (EMPTY l) c ( f ( ( Y (f:v:t: IF (BEMPTY t) (NODE FALSE v FALSE) ( IF (EQ v (MIN v (VAL t))) (NODE (f v (LEF t)) (VAL t) (RIG t)) (NODE (LEF t) (VAL t) (f v (RIG t))) ) ) ) (FST l) c) (SND l) ) ) FALSE [ 游戏里的 PREORDER 和 INORDER 两个函数似乎反了？ ]\nPREORDER 二叉树的中序遍历：\nY (f:t: IF (BEMPTY t) FALSE (CONCAT (f (LEF t)) (PUSH (VAL t) (f (RIG t)) ) ) ) INORDER 二叉树的前序遍历：\nY (f:t: IF (BEMPTY t) FALSE (PUSH (VAL t) (CONCAT (f (LEF t)) (f (RIG t)) ) ) ) SPLIT 树 t 以 v 为界进行分割：\nY (f:t:v: IF (BEMPTY t) (PAIR FALSE FALSE) ( IF (EQ v (MAX v (VAL t))) ( (p: PAIR (NODE (LEF t) (VAL t) (FST p)) (SND p)) (f (RIG t) v) ) ( (p: (PAIR (FST p) (NODE (SND p) (VAL t) (RIG t) ))) (f (LEF t) v) ) ) ) KTH 对给定的二叉搜索树，给出其中第 k 大的元素，取出树的中序遍历列表中的第 k 项即可：\n(t:k: Y (f:c:l: IF (EQ c 0) (FST l) (f (PRE c) (SND l) ) ) k (PREORDER t) ) inverse 6 对给定的二叉搜索树 t，找出 [1..6] 中的若干个缺席者，升序排列：\nt: IF (BEMPTY t) (PAIR 1 (PAIR 2 (PAIR 3 (PAIR 4 (PAIR 5 (PAIR 6 FALSE)))))) ( Y (f:c:m:n: IF (EMPTY n) (REVERSE c) ( IF (EQ (FST m) (FST n)) (f c (SND m) (SND n)) (f (PAIR (FST n) c) m (SND n)) ) ) FALSE (PREORDER t) (PAIR 1 (PAIR 2 (PAIR 3 (PAIR 4 (PAIR 5 (PAIR 6 FALSE)))))) ) ","date":"2025-02-02T21:29:00+08:00","permalink":"http://localhost:1313/p/programming-in-lambda-calculus-basic/","title":"Programming in Lambda Calculus, Basic"},{"content":"-Inspired by Algorithm Design and Analysis course, 2024 Fall-\nIntroduction In this semester\u0026rsquo;s algorithms course, we focused on two major categories of search algorithms: backtracking and branch-and-bound. Previously, I always treated various search algorithms like DFS and BFS separately, comparing their differences. In this article, I aim to abstract search algorithms, expecting to derive familiar search strategies from a concise abstract model.\nAbstracting the Search Model and Process Here\u0026rsquo;s the model I\u0026rsquo;ve summarized, demonstrated in Haskell:\nclass (Ord node) =\u0026gt; Search env node where initN :: env -\u0026gt; node check :: env -\u0026gt; node -\u0026gt; Bool child :: env -\u0026gt; node -\u0026gt; [node] search :: env -\u0026gt; node Search env node: A search requires two elements: the search environment env and the search node node. Since we need to determine the expansion order based on the priority of node, we want node to be orderable, hence the Ord constraint. initN :: env -\u0026gt; node: A search needs initialization. The search tree requires a root node, so we want to generate a simple root node from the search environment env. check :: env -\u0026gt; node -\u0026gt; Bool: A search needs a stopping condition. We need a function to determine if the current node is a solution based on the properties of env. child :: env -\u0026gt; node -\u0026gt; [node]: A search needs to continue. The live nodes of the search tree are expandable, so we need a function child to generate a list of child nodes [node] based on env and the current node. search :: env -\u0026gt; node: The main search function. Its goal is to search within the environment env and eventually return the terminal node node, which is the optimal solution we seek. To implement a search algorithm for a specific problem, we need to define the abstraction of the search environment env, design the node node, and implement the above functions: initN, check, child, and search.\nThe search model can be abstracted, and so can the search process. Therefore, I provide a default implementation of the search function (since initN, check, and child are often strongly tied to the specific problem and need to be provided during instantiation, they cannot rely on default implementations). This function abstracts the basic search process—starting from the root node (initN), checking (check) if the highest-priority node is a solution, returning it if true, otherwise expanding (child) its child nodes, reordering the live node list based on priority, and repeating this process:\nsearch e = let step :: [node] -\u0026gt; node step (n:ns) | check e n = n | otherwise = step $ sort (ns ++ child e n) in step [initN e] Example: Instantiating the TSP Search from the Model Search Environment: The directed weighted graph Graph is abstracted as follows:\ntype Vertex = Int type Distance = Int type Edge = (Vertex, Vertex, Distance) data Graph = Graph { vertices :: [Vertex], edges :: [Edge] } Additionally, the search process relies on graph functions like minOut and distance:\nminOut :: Graph -\u0026gt; [(Vertex, Distance)] minOut (Graph vs es) = [ (v, minimum ds) | v \u0026lt;- vs, let es\u0026#39; = filter (\\(v1, _, _) -\u0026gt; v1 == v) es, let ds = [ d | (_, _, d) \u0026lt;- es\u0026#39;]] distance :: Graph -\u0026gt; (Int, Int) -\u0026gt; Maybe Distance distance (Graph _ []) _ = Nothing distance (Graph vs ((v1, v2, d):es)) (s, t) | s == v1 \u0026amp;\u0026amp; t == v2 = Just d | otherwise = distance (Graph vs es) (s, t) Node Design (TspNode):\nA node needs to store the current cost, the list of visited vertices, and the heuristic value (upper bound of the total cost):\ndata TspNode = TspNode { cost :: Int, visited :: [Vertex], -- reverse heuristic :: Int -- heuristic / priority } deriving (Show) The lower the heuristic value of a node, the higher its expansion priority.\ninstance Ord TspNode where compare :: TspNode -\u0026gt; TspNode -\u0026gt; Ordering compare n1 n2 | heuristic n1 \u0026gt; heuristic n2 = GT | heuristic n1 \u0026lt; heuristic n2 = LT | otherwise = EQ Search Function Instantiation:\nTo make Graph TspNode an instance of the Search type class, we can use the default search implementation. However, we still need to implement the initN, check, and child functions:\ninitN:\nThe root node\u0026rsquo;s cost is 0, the visited list is empty, and the heuristic value is irrelevant since the root node will always be the first to be checked and removed from the live node list, never participating in sorting. Thus, heuristic can be set to 0:\ninitN :: Graph -\u0026gt; TspNode initN _ = TspNode 0 [] 0 If the current node has visited all vertices (starting from the origin, traversing a loop, and returning to the origin), then it is considered a solution:\ncheck :: Graph -\u0026gt; TspNode -\u0026gt; Bool check g (TspNode _ vs _) | length vs == length (vertices g) = True | otherwise = False child:\nBased on the visited list, calculate unvisited adjacent nodes. If all other vertices have been visited, attempt to return to the origin:\nchild :: Graph -\u0026gt; TspNode -\u0026gt; [TspNode] child g n = let upBound :: [Vertex] -\u0026gt; Int upBound vs = sum [ d | (s,d) \u0026lt;- minOut g , s `notElem` vs ] at = if null (visited n) then 0 else head (visited n) -- then-clause only for initNode nodes = [TspNode cost\u0026#39; visited\u0026#39; heuristic\u0026#39; | v \u0026lt;- filter (\\v\u0026#39; -\u0026gt; v\u0026#39; `notElem` visited n \u0026amp;\u0026amp; isJust (distance g (at, v\u0026#39;))) -- or abstract this function to `checkChildValid` ((tail . vertices) g), -- `tail` for drop the origin vertex (0 here) let way = fromJust $ distance g (at, v), let cost\u0026#39; = cost n + way, let visited\u0026#39; = v: visited n, let heuristic\u0026#39; = upBound visited\u0026#39; + cost\u0026#39;] back = case distance g (at, 0) of Just wayback -\u0026gt; let cost\u0026#39; = cost n + wayback visited\u0026#39; = 0: visited n heuristic\u0026#39; = cost\u0026#39; in [TspNode cost\u0026#39; visited\u0026#39; heuristic\u0026#39;] Nothing -\u0026gt; [] in if length (visited n) == length (vertices g) - 1 then back else nodes Overall Program Framework:\nBrief Description of Other Instances We can also represent DFS and BFS using this model. In data structure courses, we often use recursion for DFS and queues + iteration for BFS. In this model, changing the priority criteria of nodes changes the strategy for selecting nodes to expand, thereby altering the search behavior.\nAssume we have a node like this:\ndata Node a = Node { info :: a, -- Problem-specific node information level :: Int, -- The level of the node in the search tree order :: Int -- The order in which the node was generated } DFS always expands the deepest live node in the current search tree. To perform depth-first search in any search environment using this node, the priority should be set to level:\ninstance Ord (Node a) where compare :: Node a -\u0026gt; Node a -\u0026gt; Ordering compare n1 n2 | level n1 \u0026gt; level n2 = LT -- DEPTH first | level n1 \u0026lt; level n2 = LT | otherwise = EQ BFS always expands the earliest generated live node in the current search tree. To perform breadth-first search in any search environment using this node, the priority should be set to order:\ninstance Ord (Node a) where compare :: Node a -\u0026gt; Node a -\u0026gt; Ordering compare n1 n2 | order n1 \u0026gt; order n2 = LT -- BREADTH first | order n1 \u0026lt; order n2 = LT | otherwise = EQ Limitations Lack of Application to More Specific Problems:\nI initially planned to implement classic textbook cases using this model, but—time ran out. The deadline is approaching, so I only provided the instantiation of the TSP problem under this model.\nNumber of Solutions:\nHere, I limited the number of solutions to 1, defaulting to the first solution as the problem\u0026rsquo;s solution. This is effective in some cases, such as the TSP problem implemented here, where the heuristic calculation ensures the first solution is the optimal one. However, there may be other scenarios: (a) the first solution is only an approximation of the optimal solution, which may be found later, or (b) multiple solutions need to be retained. These cases are not handled by the current model.\n","date":"2024-11-24T12:09:00+08:00","permalink":"http://localhost:1313/p/abstractions-for-search-algorithms/","title":"Abstractions for Search Algorithms"},{"content":"前言 这个学期包含编译系统和算法设计与分析两门专业课，遇到一些问题总会想着放在 Haskell 里实现一下，对于程序构造多少有点新的体会，也度过了对于 Haskell 不平静的狂热期，现在的我已经不会想着到处传教了（☺️）. 本来只是准备随便写写做 0-1 背包的 Haskell 实现中的一些小思考，不过真开始动笔了就越写越正式了，也算是接触 FP / Haskell 以来的一点点小总结. Haskell 官网 对 Haskell 的描述是 \u0026ldquo;An advanced, purely functional programming language\u0026rdquo;，本文试图围绕 \u0026ldquo;purely\u0026rdquo; 做一些讨论：什么是纯，怎么样算不纯，追求纯度的理由是什么，纯度带来的效益是什么.\n首先从 0-1 背包的过程式实现出发，我把过程式实现 1:1 投射到 Haskell 里，感觉这段代码不是很符合 Haskell 的气质（😯），于是回到了递推式，回到了算法课上一笔带过的递归实现，对过程式语言的递推实现和函数式语言的递归实现做了一些比较，看看两者对于“如何避免重复计算的开销”这个问题（不局限于 0-1 背包问题）给出的不同答案，前者利用源代码上的记忆数组，后者则可以利用纯函数的特性，通过求值策略实现减少重复计算.\n一段算法设计与计算模型的讨论：从 0-1 背包问题这个例子里也可以看出\u0026quot;算法设计\u0026quot;其实是不完全独立于编程范式的，也许更合适的说法是，算法设计强相关于物理计算机的实际运行方式，毕竟算法设计除了解决问题，还有一个追求是降低在物理机上运行时的时空计算资源消耗，这和命令式语言的特性是相契合的，而函数式语言有点 Lambda Calculus 虚拟机的意思；比如复杂度的计算，直接把命令式程序的时间复杂度计算方式照搬给函数式程序是有问题的，前者的理论基础是图灵机 - 状态转移次数，后者的理论基础是 $λ$ 演算 - 规约次数，计算模型的不同势必带来一些差异. 因为我们使用的计算机采取冯诺依曼体系结构，即 图灵机的物理实现，所以算法课也采用更接近硬件的命令式的编程范式，还是很合理的. 不由得想起大一上 CPP 程序设计时老师说 “只要冯诺依曼体系结构还存在，我们就\u0026hellip;(后半句忘了)”，不知不觉我已经尝试走了走另一条路. 说起函数式语言的机器这件事情，其实 1970s,1980s 有学者为函数式的语言设计过专门的非冯诺依曼机器（combinator machine, dataflow machine, etc.），后来大家发现在效率的方面，现有机器 + 好的编译器 \u0026gt; 专用机器，可参考 A History of Haskell: Being Lazy With Class, Part I - 2.1\n命令式程序如何避免重复计算 关于过程式的 0-1 背包，你熟悉到几乎可以默写的一段程序：\n回忆：使用 dp 数组，而不是递归的原因是 —— 将递归转为迭代，避免重复计算；另一种陈述是将函数调用 dp(i, j) 的结果存储到内存中的数组 dp[i][j] 里，实现记忆化. int knapsack(int n, int* weight, int* value, int capacity) { int dp[n+1][capacity+1]; // INIT: BASE CASE// for (int j = 0; j \u0026lt;= capacity; j++) dp[0][j] = 0; for (int i = 0;i \u0026lt;= n;i++) dp[i][0] = 0; // DP // for (int i = 1; i \u0026lt;= n;i++) { int w = weight[i], v = value[i]; for (int j = 1; j \u0026lt;= capacity; j++) { if (j \u0026lt; w) dp[i][j] = dp[i-1][j]; else dp[i][j] = max(dp[i-1][j], dp[i][j-w]+v); } } return dp[n][capacity]; } 将上述代码 1:1 翻译成 Haskell 程序，你将得到：\nimport Data.Array type Value = Int type Weight = Int type Item = (Value, Weight) knapsack01 :: Weight -\u0026gt; [Item] -\u0026gt; Value knapsack01 capacity items = dp ! (n, capacity) where n = length items dp = array((0,0), (n,capacity)) [((i, w), step i w) | i \u0026lt;- [0..n], w \u0026lt;- [0..capacity]] step 0 _ = 0 step _ 0 = 0 step i w | curWgt \u0026gt; w = dp ! (i - 1, w) | otherwise = max (dp ! (i - 1, w)) (curVal + dp ! (i - 1, w - curWgt)) where curVal = fst $ items !! (i - 1) curWgt = snd $ items !! (i - 1) 写的时候感觉不太对劲，第一感觉是：这两段代码没有区别. 这就是在函数式的语言里写命令式程序. 周五晚上我从炸鸡店走出来的时候，有了一些新的想法：\n函数式程序如何避免重复计算 当我们不能像过程式语言那样在内存条里随机存取的时候，当我们建立起一层层抽象的时候，如何追求性能呢？除了在 CSAPP 第五章里学习利用局部性、循环展开、提高并行性等方法，还有什么方式可以提高程序的性能？除了程序员本身从源代码层面提高性能，还可以在哪里优化性能？编译器从程序员手上接管代码，编译器可以做什么？\n0-1 背包：回到起点 所有物品为 $items$，规模为 $N$, 物品属性为价值 $v_i, w_i$，背包总容量为 $W$，定义 $z(i, j)$ 为可选物品为 $items[1..i]$，背包容量为 $j$ 时，可获得的最大价值，那么\n递推基：$\\forall i, j,\\quad z(i, 0) = 0, z(0,j) = 0;$\n递推步：$z(i,j) = max(z(i-1, j), v_i + z(i-1, j-w_i));$\n目标值：$z(N, W)$ 毫无疑问这是递归的结构，在 Haskell 里写递归实现，如同呼吸般自然：\n（NOTE：1. 看到这里也许你已经开始担忧重复计算、内存占用的事情了 ；2. 值得稍稍注意的一点是，这一段代码完全不涉及基于索引的数据存取）\ntype Item = (Value, Weight) knapsack :: [Item] -\u0026gt; Int -\u0026gt; Int -- items + capacity -\u0026gt; maximal value knapsack _ 0 = 0 knapsack [] _ = 0 knapsack ((v,w):items) c = let choose = v + knapsack items (c-w) -- choose current item chxxse = knapsack items c -- not choose current item in if w \u0026gt; c then chxxse else max choose chxxse 严格求值 - 不递归的理由 在背包问题的 C++ （严格求值语言）实现中，我们不用递归的理由是对于性能的追求，因而使用 dp[i][j] 用空间换时间，将递归中的重复计算转换为数组的索引访问. 这个记忆化的工作，除了我们自己做（也就是使用 dp 数组），还可以 —— 交给编译器. 当然这种形式的记忆化就不是在源代码层面上呈现一个记忆数组了，而是通过求值策略来实现. 在讨论求值策略前，先看看什么是纯函数.\n对于 \u0026quot; 纯 \u0026quot; 函数的讨论 函数是什么？/ 函数的表示法 / LUT 的类比 / 编译器行为 / 纯函数的求值策略\n—— 多年以后，面对 \u0026ldquo;函数式程序设计\u0026rdquo;，🐟将会回想起数学老师带她去见识函数的那节遥远的数学课.\n函数是一种映射关系. 体现这种关系的方式，即 函数的表示法，除了函数表达式、函数图像，还有表格.\n如果我们需要一台机器来执行定义域为某有穷集的完全平方函数 f(x, y) = x*x + y*y，除了依赖加法器、乘法器构成的组合逻辑电路，我们还可以用 LUT（LookUp Table），虽然听起来有点离谱，但是它的可行性是不可否认的.\nNOTE: 可能产生的疑惑 - 如何确定 / 如何描述电路实现的函数与我们预期的函数之间的等价性？或者说，我们预期的是函数 $f$，电路实现的是函数 $f\u0026rsquo;$，如何确定 $f\u0026rsquo; \\equiv f$？如果你对 $λ$ 演算（逻辑学）中函数等价的形式化理论感兴趣，可以参看 Lambda Calculus and Combinators, an introduction - Chapter 5~8. 这里 LUT 实现的函数 $f_1\u0026rsquo;$ 与预期函数 $f$ 外延等价（extensional equivalence），组合逻辑实现的函数 $f_2\u0026rsquo;$ 与预期函数 $f$ 内涵等价（intensional equivalence）.\n我们习惯的编译器的行为大致是：看到函数+参数 → 放入组合逻辑电路计算；如果只依赖映射表（LUT），那么编译器的行为大致是：看到函数+参数 → 在 LUT 中查找对应输出，这需要 LUT 存储好所有函数输入对应的输出，于是压力给到 LUT；折中的策略是，第一次见到函数+参数时，利用组合逻辑电路计算，并缓存到 LUT，再次见到这组函数+参数，直接在 LUT 中查找.（函数式有自己的高速缓存:）\n子过程与函数 / 副作用与纯度\n这里我们用函数指代“纯”函数（定义见下），将非纯的过程称为子过程.\n使用 LUT 实现函数的前提是：函数是纯的，即对相同的输入总是返回相同的输出，并且不产生副作用. 形象地说，我们希望 LUT 是严格的，IN / OUT 引脚保持干净，IN 接收函数参数，OUT 给出函数输出，不希望在 IN 之外，再从某个寄存器接进来一个输入，也不希望在 OUT 的旁边，多连接一个寄存器，把寄存器存储值的改变作为函数执行的结果；即 函数本身总是独立于程序的其他部分 - LUT 总是独立于电路的其他部分，不受其他部分影响.\n输入输出的纯度：\naddx 是不纯的，因为这个函数无法保证对于同样的 a 总是给出相同的输出，因为全局变量 x 可能随时被修改，导致修改前后 a + x 的值不同；readOneWord 是不纯的，因为无法保证对于同一个路径 p，始终返回同样的 firstWord，因为 p 对应的文件可能被其他程序随时修改.\nint x; // global int addx(int a){ return a + x; } string readOneWord(path p) { // IO return head(getFile(p)); } 副作用：\ngreeting 是不纯的，因为它产生了 print 的副作用； write 是不纯的，因为它造成了写文件的副作用.\nvoid greeting(string name){ print(f\u0026#34;Hello, {name}\u0026#34;); } void writeLine(path p) { getFile(p).append(\u0026#34;Append this line\u0026#34;); } \u0026ldquo;提纯\u0026rdquo;？\n对于上述的非纯函数，我们可以将副作用分离，得到对应的纯函数如下：\nint addx(int a, int x) { return a + x; } string readOneWord(file f) { string firstWord = head(f); return firstWord; } string greeting(string name){ return f\u0026#34;Hello, {name}\u0026#34;; } file writeLine(file f){ return f.append(\u0026#34;Append this line\u0026#34;); } 分离副作用的示例 / Imperative Shell, Functional Core\n提问：假设有两个类 Camera, FaceRecognizer，Camera 类有一个方法 getFrame 用于从物理摄像头捕获一帧图像，FaceRecognizer 类有一个方法 recognizePerson 用于识别一帧图像中的人脸并返回对应用户名. 若需要实现函数 getFrameAndRecognize 用于捕获当前帧、识别并返回用户名，如何组织程序结构？\n一种答案：将 FaceRecognizer 的实例作为 Camera 的成员，保证 FaceRecognizer 的纯度，即 FaceRecognizer 的方法总是对帧做计算，将 getFrame 这样的副作用分离、止步于 Camera 类.\nclass Camera: self.face_recognizer = FaceRecognizer() def getFrame(): # snip # return frame def getFrameAndRecognize(): frame = getFrame() name = face_recognizer.recognizePerson(frame) return name class FaceRecognizer: def recognizePerson(frame: image): # snip # return name 即：保证功能函数的纯度，并将其作为程序的核心，将 IO 等非纯操作分离到外层 —— Imperative Shell, Functional Core. （此处应有一场 Simon Peyton Jones 的讲座链接，但我一时找不到了.）\n追求纯度的理由\n方便单元测试与维护；\n易于并行；\n可以用查表作为一种求值策略，或者作为求值策略的一部分，避免了重复计算带来的开销.\n语法树与语法图 / 重复计算 / 求值策略\n一些参考资料\nHaskell Wiki - Graph Reduction\n从 Lambda Calculus 角度解释操作语义 call-by-value / call-by-name / call-by-need，可以参考 Types and Programming Language, Section 5.1\n[TODO]\n这一节还没写的原因是：我 也 不 是 很 懂.\ngraph reduction 的图示\n语法树与语法图比较\nlet 对应的语法图（及其 Core 解释？）\n\u0026hellip;\n惰性求值 - 递归的理由 照应本文 3.2 不递归的理由 避免重复计算的方式除了通过显式缓存（记忆数组），还可以依赖编译器采取的求值策略（惰性求值 Lazy Evaluation），将语法树中的所有相同的表达式结点指向同一个结点，实现计算结果的复用.\n其他 前文试图在 命令式语言 / 函数式语言，递归 / 非递归 之间做比较明确的区分，其实，当然递归不是 FP 的专利，记忆化数组也不只是在命令式程序里好用，只是不同语言 / 编程范式本身的特性（例如 C++ 的严格求值 / Haskell 的惰性求值），使得我们对于程序产生了不一样的思考和不一样的惯性. 对于纯度与惰性求值，命令式语言也可以有灵活的求值策略，比如判断函数的纯度，对非纯函数严格求值，对纯函数惰性求值.\n","date":"2024-10-20T19:48:00+08:00","permalink":"http://localhost:1313/p/how-to-avoid-redundant-computations--pure-functions-and-their-evaluation-strategies/","title":"How to Avoid Redundant Computations + Pure Functions and Their Evaluation Strategies"},{"content":"来自 Lambda-Calculus and Combinator § 4C Theorem 4.20 的 proof 部分，整体意图是证明符合 Definition 4.18 的全称递归函数可以用组合子来表示. 这里对该证明的关键部分，即迭代组合子的构造，做简要的陈述. 也可以理解为：在 Pure Lambda Calculus 中编写一个具有特定终止条件的迭代程序. 如果你好奇 \u0026quot; 如何在 Lambda Calculus 中编写一个指定迭代 / 递归次数的迭代 / 递归函数 \u0026quot; ，可以参考 Lambda-Calculus and Combinator § 4B Theorem 4.11 的 proof 中 $R_{\\text{Bernays}}$ 组合子的构造，这个构造过程也十分精巧.\n递归与迭代：在 $R_{\\text{Bernays}}$ 递归组合子的构造中，求解某个递归函数 $\\phi $ 的值 $ \\phi(n) $，用的方法就是从 $ \\phi(0) $ 开始，做 $n$ 次迭代得到的（大致如下：记递归步更新函数为 $\\chi$，$\\phi(n) = \\chi^n \\phi(0)$）. 迭代和递归是正向与逆向的区别. 本文中的\u0026quot;递归\u0026quot;意在描述\u0026quot;调用自身\u0026quot; 的结构特点，探讨的中心问题还是对迭代（$0 \\rightarrow 1 \\rightarrow \u0026hellip; \\rightarrow n$）问题的求解.\n构造目标 假设有一个检查函数 $X$，迭代的终止条件为 $XY=_{\\beta,w}\\bar{0}$, 我们希望构造一个组合子 $P$,得到最小的符合终止条件的 $Y$. 即从 $Y = \\bar{0}$ 开始，检查 $(XY) = _{\\beta,w}? \\bar{0}$ ，若条件满足，则返回值为此 $Y$，否则继续检查 $X(\\bar{\\sigma}Y)$，我们希望构造一个组合子 $P$ 自动化此检查过程，形式化地，我们预期 $P$ 的行为如下:\n$$ PXY =_{\\beta,w}Y \\quad \\text{, if } XY = _{\\beta,w}\\bar{0};$$\n$$ PXY =_{\\beta,w}PX(\\bar{\\sigma}Y), \\text{ otherwise} $$\n完全尊重预期，写一个 $P$ 组合子：$P \\equiv \\lambda xy.\\textbf{D}y(Px(\\bar{\\sigma}y))(xy)$，其中 $\\textbf{D}=\\lambda xyz.z(\\textbf{K}y)x$, 可以用 $\\textbf{Y}$ 对这个递归的 $P$ 组合子进行求解（$P = \\textbf{Y}(\\lambda uxy.\\textbf{D}y(ux(\\bar{\\sigma}y))(xy))$），使用 $\\textbf{Y} $ 组合子求解出的 $P$ 没有 normal form，这里不采用此 $P$，我们尝试逐层构造一个具备 normal form 的 $P$ 组合子.\n构造过程 基本结构 用高级语言的伪代码表示现有的 $P$:\ncombinator p(x,y): // L1: define p if (xy == 0): return const(y) else: return p(x, σ y) // L5: call p 递归的 $\\lambda $，形如 $P \\equiv \\lambda x. MPN $，像这样的 $\\lambda$-term，符合我们在高级语言程序设计的经验，但是不符合 Lambda Calculus 中的规范，因为 Lambda Calculus 对 $\\lambda$-term 的归纳定义并不包含为 abstraction 赋标识符的规则，我们写 $P$ 等标识符的目的只在于提升可读性和明确表达式结构，而不是借助标识符的复用来像高级语言编程一样定义递归函数. 一个细节是，我们在书里看到的为某个 $\\lambda$-term 记标识符用的符号是 $\\equiv$ 而不是 $=$.\n我们不能通过标识符的复用定义递归不意味着我们不能定义递归，只是我们需要依赖多一层的抽象来构造出 形式上的非递归，事实意义上的递归.\n从高级语言编程的角度出发，如果我们希望用某种方式取代 L5 中对 p 自身的调用，我们可以如下修改我们的代码. 为了两个分支的结构一致，我们设计一个函数列表 t，t 中的两个函数对应两个分支，函数 getCurrentY 将返回当前 y 值，recursion_p 将承担递归的工作：（这里先不考虑函数的具体结构和参数设计/参数传递的问题，后面总有办法的，这里我们只关心整体结构）\nt = [getCurrentY, recursion_p] // list of functions combinator p(x,y): if (xy == 0): return t[0] else: return t[1] 如何在 Lambda Calculus 中表达以上的代码？为了专注于我们目前处理的抽象层次，先将 $P \\equiv \\lambda xy.\\textbf{D}y(Px(\\bar{\\sigma}y))(xy)$ 的结构简化为 $P \\equiv \\lambda xy.\\textbf{D}AB(xy)$\n根据预期 / 上面的伪代码，我们可以写出大致的 $\\lambda $ 框架如下:\n$$ P \\equiv \\lambda xy. T(xy)[params] $$ $$ T \\equiv \\textbf{D}AB $$ $$ A \\equiv \\lambda [params]. \\dots$$ $$ B \\equiv \\lambda [params]. \u0026hellip;$$\n此时 $PXY = _{\\beta,w} T(XY) $，$ XY = _{\\beta, w} \\bar{0} \\longrightarrow PXY = A; XY \\neq _{\\beta, w} \\bar{0} \\longrightarrow PXY = B $ .\n我们预期：将分支的具体逻辑放在 $T$ 中，将分支的选择和分支函数参数传递放在 $P$ 中.\n具体细节 上面我们忽略了许多细节，现在是考虑细节的时候了 :)\n首先注意一个事实：我们将分支函数参数传递的工作放在 $P$ 中，意味着无论当前 $P$ 中的 $(xy)$ 将导向哪个分支，我们传递的参数列表都是一致的 / 都只能是一致的. 因为 $(xy) = _{\\beta,w}\\bar{0}$ 对应的情况更简单，只需返回当前 $y$，所以我们延后考虑这一情况，先考虑 $(xy) ≠ _{\\beta,w}\\bar{0}$ 的情况，让前者迁就后者（，因为两个分支都与 $y$ 有关，所以参数列表中必然有 $y$，在这一点上两个分支是有共性的；另一方面，我们甚至可以两个分支函数对应的参数并列传递，然后在 $A$,$B$ 的具体实现中 不对与本分支无关的参数进行绑定）.\n递归（迭代）分支的构造 目标是：$XY \\neq _{\\beta, w} \\bar{0} \\longrightarrow PXY = B \\xlongequal{\\text{expected}} PX(\\bar{\\sigma}Y) $，我们希望函数 $B$ 与 $P$ 中传递的 $[params]$ 应用后得到的 $\\lambda$-term 和 $PXY$ 具备一样的结构（注意不是 $B$ 和 $P$ 两个 abstraction 本身结构一致），只是 $Y$ 位置的值替换成了 $(\\bar{\\sigma}Y)$，为了得到和 $P$ 一样的结构，最简单的方法是——把 $P$ 现有的组件作为 $[params]$ 传递到 $B$（，当然也传递到了 $A$），然后在 $B$ 中把这些组件重组成 $P$ 的结构：\n$$ P \\equiv \\lambda xy. T(xy)Txy $$ $$ T \\equiv \\textbf{D}AB $$ $$ A \\equiv \\lambda tuv. \\dots$$ $$ B \\equiv \\lambda tuv. q(uv) $$\n（$ T \\mapsto t, x \\mapsto u, y \\mapsto v$）\n由于 $[params]$ 的传递，现在 $P$ 的结构发生了改变，我们需要让 $B$ 与新的 $P$ 结构同步；另一方面，我们需要在 $B$ 的内部将传递进来的 $y$ （由 $v$ 绑定）变为 $\\bar{\\sigma}y$：\n$$ P \\equiv \\lambda xy. T(xy)Txy $$ $$ T \\equiv \\textbf{D}AB $$ $$ A \\equiv \\lambda tuv. \\dots$$ $$ B \\equiv \\lambda tuv. q(u(\\bar{\\sigma}v))qu(\\bar{\\sigma}v) $$\n做一个检查：当 $XY \\neq _{\\beta, w} \\bar{0}$：\n$ \\quad PXY $ $ = _{\\beta,w} T(XY)TXY $ $ = _{\\beta,w} BTXY $ $ = _{\\beta,w} T(X(\\bar{\\sigma}Y))TX(\\bar{\\sigma}Y) $ $ = _{\\beta,w} PX(\\bar{\\sigma}Y) $ 符合我们的预期，至此，迭代分支的构造就完成了.\n迭代终止分支的构造 目标是：$XY = _{\\beta, w} \\bar{0} \\longrightarrow PXY = A \\xlongequal{\\text{expected}} Y $，在 $B$ 的构造过程中，我们已有的参数列表是 $ t \\mapsto T, u \\mapsto x, v \\mapsto y$，在 $A$ 中，我们只需要把 $y$ 提取出来即可，所以 $A = \\lambda tuv.v$ ，如果你希望和 Definition 4.8 的记法保持一致，那么 $A = \\Pi^3_3$.\n完整 $\\lambda$ $$ P \\equiv \\lambda xy. T(xy)Txy $$ $$ T \\equiv \\textbf{D}AB $$ $$ A \\equiv \\lambda tuv. v (= _{\\beta,w} \\Pi^3_3) $$ $$ B \\equiv \\lambda tuv. q(u(\\bar{\\sigma}v))qu(\\bar{\\sigma}v) $$\nLCaC Theorem 4.20 中的 $P$ 简述 LCaC Theorem 4.20 中给出的 $P$ 定义如下：\n$$ T \\equiv \\lambda x.\\textbf{D}\\bar{0}(\\lambda uv.u(x(\\bar{\\sigma}v))u(\\bar{\\sigma}v)) $$ $$ P \\equiv \\lambda xy.Tx(xy)(Tx)y $$\n以与前文一致的格式转写：\n$$ P \\equiv \\lambda xy.Tx(xy)(Tx)y $$ $$ T \\equiv \\lambda x.\\textbf{D}AB $$ $$ A \\equiv \\bar{0} $$ $$ B \\equiv \\lambda uv.u(x(\\bar{\\sigma}v))u(\\bar{\\sigma}v) $$\n在一些时刻把 $(Tx)$ 作为一个整体，让表达式更简洁了一些，同时让 $x$ 和 $T$ 有绑定关系（$T \\equiv \\lambda x\u0026hellip;.$），在 $T$ 的内部依然可以单独地拿出 $x$ 使用；$P$ 中的 $(Tx)$ 闭包，使得传参的形态是 $B(Tx)y$ —— 而不是 $BTxy$ ——让 $A$ 的设计更简洁了，$A \\equiv \\bar{0}$.\n虽然在细节上略有差别，但是整体结构与本文给出的 $P$ 是一致的，我觉得可能是包含一些直觉 / 灵感 / 优化上的差异.\n其他 尝试着展开上面的 $P$:\n$$ \\lambda xy.\\lambda x.\\textbf{D}\\bar{0}(\\lambda uv.u(x(\\bar{\\sigma}v))u(\\bar{\\sigma}v))x(xy)(\\lambda x.\\textbf{D}\\bar{0}(\\lambda uv.u(x(\\bar{\\sigma}v))u(\\bar{\\sigma}v))x)y$$\n如果你愿意把以下也全部展开： $ \\textbf{D} = _{\\beta, w} \\lambda xyz.z(\\textbf{K}y)x, \\quad \\textbf{K} = _{\\beta, w} \\lambda xy.x $ $ \\bar{0} = _{\\beta, w} \\lambda xy.y $ $ \\bar{\\sigma} = _{\\beta, w} \\lambda nfz. f (n f z)$ $$ \\lambda xy.\\lambda x.(\\lambda xyz.z((\\lambda xy.x)y)x)(\\lambda xy.y)(\\lambda uv.u(x(\\lambda nfz. f (n f z)))u(\\lambda nfz. f (n f z)))x(xy)(\\lambda x.(\\lambda xyz.z((\\lambda xy.x)y)x)(\\lambda xy.y)(\\lambda uv.u(x(\\lambda nfz. f (n f z)))u(\\lambda nfz. f (n f z)))x)y$$\n可以说，我们用这一堆符号 + Pure Lambda Culculus 的演算规则完成了一个迭代程序的构造——Programming in Pure Lambda Calculus.\n","date":"2024-09-17T23:48:00+08:00","permalink":"http://localhost:1313/p/the-construction-of-the-iteration-combinator-lcac-4c-theorem-4.20/","title":"The Construction of the Iteration Combinator - LCaC § 4C, Theorem 4.20"},{"content":"From Types and Programming Languages § 1.2 What Type Systems Are Good For\nA safe language is one that protects its own abstractions. A safe language is completely defined by its programmer\u0026rsquo;s manual.\nComplete abstraction means that users can fully trust the language design, focusing only on the high-level language abstraction layer, without needing to concern themselves with the specific implementation at the hardware level.\nHigh-level languages provide abstractions over physical devices. For example, arrays are abstractions over memory. Programmers expect that arrays can only be modified through explicit update operations (e.g., arr[1] = 1024). \u0026ldquo;Modifying a variable, and some elements in an array are inexplicably changed\u0026rdquo; (e.g., buffer overflow attacks) is a manifestation of broken abstraction. This means that programmers must have a detailed understanding of the layout of variables (abstractions provided by high-level languages) in memory (real physical devices) to write programs that meet expectations.\nThis reminds me of a series of experiments in CSAPP. Since the goal of CSAPP is to examine computer systems from the programmer\u0026rsquo;s perspective, i.e., viewing hardware from a software perspective, if the programming language used is safe, then we can fully trust the abstractions it provides. Consequently, we cannot see the hardware through the software. If C were safe, then the experiments in CSAPP couldn\u0026rsquo;t be done 🧐.\n","date":"2024-09-10T14:10:00+08:00","permalink":"http://localhost:1313/p/safety-abstraction/","title":"Safety \u0026 Abstraction"},{"content":"Motivation: Abstraction Level Up! 对 2 应用 $3$ 次 square\n1 ]=\u0026gt; (square (square (square 2))) ;Value: 256 2 → x: 对某个数 x 应用 $3$ 次 square\n(define square3 (lambda (x) (square (square (square x))))) square → f: 对某个值 x 应用 $3$ 次某个函数 f\n(define three_times_f (lambda (f x) (f (f (f x))))) $3 → i$ : 对某个值 x 应用 $i$ 次某个函数 f $(i \\in \\mathbb{N})$\n$i=0$\n(define zero_time_f (lambda (f x) (x))) $i=1$\n(define one_time_f (lambda (f x) (f x))) $i=2$\n(define two_times_f (lambda (f x) (f (f x)))) 递归定义 $i$ 次应用\n递归基：\n(define zero_time_f (lambda (f x) (x))) 递归步：\n(define (succ z) (lambda (f x) (f (z f x)))) 递归求解 $i$ 对应的 $i$ 次应用：\n(define (church i) (if (= i 0) zero_time_f (succ (church (- i 1))) ) ) 这就是自然数 $i$ 对应的 Church Encoding.\n在 REPL 中简单做一个测试：对 3 应用 $2$ 次 cube $((3^3)^3=19683)$\n1 ]=\u0026gt; (church 2) ;Value: #[compound-procedure 15] 1 ]=\u0026gt; ( #[compound-procedure 15] cube 3) ;Value: 19683 理解 Church Encoding Church Encoding 不是：\n可以被存储在物理存储器中的，可以用 bit 表示的数字\n为了算数运算（类似 $3.14 × 2.17$ ）而设计\nChurch Encoding 是：\n对 \u0026quot; 计数 \u0026quot; 的抽象 Church Encoding 是对计数过程的一种抽象，在 Lambda Calculus 的语境里，归纳定义 $λ-term$ 的三条规则分别涉及了 $atom$, $abstraction$, $application$，Church Encoding 可以理解为：有一个起始的 $atom$ 和一个 $abstraction$ ，我们希望对这个 $atom$ 进行若干次 $abstraction$ 的应用（$apply$），我们使用更高一层的 $abstraction$ 来抽象对 \u0026quot; 若干次 \u0026quot; 进行计数的过程，这一层对于计数过程的抽象就是 Church Encoding.\nChurch Encoding in Scheme $zero：λf.λx.x$\n对某个 $term$ 进行 $0$ 次任意 $abstraction$ 的应用，返回值依然是原来的 $term$.\n(define zero (lambda (f x) x)) $one：λf.λx.(f x)$ $two：λf.λx.(f (f x))$ $three: λf.λx.(f (f (f x)))$\n(define one (lambda (f x) (f x))) (define two (lambda (f x) (f (f x)))) (define thr (lambda (f x) (f (f (f x))))) 写到 thr 的时候注意到这里的递归结构，递归基毫无疑问是 zero，递归步 succ 如下：\n(define (succ z) (lambda (f x) (f (z f x))) ) 应用举例 Church Encoding 是对计数的抽象，如果我们希望对 2 进行 3 次平方（square）操作： $((2^2)^2)^2=256$\n1 ]=\u0026gt; (thr square 2) ;Value: 256 验证 succ 的正确性：\n1 ]=\u0026gt; (succ (succ (succ zero))) ;Value: #[compound-procedure 17] 1 ]=\u0026gt; (#[compound-procedure 17] square 2) ;Value: 256 参考资料 Church Encoding wiki\nTypes and Programming Languages, Chapter 5 The Untyped Lambda-Calculus\n一则知乎回答\n","date":"2024-09-08T20:13:00+08:00","permalink":"http://localhost:1313/p/church-encoding-note/","title":"Church Encoding Note"},{"content":"Introduction SICP § 2.4.3 describes a generic system implemented using table lookup (type × operation two-dimensional table), where concrete functions are hidden under abstractions like \u0026ldquo;generic function + Selector\u0026rdquo;. What would it look like if we put concrete functions under \u0026ldquo;data + Selector\u0026rdquo; abstractions? This article presents a Boolean implementation that conforms to this abstraction (called Message Passing in SICP). The importance of data and functions in programming is self-evident. Let\u0026rsquo;s explore three perspectives on the possible relationships between data and functions: Message Passing ↦ letting data carry its own functions; Using Haskell\u0026rsquo;s $ ↦ transforming data into functions; Algebraic data types in Haskell ↦ constructing data using functions.\nGeneric Functions: Intelligent Operations In section 2.4.3, the authors build a generic system. What is generics? It\u0026rsquo;s a form of abstraction. For several types that share certain characteristics, if we can write a function for one type based on this characteristic, we want to extend this function to other types with the same characteristic. For example: for two Int values, I can calculate their maximum (max Int Int) because Int is comparable (Orderable), meaning the Int type provides implementations of comparison functions like \u0026gt; / \u0026lt; / etc. For other comparable types (those that provide comparison function implementations), we want to extend max to these types:\nmax :: (Ord a) =\u0026gt; a -\u0026gt; a -\u0026gt; a max x y = if x \u0026gt;= y then x else y We abstract the comparable characteristic into the Ord type class, and the max function can work with any member type of this class.\nWhen we apply the max function to any Ord class type, the compiler helps us find the concrete implementation of \u0026gt;= for that type.\nSo how to find it? One answer is: table lookup. When I need to execute max (operation) on Float (type), I can find the function (the non-generic concrete implementation of max for Float) corresponding to (Float, max) in the Cartesian product of type × operation.\nSICP Page 252: Generics breaks down the type × operation table row by row, with each generic function occupying one row. ✨\nData and Functions Intelligent Operation? WHAT IF Intelligent Data Objects? In generic functions mentioned in the previous section, data exists as an object to be operated on. Data\u0026rsquo;s job is to be acted upon by functions. Our generics target functions (operations). In our expectation, we want functions to be smart. For example, max :: (Ord a) =\u0026gt; a -\u0026gt; a -\u0026gt; a is smart - it can \u0026ldquo;automatically\u0026rdquo; transform into the corresponding non-generic concrete implementation max :: Int -\u0026gt; Int -\u0026gt; Int for its specific type. Data just needs to wait to be acted upon.\n𝐖𝐡𝐚𝐭 𝐢𝐟: Instead of letting generic functions find concrete implementations for data → let data find concrete implementations for functions? From the perspective of decomposing the type × operation table, what if we break this table into columns, letting certain data (corresponding to generic operations, let\u0026rsquo;s call it generic? data) represent a column?\nThis was already presented in SICP 2.1.3 when discussing compound data extraction, and was mentioned in my previous blog post. The focus in SICP 2.1.3 was on operations on compound data itself (extracting fields): to ensure consistency before and after list element access, we provide the list as a procedure that accepts parameters and returns corresponding list elements based on those parameters.\nHere we care about how data behaves in programs - how data interacts with functions and other data. We want data to carry its own interaction methods rather than being static entities that can only be acted upon by other functions. Based on this idea, let\u0026rsquo;s try to write a Boolean that follows this behavioral specification.\nBoolean Carrying Functions First, let\u0026rsquo;s present a similar type × operation two-dimensional table. Since we\u0026rsquo;re doing simple modeling, we\u0026rsquo;ll only consider two operations - AND (logic_and) and OR (logic_or):\nSimilar to generic functions representing rows, we write \u0026ldquo;data\u0026rdquo; that can represent columns. The identifiers for TRUE and FALSE columns are tru and fls respectively. How to make data carry functions? One answer is to make the data itself a function that can accept parameters, using parameters to extract the functions carried by the data:\n(define tru ; (define tru (lambda ...)) (lambda (op) (cond ((eq? op \u0026#39;and) tru_logic_and) ((eq? op \u0026#39;or) tru_logic_or) ) ) ) (define fls ; (define fls (lambda ...)) (lambda (op) (cond ((eq? op \u0026#39;and) fls_logic_and) ((eq? op \u0026#39;or) fls_logic_or) ) ) ) The functions corresponding to lambda - cond (curried logical AND and OR) are implemented as follows:\n(define (tru_logic_and x) (if (eq? x tru) tru fls)) ; 1 AND x (define (tru_logic_or x) tru) ; 1 OR _ = 1 (define (fls_logic_and x) fls) ; 0 AND _ = 0 (define (fls_logic_or x) (if (eq? x tru) tru fls)) ; 0 OR x Checking tru fls in REPL: unsurprisingly both are compound procedures\n1 ]=\u0026gt; tru ;Value: #[compound-procedure 13 tru] 1 ]=\u0026gt; fls ;Value: #[compound-procedure 12 fls] Let\u0026rsquo;s do a simple test:\n1 ]=\u0026gt; ((tru \u0026#39;and) fls) ;Value: #[compound-procedure 12 fls] What did we do here? First, tru is a lambda expression that accepts symbol parameters. (tru 'and) returns tru_logic_and - a curried logical AND (that is, logical AND with TRUE already passed in), then we apply tru_logic_and to fls, and the final return value is the compound procedure fls.\nHere\u0026rsquo;s an illustration:\nFor longer expressions: if we ignore some parentheses, it looks like infix logical expressions\n1 ]=\u0026gt; ((((fls \u0026#39;or) tru) \u0026#39;and) fls) ; ((0 or 1) and 0) ;Value: #[compound-procedure 12 fls] If you prefer prefix calls, we can add a small wrapper:\n(define (logic op x y) ((x op) y)) Testing logic:\n1 ]=\u0026gt; (logic \u0026#39;and tru fls) ;Value: #[compound-procedure 12 fls] 1 ]=\u0026gt; (logic \u0026#39;or (logic \u0026#39;and fls fls) tru) ; (or (and 0 0) 1) ;Value: #[compound-procedure 13 tru] → Message Passing: Another Perspective on Data This style of building Boolean is called Message Passing: data is an entity that receives operation names (messages). For example: tru can receive messages like 'and / 'or and return corresponding curried functions for our subsequent use. From this perspective, the data itself is as important as the methods carried by the data, which is also a manifestation of \u0026ldquo;data as program\u0026rdquo;. You might notice a hint of object-oriented flavor here - objects are essentially \u0026ldquo;state + methods\u0026rdquo;, and here data contains \u0026ldquo;state + functions\u0026rdquo;, though the state here is immutable.\nHaskell\u0026rsquo;s $ $ is an infix function with the following type signature and precedence. Its purpose is to change expression evaluation order, and one objective result is that using $ reduces the number of parentheses in code:\nghci\u0026gt; :i ($) ($) :: (a -\u0026gt; b) -\u0026gt; a -\u0026gt; b -- Defined in \u0026#39;GHC.Base\u0026#39; infixr 0 $ Applying $ (curried) to a value returns a function:\nghci\u0026gt; x = 5 :: Int ghci\u0026gt; :t ($ x) ($ x) :: (Int -\u0026gt; b) -\u0026gt; b One way to understand this is: ($ x) transforms x from static data into data waiting to be acted upon by function Int -\u0026gt; b (which is a function from the type signature). Based on this understanding, we can write code like this:\nghci\u0026gt; map ($ 5) [(* 2), (+ 10), (^ 3)] [10,15,125] Algebraic Data Types in Haskell Here\u0026rsquo;s the classic recursive definition of binary trees using algebraic data types:\ndata Tree a = Empty | Node a (Tree a) (Tree a) Empty and Node are value constructors for Tree a. Value constructors are functions that return values of some type. Empty is a nullary constructor, while Node takes three value parameters: a, Tree a, and Tree a.\nTree a is a type constructor. Type constructors are functions that return specific types. Tree a takes one type parameter a and returns the corresponding concrete Tree type. For example, Tree Int and Tree Char are Tree types with node data types of Int and Char respectively.\nThis shows Haskell\u0026rsquo;s beautiful consistency in language design - there\u0026rsquo;s no special generic syntax, just functions throughout.\n","date":"2024-09-07T23:18:00+08:00","permalink":"http://localhost:1313/p/message-passing-perspective-on-bool-sicp-2.4.3-generic-data-and-functions/","title":"Message Passing Perspective on Bool - SICP § 2.4.3 | Generic | Data and Functions"},{"content":"Code Here: Huffman Tree in Haskell\nHaskell Implementation of Huffman Trees Data Abstraction type Weight = Int data Symbol = A | B | C | D | E | F | G | H deriving Show data HuffmanTree a = Empty | Leaf a Weight | Node (HuffmanTree a) (HuffmanTree a) [a] Weight deriving Show Symbol + Weight → Leaf We encode symbols (Symbol / generic a) based on their frequency/weight (Weight), combining these two pieces of information into a Leaf abstraction, corresponding to SICP\u0026rsquo;s (define (make-leaf symbol weight) (list 'leaf symbol weight)).\nGeneric types and constraints: There are no type constraints on symbols. The weight constraint is that Weight belongs to the Ord typeclass because weights need to be comparable. Here we directly use Int as the weight type instead of making it generic.\nRecursive Definition of HuffmanTree Contains three constructors: Empty, Leaf, and Node:\nEmpty: Empty tree Leaf: Leaf node containing symbol a and weight Weight Node: Branch node containing left and right subtrees (HuffmanTree a), union of subtree symbols [a], and total subtree weight Weight. Building the Huffman Tree Getting Weight Get the weight of Leaf，Node through pattern matching.\ngetWeight :: HuffmanTree a -\u0026gt; Weight getWeight (Leaf _ w) = w getWeight (Node _ _ _ w) = w For simplicity, we haven't considered the `Empty` tree case. For better safety, we should write `getWeight :: HuffmanTree a -\u003e Maybe Weight`, returning `Nothing` when matching `Empty`.\nList Organization The starting point for building a Huffman tree is an ordered list of leaves. During construction, the [HuffmanTree a] list needs to maintain order. The functions in this section aim to organize an unordered list into an ordered one.\n» adjoinLeaf: Insert a HuffmanTree a into an existing ordered [HuffmanTree a] based on weight (ascending order).\n» initLeafs: Organize an existing unordered leaf list into an ordered leaf list.\n» moveFirstNode: During Huffman Tree construction, the Merge operation combines the two HuffmanTree (Leaf / Node) with smallest weights—the first two elements in the list—into a new Node. This function helps reposition the newly generated Node after merging.\nadjoinTree :: HuffmanTree a -\u0026gt; [HuffmanTree a] -\u0026gt; [HuffmanTree a] adjoinTree t [] = [t] adjoinTree t (t\u0026#39;:ts) | w \u0026lt; w\u0026#39; = t: t\u0026#39;: ts | otherwise = t\u0026#39;: (adjoinTree t ts) where w = getWeight t w\u0026#39; = getWeight t\u0026#39; initLeafs :: [HuffmanTree a] -\u0026gt; [HuffmanTree a] -- I know pl(leaf) = leaves, btw. ^^ initLeafs [] = [] initLeafs (p:ps) = adjoinLeaf p (initLeafs ps) moveFirstNode :: [HuffmanTree a] -\u0026gt; [HuffmanTree a] moveFirstNode (t:ts) = adjoinLeaf t ts Tree Construction » makeNode: Combines two HuffmanTrees into a Node. » constructHuffTree: Bottom-up tree construction, building the Huffman Tree using tail recursion.\nRecursive step: Merge the first two elements in the current list into a parent Node using makeNode, move the parent node to get a new ordered list, and recursively process the new list.\nBase case: List contains only one element, which is the root node.\n» initAndConstructHuffTree: Final encapsulation, using Point-less composition to combine leaf list initialization initLeafs and tree construction constructHuffTree.\nmakeNode :: HuffmanTree a -\u0026gt; HuffmanTree a -\u0026gt; HuffmanTree a makeNode (Leaf s1 w1) (Leaf s2 w2) = Node (Leaf s1 w1) (Leaf s2 w2) [s1, s2] (w1 + w2) makeNode (Leaf s w) (Node l r ss w\u0026#39;) = Node (Leaf s w) (Node l r ss w\u0026#39;) (s:ss) (w + w\u0026#39;) makeNode (Node l r ss w\u0026#39;) (Leaf s w) = Node (Node l r ss w\u0026#39;) (Leaf s w) (ss ++ [s]) (w + w\u0026#39;) makeNode (Node l1 r1 ss1 w1) (Node l2 r2 ss2 w2) = Node (Node l1 r1 ss1 w1) (Node l2 r2 ss2 w2) (ss1 ++ ss2) (w1 + w2) constructHuffTree :: [HuffmanTree a] -\u0026gt; HuffmanTree a constructHuffTree [] = Empty constructHuffTree [t] = t constructHuffTree (x:y:ts) = constructHuffTree $ moveFirstNode $ (makeNode x y): ts initAndConstructHuffTree :: [HuffmanTree a] -\u0026gt; HuffmanTree a initAndConstructHuffTree = constructHuffTree . initLeafs Huffman Tree Encoding and Decoding Getting Symbol Encoding The process of building a Huffman tree is the encoding process itself. A node\u0026rsquo;s position in the tree represents its encoding. Here we present the encoding in binary form.\nEncoding representation:\ndata Bit = L | R deriving Show type Bits = [Bit] L corresponds to binary 0, R corresponds to binary 1.\nGetting the encoding involves traversing and recording the Huffman tree:\ngetCode\u0026#39; :: HuffmanTree a -\u0026gt; Bits -\u0026gt; [(a, Bits)] getCode\u0026#39; (Node (Leaf s1 _) (Leaf s2 _) _ _) rec = [(s1, rec ++ [L]), (s2, rec ++ [R])] getCode\u0026#39; (Node (Leaf s\u0026#39; _) node _ _) rec = [(s\u0026#39;, rec ++ [L])] ++ getCode\u0026#39; node (rec++[R]) getCode\u0026#39; (Node node (Leaf s\u0026#39; _) _ _) rec = getCode\u0026#39; node (rec++[L]) ++ [(s\u0026#39;, rec ++ [R])] getCode\u0026#39; (Node nodel noder _ _) rec = getCode\u0026#39; nodel (rec++[L]) ++ getCode\u0026#39; noder (rec++[R]) getCode :: HuffmanTree a -\u0026gt; [(a, Bits)] getCode t = getCode\u0026#39; t [] » getCode': Traverse the Huffman tree Recursively\nRecursive step: For a node, match left and right subtrees, continue recursive traversal for non-leaf nodes (node), recording branch directions in rec.\nBase case: When matching a Leaf in left/right subtree, it indicates reaching a Symbol. At this point, rec ++ [L] / rec ++ [R] is the encoding for that Symbol.\nPattern matching explanation: Reviewing the Huffman tree construction process, we always merge two nodes into their parent node, so there\u0026rsquo;s no case where a subtree is Empty. Therefore, every branch node\u0026rsquo;s pattern is Node lhs rhs _ _. Also, we use Leaf as the base case without recursing on it, which is why we only pattern match different forms of the Node constructor and put the Leaf recursive base cases first.\n» getCode：Wraps getCode', giving rec an initial value of [], meaning no path record at the Huffman tree\u0026rsquo;s root node.\nDecoding Basic approach: Move through the tree based on Bit, L - move to left subtree, R - move to right subtree. When reaching a Leaf subtree, one character is decoded. Then return to the root node to continue decoding the next character until the Bit list is empty.\n-- decode one symbol decodeOne :: HuffmanTree a -\u0026gt; Bits -\u0026gt; (a, Bits) decodeOne (Node (Leaf s _) _ _ _) (L:bs) = (s, bs) decodeOne (Node _ (Leaf s _) _ _) (R:bs) = (s, bs) decodeOne (Node node _ _ _) (L:bs) = decodeOne node bs decodeOne (Node _ node _ _) (R:bs) = decodeOne node bs -- decode from scratch decode :: HuffmanTree a -\u0026gt; Bits -\u0026gt; [a] decode _ [] = [] decode t bs = let (s, remainBits) = decodeOne t bs in s: decode t remainBits » decodeOne:\nBase case: When the current Bit\u0026rsquo;s corresponding subtree is a Leaf, one character is decoded. Return that character and the remaining Bits.\nRecursive step: When the current Bit\u0026rsquo;s corresponding subtree is a Node, continue recursive decoding on that Node until reaching the base case.\n» decode:\nBase case: Empty Bit list means decoding is complete.\nRecursive step: For non-empty Bit list, pass the root node and current Bit list to decodeOne for single character decoding. After one character is decoded, continue decoding remaining Bits from the root node until the Bit list is empty.\n» How to return to root node:\nInitially, the function signature I wrote was decode :: HuffmanTree a -\u0026gt; HuffmanTree a -\u0026gt; Bits -\u0026gt; [a], with two HuffmanTree parameters representing the original root node and current node. Implementation was roughly:\ndecode\u0026#39; :: HuffmanTree a -\u0026gt; HuffmanTree a -\u0026gt; Bits -\u0026gt; [a] decode\u0026#39; originT (Node (Leaf s _) _ _ _) (L:bs) = s: (decode\u0026#39; originT originT bs) --snip-- This didn\u0026rsquo;t feel quite right since the originT parameter never changed during recursion, so I slightly modified the recursive structure to write the above decode and decodeOne. SICP uses closures to remember the initial root node.\nStructure and Destructure of Compound Data SICP: Data, but Functions? Consistency We want to use structured data—rather than scattered variables—as program components, thus we have compound data like struct / class. The question then becomes how to extract the fields used to construct compound data. One thing extraction needs to ensure is consistency of fields before and after extraction. This is mainly the compiler\u0026rsquo;s work, but if we want to demonstrate this at the source code level, how can we do it? SICP 2.1.3 (Page 124) does it this way:\n(define (cons x y) (define (dispatch m) (cond ((= m 0) x) ((= m 1) y) (else (error \u0026#34;Argument not 0 or 1: CONS\u0026#34; m)))) dispatch) (define (car z) (z 0)) (define (cdr z) (z 1)) Exercise 2.4 (Page 125) has an elegant implementation using lambda:\n(define (cons x y) (lambda (m) (m x y))) (define (car z) (z (lambda (p q) p))) （For Pure Lambda Calculus implementation of this example, see the last section of this article.）\nA key point this chapter of SICP emphasizes is: The boundary between data and procedures isn\u0026rsquo;t so clear-cut. The above two programs demonstrate this precisely: the list constructor returns a procedure that provides an interface to access the elements composing the list, which enables the definition of car / cdr.\nData Combination and Extraction → Program Construction: Abstraction Layer Combination in LISP (LISt Programming) can be simple - data is combined by constructing lists, like (list 1 2 3) / (list 3 4 (list 9 7) 5), you can implement pair, tree, etc. with lists.\nHowever, data within programs can\u0026rsquo;t directly flow between functions in this form, so we have abstraction layers:\nConstructor (make-rat) and selector (denom, numer) represent one level of abstraction from primitive data types to compound data, giving programs (functions above this abstraction layer, like add-rat / sub-rat) a higher perspective to view data. Data is no longer just scattered integers/floats, but rat that can be constructed/extracted/analyzed. Functions above add-rat / sub-rat don\u0026rsquo;t need to care about rat\u0026rsquo;s implementation details, they just need to use operations like add-rat to solve problems. The process of program construction is a process of raising abstraction levels.\nHaskell: Pattern Match In Haskell, how do we handle the issue of data construction and extraction?\nConstruction:\nThe syntax for declaring compound data is:\ndata Point = Point Int Int This defines the Point type with a constructor Point Int Int, which can then be used to construct compound data of type Point, like p = Point 1 2.\nExtraction:\nPattern Match\nA simple example:\ngetX :: Point -\u0026gt; Int getX (Point x _) = x Notably: How you construct the compound data (Point Int Int) is how you match it (Point x _). That is—how you structure is how you destructure.\nOne advantage of this syntax is that you can parse function parameters through Pattern Matching. For example:\nconstructHuffTree :: [HuffmanTree a] -\u0026gt; HuffmanTree a constructHuffTree [] = ... -- empty leaf list → return empty tree constructHuffTree [t] = ... -- only one leaf → return tree with just root node constructHuffTree (x:y:ts) = ... -- two or more leaves → recursively build Huffman tree This demonstrates that: The way function parameters are destructured determines the function\u0026rsquo;s behavior.\nFor example, consider this problem: counting the number of nodes in a binary tree\ndata Tree a = Empty | Node a (Tree a) (Tree a) treeSize :: Tree a -\u0026gt; Int treeSize Empty = 0 treeSize (Node _ left right) = 1 + treeSize left + treeSize right Empty tree constructed with Empty constructor → directly return 0 (base case)\nNon-empty tree constructed with Node constructor → solve recursively (recursive step)\nHow we construct data determines how we process it, and in Haskell, the form of constructing data matches the form of pattern matching on data, so we can do pattern matching in function parameter positions, with each pattern corresponding to a function behavior.\nLambda Calculus - pair abstraction pair abstraction in Pure Lambda Calculus 上The example mentioned in the Consistencysection can be implemented in pure Lambda Calculus:1：\npair = λm λn λb. b m n pair v w = λb. b v w This abstraction provides this perspective: through two applications of pair, we instantiate m and n, determining the elements contained in the pair, leaving b as an interface for subsequent operations on the pair elements. To extract elements from the pair in order, we can define fst and snd:\nfst = λa λb. a snd = λa λb. b (pair v w) fst → v // parentheses here can be omitted , according to left associativity convention (pair v w) snd → w If you prefer programming style like fst (pair v w), that\u0026rsquo;s also possible:\ntru = λt λf. t // α-equivalent to `fst` defined in previous code block, we can understand the same abstraction differently fls = λt λf. f // ... `snd` ... fst = λp. p tru snd = λp. p fls fst (pair v w) → v snd (pair v w) → w Let\u0026rsquo;s examine this abstraction again: pair = λm λn λb. b m n. In Lambda Calculus, what we commonly call functions are termed abstractions, and this pair abstraction provides an abstraction over the construction and operation of pairs. We first determine the contained elements through outer parameters m and n to build the pair, then use inner parameter b to execute operations on the existing elements. From this perspective, pair naturally possesses the ability to interact with other functions (abstractions) within the Lambda Calculus system, because after instantiating the pair elements, it provides the interaction interface b, waiting for other abstractions to interact with the pair\u0026rsquo;s existing elements through application.\nTypes and Programming Languages - Chapter 5 The Untyped Lambda-Calculus\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-09-02T01:53:00+08:00","permalink":"http://localhost:1313/p/huffman-trees-in-haskell-structure-and-destructure-of-compound-data/","title":"Huffman Trees in Haskell | Structure and Destructure of Compound Data"},{"content":"Problem Description Problem: Given a positive integer $n$, find all ordered pairs of distinct positive integers $i$ and $j$, where $ 1 \\leq i \\leq j \\leq n $, such that $ i + j $ is prime.\nImplementation in Haskell isDivisible :: Int -\u0026gt; Int -\u0026gt; Bool isDivisible x y | mod x y == 0 = True | otherwise = False isPrime :: Int -\u0026gt; Bool isPrime x | x \u0026lt;= 2 = True | otherwise = not (foldr (||) False (map (isDivisible x) [2..((floor . sqrt . fromIntegral) x)])) genPairs :: Int -\u0026gt; [((Int, Int), Int)] genPairs n = do x \u0026lt;- [1..n] y \u0026lt;- [1..(x-1)] return ((y, x), (x + y)) sumPrimePairs :: Int -\u0026gt; [((Int, Int), Int)] sumPrimePairs = (filter (\\(_, s) -\u0026gt; (isPrime s))) . genPairs About List Monad: Context, Nested lambda and do-notation Context of List Monad : nondeterministic result.\nThe title of this section is Nested Mappings, represented in code with nested lambdas. In Haskell, do notation is syntactic sugar for nested lambdas.\nAnd flatMap defined in this chapter is actually Haskell \u0026gt;\u0026gt;= (bind) in Haskell.\nFor further details, consult Learn You a Haskell for Great Good: A Fistful of Monads - the List Monad\nAnother Example: The List Monad for Permutation An intuitive way to understand this is that nondeterministic results are well-suited for solving permutations.\npermutations :: Eq a =\u0026gt; [a] -\u0026gt; [[a]] permutations [] = [[]] permutations xs = do x \u0026lt;- xs perm \u0026lt;- permutations $ removeByElem x xs return (x: perm) removeByElem :: Eq a =\u0026gt; a -\u0026gt; [a] -\u0026gt; [a] removeByElem x = filter (/= x) ","date":"2024-08-29T00:00:00+08:00","permalink":"http://localhost:1313/p/nested-mapping-examples-implemented-in-haskell-sicp-2.2.3-list-monad/","title":"Nested Mapping Examples Implemented in Haskell - SICP § 2.2.3  | List Monad "},{"content":" Semantics of let Key point: A let scope is evaluated immediately (including both bindings and expressions after bindings, i.e., everything within the outer parentheses of the let), even if the let is nested inside an inner function that hasn\u0026rsquo;t been called yet.\nExample:\n(define (comp x) (if (\u0026gt; 3 x) (display \u0026#34;then-clause\u0026#34;) (display \u0026#34;else-clause\u0026#34;) ) #| (define foo1 (let ((bar1 (/ 2 0))) ; * evaluted immediately (display \u0026#34;should not be printed\u0026#34;) ) ) |# (define foo2 (let ((bar2 (/ 5 2))) ; * evaluted immediately (newline) (display \u0026#34;let in `foo2`, bar2: \u0026#34;) (display bar2) ) ) ) Running examples:\nfoo1: We can see that the let binding is evaluated, otherwise we wouldn\u0026rsquo;t get a division by zero exception.\nprompt\u0026gt; (comp 4) else-clause ;Division by zero signalled by /. ;To continue, call RESTART with an option number: ;snip foo2: We can see that the expressions after the let binding are evaluated, otherwise we wouldn\u0026rsquo;t see the display output.\nprompt\u0026gt; (comp 2) then-clause let in `foo2`, bar2: 5/2 ;Unspecified return value Semantics of if The semantics of if: It evaluates the condition first, then decides whether to evaluate the then-clause or else-clause based on the result.\nA good reference for this is SICP (2nd Edition) Exercise 1.6, where an abstraction is used to define new-if using cond:\n(define (new-if predicate then-clause else-clause) (cond (predicate then-clause) (else else-clause) ) ) The semantics of function application (applicative order evaluation) requires evaluating arguments first (like then-clause and else-clause here) before applying the function. This is why you can\u0026rsquo;t write recursive expressions in then-clause or else-clause - they would be evaluated regardless of the predicate\u0026rsquo;s value, leading to infinite recursion. if/cond/\u0026hellip; are special forms with different semantics compared to abstractions defined through define. I like the new-if example because it elegantly demonstrates Lisp\u0026rsquo;s metaprogramming features. Following the substitution model, predicate, then-clause, and else-clause can be replaced with any expressions you need, where expressions are enclosed in parentheses - the parentheses mark expression boundaries, and you can put parenthesized expressions in any parameter position (as long as they satisfy the implicit type constraints of the abstraction).\nAn Error Caused by Immediate let Evaluation Consider this prime number checking code:\n(define (prime? x) (if (or (= x 1) (= x 2)) #t test_prime ) (define (divisible? y) (= 0 (remainder x y)) ) (define (iter_biggest_divisor y) (cond ((= y 1) 1) ((divisible? y) y) (else (iter_biggest_divisor (- y 1))) ) ) (define test_prime (let ((biggest_divisor (iter_biggest_divisor (quotient x 2)) )) ; Notice (display biggest_divisor) (if (= biggest_divisor 1) #t #f ) ) ) ) The results when running:\nprompt\u0026gt; (prime? 1) ;The object 0, passed as the second argument to integer-remainder, is not in the correct range. prompt\u0026gt; (prime? 2) 1 ;Value: #t According to programmers\u0026rsquo; expectations, both (prime? 1) and (prime? 2) should directly return #t, rather than the former throwing an error and the latter showing the behavior of (display biggest_divisor). As stated earlier, this occurs because the entire let scope is evaluated immediately.\n","date":"2024-08-29T00:00:00+08:00","permalink":"http://localhost:1313/p/semantics-of-let-in-schemefeat.-semantics-of-if/","title":"Semantics of `let` in Scheme(feat. Semantics of `if`)"},{"content":"Code, easier✨\nYour VSCode Assistant Ctrl + Shift + P\nIf you need to do something in VSCode, you can press Ctrl + Shift + P to search for it. For example, if you want to change settings but manually opening settings.json is too tedious, you can:\nAfter pressing Enter, settings.json will be right in front of you. If you need to frequently perform this action, you can bind a shortcut for it in Keyboard Shortcuts (open with Ctrl-k Ctrl-s):\nLayout Hide Activity Bar and Status Bar I’ve configured shortcuts in the image below to toggle the Activity Bar and Status Bar. Hiding these can make the interface cleaner.\nPlace Terminal Tab and Code Tab Together Press Ctrl+Shift+P → Search for Terminal: Move Terminal to Editor Area in the command palette to move the terminal into the Editor Area. Other similar actions include Move Terminal to Panel, Create New Terminal in Editor Area, etc. Of course, you can bind a shortcut for frequently used actions.\nAn applicable scenario is: if you are learning a programming language that has a REPL (like Haskell, Lisp, Python\u0026hellip;), you can split the Editor Area into two parts, one for the code and one for the Terminal REPL. If needed, you can edit files and import them in the REPL (like :l foo.hs in GHCi). This way, it’s more convenient, and you can switch focus between the code tab and terminal tab with Ctrl+1 / Ctrl+2.\nAnother similar solution: Open the Secondary Side Bar with Ctrl+Shift+B, then drag the terminal to the Secondary Side Bar.\nEditor Area Rainbow Guidelines In Settings (GUI), type @id:editor.bracketPairColorization.enabled @id:editor.guides.bracketPairs and select the options you need. editor.bracketPairColorization.enabled is enabled by default, while editor.guides.bracketPairs is off by default. You can set it to true or active to enable. The true effect colors all parentheses, and the active effect only colors the outer parentheses closest to the cursor. I think active is enough, and here’s the result:\nUse Ctrl+Shift+\\ to jump between the closest paired parentheses to the cursor, useful for checking nested expressions, corresponding to % in Vim Normal Mode. If your focus is in the Terminal, you can use Ctrl+Shift+\\ to jump between terminal tabs.\nShortcuts Tip\nHover your cursor over a button in the GUI, and if the button has a corresponding shortcut, a tooltip will show the shortcut key (many programs follow this design philosophy). So, if you find yourself frequently clicking a button, stop and check its hotkey.\nCtrl-b：toggle side bar.\nHere\u0026rsquo;s a related story: someone submitted an issue requesting a toggleExplorerVisibility configuration in VSCode. A user replied \u0026ldquo;Ctrl-B to toggle side bar\u0026rdquo; and closed the issue. Why do I know this? Because I also thought my need was toggleExplorerVisibility, and the lesson learned is: knowing the correct names of components is important 😣.\nAlt-←/→：Go back to the previous cursor position / move forward to the next cursor position.\nThis is particularly useful when navigating through function calls, in combination with F12.\nCtrl-[ / Ctrl-]：Indent the current line left/right.\nSimilar to Vim’s \u0026gt; / \u0026lt; in Visual Mode. I don’t find Vim’s version very smooth because you can only perform the operation once after selecting, and to make further indentations, you need to select again.\nAlt-↑/↓：Move the current line up/down.\nShift-Alt-f: Format code, provided a formatter is configured.\nCtrl-(Shift-)Enter: Create a new line below (or above) the current cursor position, with the cursor jumping to the start of the new line.\nCorresponds to o(O) in Vim Normal Mode.\nFrom the 2025-02-19 update: After the VSCode update, Copilot Suggestions (GitHub Copilot: Open Completion Panel) now occupy Ctrl-Enter, which can be changed in Keyboard Shortcuts. Ctrl-k Ctrl-w\nClose all tabs in the Editor Area.\nConflict Avoidance\nDirect conflicts are shown when performing keybinding actions, but in cases like this, where the leading key = other shortcut keys, no conflict is shown. However, in this case, Copy is essentially broken because Ctrl-c will act as the leading key, and after pressing it, VSCode will wait for the chord key. You can observe this in the status bar.\nExtensions Bluloco Light Theme (Author: Umut Topuzoğlu)\nA very beautiful theme.\nRemove empty lines (Author: Alexander)\nDeletes all empty lines in the selected area. You can call it via Ctrl + Shift + P or bind a shortcut for it.\nMiscellaneous Some small settings in User Settings (JSON) include:\nChange the background color of hover widgets (e.g., function descriptions provided by the Language Server);\nChange the zoom level;\nRainbow bracket guide line.\n{ \u0026#34;workbench.colorCustomizations\u0026#34;: { \u0026#34;editorHoverWidget.background\u0026#34;: \u0026#34;#edeeee\u0026#34;, // Set the hover widget background color }, \u0026#34;window.zoomLevel\u0026#34;: 1, \u0026#34;editor.guides.bracketPairs\u0026#34;: \u0026#34;active\u0026#34; } Some Useful Windows Shortcuts （🪟 epresents the Windows key.）\n🪟\nPress the Windows key and type text to search for apps, settings, files, etc. After finding the match, press Enter to open it.\n🪟 + Arrow keys\nWin + ↑：Maximize the current window Win + ←/→：Snap the window to the left/right\nWin + ↓：Exit fullscreen / Minimize\n🪟 + v\nShow clipboard history (the maximum capacity is unknown, but records are lost when shutting down). You can also select and enter emojis, symbols, and emoticons here.\nAlt-Tab\nSwitch between windows on the current desktop.\nCtrl-(Shift-)Tab\nSwitch between tabs in the current application (browser, VSCode). Different applications may sort the tabs differently—some by access order (VSCode), others by creation order (Edge).\nAlt-F4\nClose the current window.\nCtrl-w\nClose the current tab in Edge.\n","date":"2024-08-26T00:00:00+08:00","permalink":"http://localhost:1313/p/my-common-vscode-shortcuts/","title":"My Common VSCode Shortcuts"},{"content":" Perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away. \u0026ndash; Antoine de Saint-Exupéry\nInstalling MIT-Scheme via Package Manager MacOS:\nbrew install mit-scheme Ubuntu:\nsudo apt-get update sudo apt-get install mit-scheme Basic REPL Usage （REPL: Read-Evaluate-Print Loop）\nStart the REPL with a single command mit-scheme.\nLoad Scheme code into the REPL:\n1 ] =\u0026gt; (load \u0026#34;path/to/file.scm\u0026#34;) (The .scm extension can be omitted.)\nView the manual:\nUse the man mit-scheme command in the terminal to view the brief mit-scheme CLI manual.\nWhen in REPL, press Ctrl-C and then type H to see the interrupt manual:\nCtrl-C: Waits for the next keyboard input to decide the interrupt behavior.\nCtrl-G: Returns to the top-level REPL.\nCtrl-Z: Suspends the current mit-scheme process.\nPress Ctrl-C and then type ? to see the manual for the next key input (option) and how it corresponds to REPL behavior (clear screen, suspend, exit, ignore interrupts, etc.).\nIf the REPL doesn\u0026rsquo;t respond:\nCheck if parentheses are properly matched; ( ( ) ( ( ) )\nAfter interrupting with Ctrl-C, the prompt (1 ] =\u0026gt; / 2 error\u0026gt;) may not reappear, which results in the \u0026ldquo;frozen\u0026rdquo; REPL.\nWorried about deep recursion? If the recursion depth exceeds the limit, the REPL will show Recursion depth limit exceeded. Aborting!. (According to mit-scheme manual, which you can get by man mit-scheme, stack size can be specified with CLI parameters, meaning MIT-Scheme has limited stack resources.)\nScHeMe Scheme is case-insensitive.\nSo (LoAd \u0026quot;path/to/file.scm\u0026quot;)/(DEFINE x 1)/(define x 1)/(defiNE x 1), etc. won\u0026rsquo;t cause errors.\nHistory variable (procedure): Reuse procedures returned after evaluating expressions in the REPL:\n1 ]=\u0026gt; (average-dump square) ;Value: #[compound-procedure 12] ; Can be reused in subsequent expressions, similar to GDB\u0026#39;s history variable `$1` 1 ]=\u0026gt; (#[compound-procedure 12] 10) ; Not very convenient to use directly, but it works ;Value: 55 1 ]=\u0026gt; (define newfunc #[compound-procedure 12]) ; Can be bound to a new identifier for reuse ;Value: newfunc 1 ]=\u0026gt; (newfunc 10) ;Value: 55 Afterword This Scheme REPL is quite basic. It doesn’t support history backtracking or cursor movement, however, since I don\u0026rsquo;t need it for anything too complex, it\u0026rsquo;s good enough for me.\n","date":"2024-08-24T00:00:00+08:00","permalink":"http://localhost:1313/p/mit-scheme-basic-usage/","title":"mit-scheme Basic Usage"},{"content":" How to debug a Rust program? $ gdb excutable Simple example:\nViewing a variable\u0026rsquo;s address:\nFormatted output of p s:\n$17 = alloc::string::String { vec: alloc::vec::Vec\u0026lt;u8, alloc::alloc::Global\u0026gt; { buf: alloc::raw_vec::RawVec\u0026lt;u8, alloc::alloc::Global\u0026gt; { ptr: core::ptr::unique::Unique\u0026lt;u8\u0026gt; { pointer: core::ptr::non_null::NonNull\u0026lt;u8\u0026gt; { pointer: 0x5555555abb80 }, _marker: core::marker::PhantomData\u0026lt;u8\u0026gt; }, cap: alloc::raw_vec::Cap (16), alloc: alloc::alloc::Global }, len: 16 } } Key points: p \u0026lt;variable\u0026gt; p \u0026amp;\u0026lt;variable\u0026gt; ptype \u0026lt;variable\u0026gt;\nOwnership issues with dbg! when outputting debug information Incorrect:\ndbg!(var); // move dbg!(var); // invalid reference dbg! will take ownership of var (Move), so var can\u0026rsquo;t be used again.\nCorrect:\ndbg!(\u0026amp;var); // or let new_var = dbg!(var); dbg!(\u0026amp;new_var); // if you want to Explore with gdb For things you want to explore, use gdb, for example: [How is enum represented at a low level?] -\u0026gt; Write a simple program, compile it to an executable, then use gdb, using print var print \u0026amp;var x/x \u0026lt;addr\u0026gt; to explore.\n关于对 vector 的引用 An excerpt from ch08-01\n/* CANNOT COMPILE */ let mut v = vec![1, 2, 3, 4, 5]; let first = \u0026amp;v[0]; v.push(6); println!(\u0026#34;The first element is: {first}\u0026#34;); The code in Listing 8-6 might look like it should work: why should a reference to the first element care about changes at the end of the vector? This error is due to the way vectors work: because vectors put the values next to each other in memory, adding a new element onto the end of the vector might require allocating new memory and copying the old elements to the new space, if there isn’t enough room to put all the elements next to each other where the vector is currently stored. In that case, the reference to the first element would be pointing to deallocated memory. The borrowing rules prevent programs from ending up in that situation.\nA question: How to make a Vector appear to store multiple types of data? Answer: Have the Vector store enums. An enum can have variants of different types, so in a sense, the Vector can store multiple types of data.\nfn main(){ let v: Vec\u0026lt;CellType\u0026gt; = vec![ CellType::Int(12), CellType::Text(String::from(\u0026#34;word\u0026#34;)), CellType::Float(3.14), ]; let v1 = \u0026amp;v[0]; } enum CellType { Int(i32), Float(f64), Text(String), } Debugging enums with gdb and using history variables in gdb (and other REPLs) Source code:\nfn main(){ let v: Vec\u0026lt;CellType\u0026gt; = vec![ CellType::Int(12), CellType::Float(3.14), ]; let v1: \u0026amp;CellType = \u0026amp;v[0]; let v2: \u0026amp;CellType = \u0026amp;v[1]; println!(\u0026#34;END\u0026#34;); } enum CellType { Int(i32), Float(f64), } Debugging session:\np v1：Prints the value of v1: \u0026amp;CellType, which is a pointer value, meaning the address where the associated data is stored on the heap. Note that the data corresponding to v1, v2 each occupies 16 bytes. x/4x $1：Examines the 16 bytes pointed to by v1. p *v1：Dereferences v1 to view the actual value stored at that memory location. Analysis of how enum is actually stored in memory:\nThe first byte is likely the variant identifier, with the mapping: 0-Int 1-Float\nInt: Associated data is stored in the second byte, 0x0000000c represents Int(12) from the code\nFloat: Associated data is stored in the third and fourth bytes 0x40091eb8_51eb851f which is the IEEE 754 64-bit representation of 3.14\nRemaining question: Why are the associated data stored in different positions for these two variants, and what is 0x00005555 in Float?\nRediscovering gdb features (history variable)：\nThe $x in p var output is a history variable for later reuse. Similar REPL behaviors include bash\u0026rsquo;s echo $(ls) and mit-scheme, which also provides referenceable history variables for returned procedures (though those variables are long and contain special characters like #[], so to truly reuse them you still need to copy the identifier and bind it to another identifier for reuse).\nRUST_BACKTRACE and command line tips $ RUST_BACKTRACE=1 cargo run $ A=12 B=23 echo \u0026#34;$A $B\u0026#34; You can write temporary environment variables at the leftmost part of the command.\nFancy technique: color escape sequences in Rust\u0026rsquo;s println println!(\u0026#34;\\x1b[34mMESSAGE\\x1b[0m\u0026#34;); Using \\x1b[34m for escape sequences\nWhat is \\x1b?\n\\x indicates hexadecimal, 1b is the ASCII hex code for ESC.\nDifference between unwrap and expect in Result\u0026lt;T, E\u0026gt;: Looking at library function implementations can give you a better understanding of pre-packaged functions. For example, with Result\u0026lt;T, E\u0026gt;\u0026rsquo;s unwrap and expect, looking at the source code reveals that the difference is in the msg parameter of unwrap_failed (and unwrap_failed is just a wrapper around panic!):\nimpl\u0026lt;T, E\u0026gt; Result\u0026lt;Result\u0026lt;T, E\u0026gt;, E\u0026gt; { ... pub fn expect(self, msg: \u0026amp;str) -\u0026gt; T where E: fmt::Debug, { match self { Ok(t) =\u0026gt; t, Err(e) =\u0026gt; unwrap_failed(msg, \u0026amp;e), } } pub fn unwrap(self) -\u0026gt; T where E: fmt::Debug, { match self { Ok(t) =\u0026gt; t, Err(e) =\u0026gt; unwrap_failed(\u0026#34;called `Result::unwrap()` on an `Err` value\u0026#34;, \u0026amp;e), } } ... } fn unwrap_failed(msg: \u0026amp;str, error: \u0026amp;dyn fmt::Debug) -\u0026gt; ! { panic!(\u0026#34;{msg}: {error:?}\u0026#34;) } ","date":"2024-08-05T00:00:00Z","permalink":"http://localhost:1313/p/explore-rust-basic-revisiting-gdb/","title":"Explore Rust (Basic) \u0026 Revisiting gdb"},{"content":"Simple Introduction Based on materials I prepared for Computer System course\nI\u0026rsquo;ve seen many people claim that Bash syntax is uncomfortable, but I had already gotten used to Bash syntax before encountering such opinions - \u0026ldquo;I met you before the rumors did\u0026rdquo;?? 😶‍🌫️\nThe topic of the related discussion session was: how does the compiler handle switch-case statements in C? Specifically, under what distribution of case statements (continuous/discontinuous, size of intervals) will the compiler generate a jump table? Since we needed to explore different case scenarios, we first needed to generate C source files with different case patterns. This seemed rather mechanical, so we considered using an automated script. Our expectation for this script was that generator -b 10 -s 2 -d dest_dir -f file_name would produce a file with 10 branches (-b), branch intervals (-s) of 2, in the directory (-d) dest_dir, with the filename (-f) file_name.c. With a single file generator in hand, we could then write another generator to call this one and create a batch of C source files with varying numbers of branches and intervals.\nCommand Line Argument Capture The most obvious benefit of command line interfaces is that you can control a command\u0026rsquo;s specific behavior through options. For example, cat displays file contents, while cat -n adds line numbers. To capture command line arguments, we use getopts:\nwhile getopts \u0026#34;:b:d:f:s:\u0026#34; opt; do case $opt in b) branch=$OPTARG # number of switch branches ;; :) echo \u0026#34;Option -$OPTARG requires an argument.\u0026#34; ;; ?) echo \u0026#34;Invalid option: -$OPTARG\u0026#34; ;; esac done The Simplest Metaprogramming The metaprogramming here refers to using code to generate code. This can be complex, but here we take the simplest approach - code is just a text file, right? So we can simply echo code text and append it to the target file:\ntargetpath=\u0026#34;./${dir}/${filename}\u0026#34; echo -e \u0026#34;/* Created by switch_generator */\\n\u0026#34;\\ \u0026gt; ${targetpath} # sleep 0.1 echo -e \\ \u0026#34;int main(){\\n\\n\\ int i = 0, j = 0;\\n\\ switch (i) {\\ \u0026#34; \u0026gt;\u0026gt; ${targetpath}; # sleep 0.1 for (( i = 1;i \u0026lt;= $branch; i++ )); do record=$i i=$(( i*seperate )) echo -e \\ \u0026#34; case $i:\\n\\ j += $i;\\n\\ break;\\n\\ \u0026#34; \u0026gt;\u0026gt; ${targetpath}; # sleep 0.1 i=$record done echo -e \\ \u0026#34; default:\\n\\ j += 1000;\\n\\ break;\\n\\ }\\n\\ return 0;\\n\\ }\u0026#34; \u0026gt;\u0026gt; ${targetpath} Source File Pipeline Raising the level of abstraction, we use another script to call the above script, implementing batch production of source files. The core code is:\nfor (( branch_num = 1; branch_num \u0026lt;= $size; branch_num++ ));do filename=\u0026#34;${compiler}_branch_${branch_num}\u0026#34; bash ./switch_generator.sh -b $branch_num -d $dir -f ${filename}.c # $compiler -S ./${dir}/${filename}.c -o ./${dir}/${filename}.s # ... done By batch compiling these files to assembly, then using grep to check for and report jump tables, our task was complete. The principles are similar, so I won\u0026rsquo;t go into further detail. If you\u0026rsquo;re curious about the answers to the discussion questions:\nCompilers use jump tables when the number of consecutive branches is ≥ 4 (clang) / 5 (gcc); otherwise, they use subl, je conditional jump instructions; When branch constant intervals are ≥ 12 (clang) / 10 (gcc), compilers no longer use jump tables, but directly use subl, je for conditional testing and jumping; When branch variables form two consecutive segments with a large gap between them, such as 1,2,\u0026hellip;,6, 101,102,\u0026hellip;106, gcc generates two jump tables (this conclusion comes from my teammate LYT) ","date":"2024-04-03T00:00:00Z","permalink":"http://localhost:1313/p/simple-bash-cli-programs-simple-metaprogramming/","title":"Simple Bash CLI Programs \u0026 Simple Metaprogramming"},{"content":"Simple Introduction Although the date here is March 20, 2024, I\u0026rsquo;m actually writing this blog on February 18, 2025, based on materials from my Computer System discussion course. If you want to know a file\u0026rsquo;s type, you might use the file command. But how does file determine file types, or more specifically, how do files in the system tell file (or any program wanting to know its type) what type they are? Where do files store their type information?\nManuals Are Always Your Friend The first second third method to understand a command is usually through whatis / man / tldr.\nman whatis will tell you that whatis actually comes from man:\nEach manual page has a short description available within it. whatis searches the manual page names and displays the manual page descriptions of any name matched.\nman file will tell that file checks file types like this：\nfile tests each argument in an attempt to classify it. There are three sets of tests, performed in this order: filesystem tests, magic tests, and language tests. The first test that succeeds causes the file type to be printed.\nfilesystem tests System call stat, using its return value to determine the file type; stat can identify empty files / file types defined in \u0026lt;sys/stat.h\u0026gt;. magic tests Check if the file header contains specific magic bytes. For example, if the first five bytes of the file correspond to the ASCII characters \u0026ldquo;%PDF-\u0026rdquo;, it\u0026rsquo;s identified as a PDF file. If no magic bytes exist, it\u0026rsquo;s determined to be a text file, and file will continue to determine its encoding as ASCII/UTF-8/\u0026hellip; language tests Determine the file\u0026rsquo;s language through keywords, such as inferring a text file is a C source file from main, struct, printf. A closer way to observe this command\u0026rsquo;s execution process is strace file foo.bar; you can also redirect the output to a file and use Vim to view it for keyword searching / readability, like strace file foo.bar \u0026amp;\u0026gt; strace.out; vim strace.out.\nFooling file? Exploiting the magic test Exploiting the language test Simple Conclusion To answer the initial question—file determines file types through filesystem tests, magic tests, and language tests. Files \u0026ldquo;express\u0026rdquo; their types through magic bytes in the file header, text encoding, or programming language keywords.\n","date":"2024-03-20T20:50:00+08:00","permalink":"http://localhost:1313/p/a-quick-look-at-the-file-command/","title":"A Quick Look at the `file` Command"}]